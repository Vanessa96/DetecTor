{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average error is 2.74ms\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "def check_sleep(amount):\n",
    "    start = datetime.now()\n",
    "    time.sleep(amount)\n",
    "    end = datetime.now()\n",
    "    delta = end-start\n",
    "    return delta.seconds + delta.microseconds/1000000.\n",
    "\n",
    "error = sum(abs(check_sleep(0.1)-0.1) for i in range(100))*10\n",
    "print(\"Average error is %0.2fms\" % error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-15 22:46:42.136237\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(datetime.fromtimestamp(1605498402.136237))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import autoreload\n",
    "# ?autoreload\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "from transformers import BertModel\n",
    "from transformers import AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# config = AutoConfig.from_pretrained(\"prajjwal1/bert-tiny\")\n",
    "config = AutoConfig.from_pretrained(\"bert-base-uncased\")\n",
    "config.hidden_act = 'gelu_fast'\n",
    "config.torchscript = True\n",
    "model = BertModel(config)\n",
    "inputs = torch.randint(1000, size=(1, 100)).long()\n",
    "# model()\n",
    "# with torch.onnx.select_model_mode_for_export(model, False):\n",
    "  # trace, _ = torch.jit._get_trace_graph(model, args=(inputs,))\n",
    "#     trace = torch.jit.trace(model, (inputs, ))\n",
    "mo=model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;33mproperty:\u001b[0m\n",
       "    \u001b[0;36mT_destination\u001b[0m\u001b[1;30m, \u001b[0m\u001b[0;36m_backward_hooks\u001b[0m\u001b[1;30m, \u001b[0m\u001b[0;36m_buffers\u001b[0m\u001b[1;30m, \u001b[0m\u001b[0;36m_forward_hooks\u001b[0m\u001b[1;30m, \u001b[0m\u001b[0;36m_forward_pre_hooks\u001b[0m\u001b[1;30m, \u001b[0m\u001b[0;36m_load_state_dict_pre_hooks\u001b[0m\u001b[1;30m, \u001b[0m\u001b[0;36m_modules\u001b[0m\u001b[1;30m, \u001b[0m\u001b[0;36m_non_persistent_buffers_set\u001b[0m\u001b[1;30m, \u001b[0m\u001b[0;36m_parameters\u001b[0m\u001b[1;30m, \u001b[0m\u001b[0;36m_state_dict_hooks\u001b[0m\u001b[1;30m, \u001b[0m\u001b[0;36m_version\u001b[0m\u001b[1;30m, \u001b[0m\u001b[0;36mauthorized_missing_keys\u001b[0m\u001b[1;30m, \u001b[0m\u001b[0;36mauthorized_unexpected_keys\u001b[0m\u001b[1;30m, \u001b[0m\u001b[0;36mbase_model_prefix\u001b[0m\u001b[1;30m, \u001b[0m\u001b[0;36mconfig\u001b[0m\u001b[1;30m, \u001b[0m\u001b[0;36mdump_patches\u001b[0m\u001b[1;30m, \u001b[0m\u001b[0;36membeddings\u001b[0m\u001b[1;30m, \u001b[0m\u001b[0;36mencoder\u001b[0m\u001b[1;30m, \u001b[0m\u001b[0;36mkeys_to_never_save\u001b[0m\u001b[1;30m, \u001b[0m\u001b[0;36mname_or_path\u001b[0m\u001b[1;30m, \u001b[0m\u001b[0;36mpooler\u001b[0m\u001b[1;30m, \u001b[0m\u001b[0;36mtraining\u001b[0m\n",
       "\u001b[0;33mspecial attribute:\u001b[0m\n",
       "    \u001b[0;36m__annotations__\u001b[0m\u001b[1;30m, \u001b[0m\u001b[0;36m__class__\u001b[0m\u001b[1;30m, \u001b[0m\u001b[0;36m__dict__\u001b[0m\u001b[1;30m, \u001b[0m\u001b[0;36m__doc__\u001b[0m\u001b[1;30m, \u001b[0m\u001b[0;36m__module__\u001b[0m\u001b[1;30m, \u001b[0m\u001b[0;36m__weakref__\u001b[0m\n",
       "\u001b[0;33mabstract class:\u001b[0m\n",
       "    \u001b[0;36m__subclasshook__\u001b[0m\n",
       "\u001b[0;33mobject customization:\u001b[0m\n",
       "    \u001b[0;36m__format__\u001b[0m\u001b[1;30m, \u001b[0m\u001b[0;36m__hash__\u001b[0m\u001b[1;30m, \u001b[0m\u001b[0;36m__init__\u001b[0m\u001b[1;30m, \u001b[0m\u001b[0;36m__new__\u001b[0m\u001b[1;30m, \u001b[0m\u001b[0;36m__repr__\u001b[0m\u001b[1;30m, \u001b[0m\u001b[0;36m__sizeof__\u001b[0m\u001b[1;30m, \u001b[0m\u001b[0;36m__str__\u001b[0m\n",
       "\u001b[0;33mrich comparison:\u001b[0m\n",
       "    \u001b[0;36m__eq__\u001b[0m\u001b[1;30m, \u001b[0m\u001b[0;36m__ge__\u001b[0m\u001b[1;30m, \u001b[0m\u001b[0;36m__gt__\u001b[0m\u001b[1;30m, \u001b[0m\u001b[0;36m__le__\u001b[0m\u001b[1;30m, \u001b[0m\u001b[0;36m__lt__\u001b[0m\u001b[1;30m, \u001b[0m\u001b[0;36m__ne__\u001b[0m\n",
       "\u001b[0;33mattribute access:\u001b[0m\n",
       "    \u001b[0;36m__delattr__\u001b[0m\u001b[1;30m, \u001b[0m\u001b[0;36m__dir__\u001b[0m\u001b[1;30m, \u001b[0m\u001b[0;36m__getattr__\u001b[0m\u001b[1;30m, \u001b[0m\u001b[0;36m__getattribute__\u001b[0m\u001b[1;30m, \u001b[0m\u001b[0;36m__setattr__\u001b[0m\n",
       "\u001b[0;33mclass customization:\u001b[0m\n",
       "    \u001b[0;36m__init_subclass__\u001b[0m\n",
       "\u001b[0;33mpickle:\u001b[0m\n",
       "    \u001b[0;36m__reduce__\u001b[0m\u001b[1;30m, \u001b[0m\u001b[0;36m__reduce_ex__\u001b[0m\u001b[1;30m, \u001b[0m\u001b[0;36m__setstate__\u001b[0m\n",
       "\u001b[0;33mdescriptor:\u001b[0m\n",
       "    \u001b[0;36mbase_model\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30m@property with getter, :obj:`torch.nn.Module`: The main body of the model.\u001b[0m\n",
       "    \u001b[0;36mdevice\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30m@property with getter, :obj:`torch.device`: The device on which the module is (assuming that all the module parameters are on the same\u001b[0m\n",
       "    \u001b[0;36mdtype\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30m@property with getter, :obj:`torch.dtype`: The dtype of the module (assuming that all the module parameters have the same dtype).\u001b[0m\n",
       "    \u001b[0;36mdummy_inputs\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30m@property with getter, :obj:`Dict[str, torch.Tensor]`: Dummy inputs to do a forward pass in the network.\u001b[0m\n",
       "    \u001b[0;36mfrom_pretrained\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mclass classmethod with getter, classmethod(function) -> method\u001b[0m\n",
       "\u001b[0;33mstatic method:\u001b[0m\n",
       "    \u001b[0;36m_expand_inputs_for_generation\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mstaticmethod(function) -> method\u001b[0m\n",
       "    \u001b[0;36m_hook_rss_memory_post_forward\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mstaticmethod(function) -> method\u001b[0m\n",
       "    \u001b[0;36m_hook_rss_memory_pre_forward\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mstaticmethod(function) -> method\u001b[0m\n",
       "    \u001b[0;36m_init_sequence_length_for_generation\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mstaticmethod(function) -> method\u001b[0m\n",
       "    \u001b[0;36m_reorder_cache\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mstaticmethod(function) -> method\u001b[0m\n",
       "    \u001b[0;36m_tie_encoder_decoder_weights\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mstaticmethod(function) -> method\u001b[0m\n",
       "    \u001b[0;36m_update_model_kwargs_for_generation\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mstaticmethod(function) -> method\u001b[0m\n",
       "    \u001b[0;36m_update_seq_length_for_generation\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mstaticmethod(function) -> method\u001b[0m\n",
       "\u001b[0;33mclass:\u001b[0m\n",
       "    \u001b[0;36mconfig_class\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mThis is the configuration class to store the configuration of a :class:`~transformers.BertModel` or a\u001b[0m\n",
       "\u001b[0;33mfunction:\u001b[0m\n",
       "    \u001b[0;36m_apply\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30m\u001b[0m\n",
       "    \u001b[0;36m_call_impl\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30m\u001b[0m\n",
       "    \u001b[0;36m_convert_head_mask_to_5d\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30m-> [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[0m\n",
       "    \u001b[0;36m_forward_unimplemented\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30m\u001b[0m\n",
       "    \u001b[0;36m_get_decoder_start_token_id\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30m\u001b[0m\n",
       "    \u001b[0;36m_get_logits_processor\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mThis class returns a :obj:`~transformers.LogitsProcessorList` list object that contains all relevant\u001b[0m\n",
       "    \u001b[0;36m_get_logits_warper\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mThis class returns a :obj:`~transformers.LogitsProcessorList` list object that contains all relevant\u001b[0m\n",
       "    \u001b[0;36m_get_name\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30m\u001b[0m\n",
       "    \u001b[0;36m_get_pad_token_id\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30m\u001b[0m\n",
       "    \u001b[0;36m_get_resized_embeddings\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mBuild a resized Embedding Module from a provided token Embedding Module. Increasing the size will add newly\u001b[0m\n",
       "    \u001b[0;36m_init_weights\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mInitialize the weights \u001b[0m\n",
       "    \u001b[0;36m_load_from_state_dict\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mCopies parameters and buffers from :attr:`state_dict` into only\u001b[0m\n",
       "    \u001b[0;36m_named_members\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mHelper method for yielding various names + members of modules.\u001b[0m\n",
       "    \u001b[0;36m_prepare_attention_mask_for_generation\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30m\u001b[0m\n",
       "    \u001b[0;36m_prepare_decoder_input_ids_for_generation\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30m\u001b[0m\n",
       "    \u001b[0;36m_prepare_encoder_decoder_kwargs_for_generation\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30m\u001b[0m\n",
       "    \u001b[0;36m_prepare_input_ids_for_generation\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30m\u001b[0m\n",
       "    \u001b[0;36m_prune_heads\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mPrunes heads of the model. heads_to_prune: dict of {layer_num: list of heads to prune in this layer} See base\u001b[0m\n",
       "    \u001b[0;36m_register_load_state_dict_pre_hook\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mThese hooks will be called with arguments: `state_dict`, `prefix`,\u001b[0m\n",
       "    \u001b[0;36m_register_state_dict_hook\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mThese hooks will be called with arguments: `self`, `state_dict`,\u001b[0m\n",
       "    \u001b[0;36m_replicate_for_data_parallel\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30m\u001b[0m\n",
       "    \u001b[0;36m_resize_token_embeddings\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30m\u001b[0m\n",
       "    \u001b[0;36m_save_to_state_dict\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mSaves module state to `destination` dictionary, containing a state\u001b[0m\n",
       "    \u001b[0;36m_slow_forward\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30m\u001b[0m\n",
       "    \u001b[0;36m_tie_or_clone_weights\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mTie or clone module weights depending of whether we are using TorchScript or not\u001b[0m\n",
       "    \u001b[0;36madd_memory_hooks\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mAdd a memory hook before and after each sub-module forward pass to record increase in memory consumption.\u001b[0m\n",
       "    \u001b[0;36madd_module\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mAdds a child module to the current module.\u001b[0m\n",
       "    \u001b[0;36madjust_logits_during_generation\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mImplement in subclasses of :class:`~transformers.PreTrainedModel` for custom behavior to adjust the logits in\u001b[0m\n",
       "    \u001b[0;36mapply\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mApplies ``fn`` recursively to every submodule (as returned by ``.children()``)\u001b[0m\n",
       "    \u001b[0;36mbeam_sample\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mGenerates sequences for models with a language modeling head using beam search with multinomial sampling.\u001b[0m\n",
       "    \u001b[0;36mbeam_search\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mGenerates sequences for models with a language modeling head using beam search decoding.\u001b[0m\n",
       "    \u001b[0;36mbfloat16\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mCasts all floating point parameters and buffers to ``bfloat16`` datatype.\u001b[0m\n",
       "    \u001b[0;36mbuffers\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mReturns an iterator over module buffers.\u001b[0m\n",
       "    \u001b[0;36mchildren\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mReturns an iterator over immediate children modules.\u001b[0m\n",
       "    \u001b[0;36mcpu\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mMoves all model parameters and buffers to the CPU.\u001b[0m\n",
       "    \u001b[0;36mcuda\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mMoves all model parameters and buffers to the GPU.\u001b[0m\n",
       "    \u001b[0;36mdouble\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mCasts all floating point parameters and buffers to ``double`` datatype.\u001b[0m\n",
       "    \u001b[0;36mestimate_tokens\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mHelper function to estimate the total number of tokens from the model inputs.\u001b[0m\n",
       "    \u001b[0;36meval\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mSets the module in evaluation mode.\u001b[0m\n",
       "    \u001b[0;36mextra_repr\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mSet the extra representation of the module\u001b[0m\n",
       "    \u001b[0;36mfloat\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mCasts all floating point parameters and buffers to float datatype.\u001b[0m\n",
       "    \u001b[0;36mfloating_point_ops\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mGet number of (optionally, non-embeddings) floating-point operations for the forward and backward passes of a\u001b[0m\n",
       "    \u001b[0;36mforward\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mThe :class:`~transformers.BertModel` forward method, overrides the :func:`__call__` special method.\u001b[0m\n",
       "    \u001b[0;36mgenerate\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mGenerates sequences for models with a language modeling head. The method currently supports greedy decoding,\u001b[0m\n",
       "    \u001b[0;36mget_extended_attention_mask\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mMakes broadcastable attention and causal masks so that future and masked tokens are ignored.\u001b[0m\n",
       "    \u001b[0;36mget_head_mask\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mPrepare the head mask if needed.\u001b[0m\n",
       "    \u001b[0;36mget_input_embeddings\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mReturns the model's input embeddings.\u001b[0m\n",
       "    \u001b[0;36mget_output_embeddings\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mReturns the model's output embeddings.\u001b[0m\n",
       "    \u001b[0;36mgreedy_search\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mGenerates sequences for models with a language modeling head using greedy decoding.\u001b[0m\n",
       "    \u001b[0;36mhalf\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mCasts all floating point parameters and buffers to ``half`` datatype.\u001b[0m\n",
       "    \u001b[0;36minit_weights\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mInitializes and prunes weights if needed.\u001b[0m\n",
       "    \u001b[0;36minvert_attention_mask\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mInvert an attention mask (e.g., switches 0. and 1.).\u001b[0m\n",
       "    \u001b[0;36mload_state_dict\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mCopies parameters and buffers from :attr:`state_dict` into\u001b[0m\n",
       "    \u001b[0;36mload_tf_weights\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mLoad tf checkpoints in a pytorch model.\u001b[0m\n",
       "    \u001b[0;36mmodules\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mReturns an iterator over all modules in the network.\u001b[0m\n",
       "    \u001b[0;36mnamed_buffers\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mReturns an iterator over module buffers, yielding both the\u001b[0m\n",
       "    \u001b[0;36mnamed_children\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mReturns an iterator over immediate children modules, yielding both\u001b[0m\n",
       "    \u001b[0;36mnamed_modules\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mReturns an iterator over all modules in the network, yielding\u001b[0m\n",
       "    \u001b[0;36mnamed_parameters\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mReturns an iterator over module parameters, yielding both the\u001b[0m\n",
       "    \u001b[0;36mnum_parameters\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mGet number of (optionally, trainable or non-embeddings) parameters in the module.\u001b[0m\n",
       "    \u001b[0;36mparameters\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mReturns an iterator over module parameters.\u001b[0m\n",
       "    \u001b[0;36mprepare_inputs_for_generation\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mImplement in subclasses of :class:`~transformers.PreTrainedModel` for custom behavior to prepare inputs in the\u001b[0m\n",
       "    \u001b[0;36mprune_heads\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mPrunes heads of the base model.\u001b[0m\n",
       "    \u001b[0;36mregister_backward_hook\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mRegisters a backward hook on the module.\u001b[0m\n",
       "    \u001b[0;36mregister_buffer\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mAdds a buffer to the module.\u001b[0m\n",
       "    \u001b[0;36mregister_forward_hook\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mRegisters a forward hook on the module.\u001b[0m\n",
       "    \u001b[0;36mregister_forward_pre_hook\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mRegisters a forward pre-hook on the module.\u001b[0m\n",
       "    \u001b[0;36mregister_parameter\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mAdds a parameter to the module.\u001b[0m\n",
       "    \u001b[0;36mrequires_grad_\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mChange if autograd should record operations on parameters in this\u001b[0m\n",
       "    \u001b[0;36mreset_memory_hooks_state\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mReset the :obj:`mem_rss_diff` attribute of each module (see\u001b[0m\n",
       "    \u001b[0;36mresize_token_embeddings\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mResizes input token embeddings matrix of the model if :obj:`new_num_tokens != config.vocab_size`.\u001b[0m\n",
       "    \u001b[0;36msample\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mGenerates sequences for models with a language modeling head using multinomial sampling.\u001b[0m\n",
       "    \u001b[0;36msave_pretrained\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mSave a model and its configuration file to a directory, so that it can be re-loaded using the\u001b[0m\n",
       "    \u001b[0;36mset_input_embeddings\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mSet model's input embeddings.\u001b[0m\n",
       "    \u001b[0;36mshare_memory\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30m\u001b[0m\n",
       "    \u001b[0;36mstate_dict\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mReturns a dictionary containing a whole state of the module.\u001b[0m\n",
       "    \u001b[0;36mtie_weights\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mTie the weights between the input embeddings and the output embeddings.\u001b[0m\n",
       "    \u001b[0;36mto\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mMoves and/or casts the parameters and buffers.\u001b[0m\n",
       "    \u001b[0;36mtrain\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mSets the module in training mode.\u001b[0m\n",
       "    \u001b[0;36mtype\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mCasts all parameters and buffers to :attr:`dst_type`.\u001b[0m\n",
       "    \u001b[0;36mzero_grad\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30mSets gradients of all model parameters to zero.\u001b[0m\n",
       "\u001b[0;33mmagic:\u001b[0m\n",
       "    \u001b[0;36m__call__\u001b[0m\u001b[0;36m: \u001b[0m\u001b[1;30m\u001b[0m"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdir(mo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start_times = dict()\n",
    "end_times = dict()\n",
    "\n",
    "def log_start_builder(name):\n",
    "    def log_start(module, m_in):\n",
    "        start_times[f'{name}:{module.__class__.__name__}'] = time.perf_counter()\n",
    "    return log_start\n",
    "def log_end_builder(name):\n",
    "    def log_end(module, m_in, m_out):\n",
    "        end_times[f'{name}:{module.__class__.__name__}'] = time.perf_counter()\n",
    "#         print(name, module.__class__.__name__, 'end', time.perf_counter())\n",
    "    return log_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " BertModel\n",
      "embeddings BertEmbeddings\n",
      "embeddings.word_embeddings Embedding\n",
      "embeddings.position_embeddings Embedding\n",
      "embeddings.token_type_embeddings Embedding\n",
      "embeddings.LayerNorm LayerNorm\n",
      "embeddings.dropout Dropout\n",
      "encoder BertEncoder\n",
      "encoder.layer ModuleList\n",
      "encoder.layer.0 BertLayer\n",
      "encoder.layer.0.attention BertAttention\n",
      "encoder.layer.0.attention.self BertSelfAttention\n",
      "encoder.layer.0.attention.self.query Linear\n",
      "encoder.layer.0.attention.self.key Linear\n",
      "encoder.layer.0.attention.self.value Linear\n",
      "encoder.layer.0.attention.self.dropout Dropout\n",
      "encoder.layer.0.attention.output BertSelfOutput\n",
      "encoder.layer.0.attention.output.dense Linear\n",
      "encoder.layer.0.attention.output.LayerNorm LayerNorm\n",
      "encoder.layer.0.attention.output.dropout Dropout\n",
      "encoder.layer.0.intermediate BertIntermediate\n",
      "encoder.layer.0.intermediate.dense Linear\n",
      "encoder.layer.0.output BertOutput\n",
      "encoder.layer.0.output.dense Linear\n",
      "encoder.layer.0.output.LayerNorm LayerNorm\n",
      "encoder.layer.0.output.dropout Dropout\n",
      "encoder.layer.1 BertLayer\n",
      "encoder.layer.1.attention BertAttention\n",
      "encoder.layer.1.attention.self BertSelfAttention\n",
      "encoder.layer.1.attention.self.query Linear\n",
      "encoder.layer.1.attention.self.key Linear\n",
      "encoder.layer.1.attention.self.value Linear\n",
      "encoder.layer.1.attention.self.dropout Dropout\n",
      "encoder.layer.1.attention.output BertSelfOutput\n",
      "encoder.layer.1.attention.output.dense Linear\n",
      "encoder.layer.1.attention.output.LayerNorm LayerNorm\n",
      "encoder.layer.1.attention.output.dropout Dropout\n",
      "encoder.layer.1.intermediate BertIntermediate\n",
      "encoder.layer.1.intermediate.dense Linear\n",
      "encoder.layer.1.output BertOutput\n",
      "encoder.layer.1.output.dense Linear\n",
      "encoder.layer.1.output.LayerNorm LayerNorm\n",
      "encoder.layer.1.output.dropout Dropout\n",
      "encoder.layer.2 BertLayer\n",
      "encoder.layer.2.attention BertAttention\n",
      "encoder.layer.2.attention.self BertSelfAttention\n",
      "encoder.layer.2.attention.self.query Linear\n",
      "encoder.layer.2.attention.self.key Linear\n",
      "encoder.layer.2.attention.self.value Linear\n",
      "encoder.layer.2.attention.self.dropout Dropout\n",
      "encoder.layer.2.attention.output BertSelfOutput\n",
      "encoder.layer.2.attention.output.dense Linear\n",
      "encoder.layer.2.attention.output.LayerNorm LayerNorm\n",
      "encoder.layer.2.attention.output.dropout Dropout\n",
      "encoder.layer.2.intermediate BertIntermediate\n",
      "encoder.layer.2.intermediate.dense Linear\n",
      "encoder.layer.2.output BertOutput\n",
      "encoder.layer.2.output.dense Linear\n",
      "encoder.layer.2.output.LayerNorm LayerNorm\n",
      "encoder.layer.2.output.dropout Dropout\n",
      "encoder.layer.3 BertLayer\n",
      "encoder.layer.3.attention BertAttention\n",
      "encoder.layer.3.attention.self BertSelfAttention\n",
      "encoder.layer.3.attention.self.query Linear\n",
      "encoder.layer.3.attention.self.key Linear\n",
      "encoder.layer.3.attention.self.value Linear\n",
      "encoder.layer.3.attention.self.dropout Dropout\n",
      "encoder.layer.3.attention.output BertSelfOutput\n",
      "encoder.layer.3.attention.output.dense Linear\n",
      "encoder.layer.3.attention.output.LayerNorm LayerNorm\n",
      "encoder.layer.3.attention.output.dropout Dropout\n",
      "encoder.layer.3.intermediate BertIntermediate\n",
      "encoder.layer.3.intermediate.dense Linear\n",
      "encoder.layer.3.output BertOutput\n",
      "encoder.layer.3.output.dense Linear\n",
      "encoder.layer.3.output.LayerNorm LayerNorm\n",
      "encoder.layer.3.output.dropout Dropout\n",
      "encoder.layer.4 BertLayer\n",
      "encoder.layer.4.attention BertAttention\n",
      "encoder.layer.4.attention.self BertSelfAttention\n",
      "encoder.layer.4.attention.self.query Linear\n",
      "encoder.layer.4.attention.self.key Linear\n",
      "encoder.layer.4.attention.self.value Linear\n",
      "encoder.layer.4.attention.self.dropout Dropout\n",
      "encoder.layer.4.attention.output BertSelfOutput\n",
      "encoder.layer.4.attention.output.dense Linear\n",
      "encoder.layer.4.attention.output.LayerNorm LayerNorm\n",
      "encoder.layer.4.attention.output.dropout Dropout\n",
      "encoder.layer.4.intermediate BertIntermediate\n",
      "encoder.layer.4.intermediate.dense Linear\n",
      "encoder.layer.4.output BertOutput\n",
      "encoder.layer.4.output.dense Linear\n",
      "encoder.layer.4.output.LayerNorm LayerNorm\n",
      "encoder.layer.4.output.dropout Dropout\n",
      "encoder.layer.5 BertLayer\n",
      "encoder.layer.5.attention BertAttention\n",
      "encoder.layer.5.attention.self BertSelfAttention\n",
      "encoder.layer.5.attention.self.query Linear\n",
      "encoder.layer.5.attention.self.key Linear\n",
      "encoder.layer.5.attention.self.value Linear\n",
      "encoder.layer.5.attention.self.dropout Dropout\n",
      "encoder.layer.5.attention.output BertSelfOutput\n",
      "encoder.layer.5.attention.output.dense Linear\n",
      "encoder.layer.5.attention.output.LayerNorm LayerNorm\n",
      "encoder.layer.5.attention.output.dropout Dropout\n",
      "encoder.layer.5.intermediate BertIntermediate\n",
      "encoder.layer.5.intermediate.dense Linear\n",
      "encoder.layer.5.output BertOutput\n",
      "encoder.layer.5.output.dense Linear\n",
      "encoder.layer.5.output.LayerNorm LayerNorm\n",
      "encoder.layer.5.output.dropout Dropout\n",
      "encoder.layer.6 BertLayer\n",
      "encoder.layer.6.attention BertAttention\n",
      "encoder.layer.6.attention.self BertSelfAttention\n",
      "encoder.layer.6.attention.self.query Linear\n",
      "encoder.layer.6.attention.self.key Linear\n",
      "encoder.layer.6.attention.self.value Linear\n",
      "encoder.layer.6.attention.self.dropout Dropout\n",
      "encoder.layer.6.attention.output BertSelfOutput\n",
      "encoder.layer.6.attention.output.dense Linear\n",
      "encoder.layer.6.attention.output.LayerNorm LayerNorm\n",
      "encoder.layer.6.attention.output.dropout Dropout\n",
      "encoder.layer.6.intermediate BertIntermediate\n",
      "encoder.layer.6.intermediate.dense Linear\n",
      "encoder.layer.6.output BertOutput\n",
      "encoder.layer.6.output.dense Linear\n",
      "encoder.layer.6.output.LayerNorm LayerNorm\n",
      "encoder.layer.6.output.dropout Dropout\n",
      "encoder.layer.7 BertLayer\n",
      "encoder.layer.7.attention BertAttention\n",
      "encoder.layer.7.attention.self BertSelfAttention\n",
      "encoder.layer.7.attention.self.query Linear\n",
      "encoder.layer.7.attention.self.key Linear\n",
      "encoder.layer.7.attention.self.value Linear\n",
      "encoder.layer.7.attention.self.dropout Dropout\n",
      "encoder.layer.7.attention.output BertSelfOutput\n",
      "encoder.layer.7.attention.output.dense Linear\n",
      "encoder.layer.7.attention.output.LayerNorm LayerNorm\n",
      "encoder.layer.7.attention.output.dropout Dropout\n",
      "encoder.layer.7.intermediate BertIntermediate\n",
      "encoder.layer.7.intermediate.dense Linear\n",
      "encoder.layer.7.output BertOutput\n",
      "encoder.layer.7.output.dense Linear\n",
      "encoder.layer.7.output.LayerNorm LayerNorm\n",
      "encoder.layer.7.output.dropout Dropout\n",
      "encoder.layer.8 BertLayer\n",
      "encoder.layer.8.attention BertAttention\n",
      "encoder.layer.8.attention.self BertSelfAttention\n",
      "encoder.layer.8.attention.self.query Linear\n",
      "encoder.layer.8.attention.self.key Linear\n",
      "encoder.layer.8.attention.self.value Linear\n",
      "encoder.layer.8.attention.self.dropout Dropout\n",
      "encoder.layer.8.attention.output BertSelfOutput\n",
      "encoder.layer.8.attention.output.dense Linear\n",
      "encoder.layer.8.attention.output.LayerNorm LayerNorm\n",
      "encoder.layer.8.attention.output.dropout Dropout\n",
      "encoder.layer.8.intermediate BertIntermediate\n",
      "encoder.layer.8.intermediate.dense Linear\n",
      "encoder.layer.8.output BertOutput\n",
      "encoder.layer.8.output.dense Linear\n",
      "encoder.layer.8.output.LayerNorm LayerNorm\n",
      "encoder.layer.8.output.dropout Dropout\n",
      "encoder.layer.9 BertLayer\n",
      "encoder.layer.9.attention BertAttention\n",
      "encoder.layer.9.attention.self BertSelfAttention\n",
      "encoder.layer.9.attention.self.query Linear\n",
      "encoder.layer.9.attention.self.key Linear\n",
      "encoder.layer.9.attention.self.value Linear\n",
      "encoder.layer.9.attention.self.dropout Dropout\n",
      "encoder.layer.9.attention.output BertSelfOutput\n",
      "encoder.layer.9.attention.output.dense Linear\n",
      "encoder.layer.9.attention.output.LayerNorm LayerNorm\n",
      "encoder.layer.9.attention.output.dropout Dropout\n",
      "encoder.layer.9.intermediate BertIntermediate\n",
      "encoder.layer.9.intermediate.dense Linear\n",
      "encoder.layer.9.output BertOutput\n",
      "encoder.layer.9.output.dense Linear\n",
      "encoder.layer.9.output.LayerNorm LayerNorm\n",
      "encoder.layer.9.output.dropout Dropout\n",
      "encoder.layer.10 BertLayer\n",
      "encoder.layer.10.attention BertAttention\n",
      "encoder.layer.10.attention.self BertSelfAttention\n",
      "encoder.layer.10.attention.self.query Linear\n",
      "encoder.layer.10.attention.self.key Linear\n",
      "encoder.layer.10.attention.self.value Linear\n",
      "encoder.layer.10.attention.self.dropout Dropout\n",
      "encoder.layer.10.attention.output BertSelfOutput\n",
      "encoder.layer.10.attention.output.dense Linear\n",
      "encoder.layer.10.attention.output.LayerNorm LayerNorm\n",
      "encoder.layer.10.attention.output.dropout Dropout\n",
      "encoder.layer.10.intermediate BertIntermediate\n",
      "encoder.layer.10.intermediate.dense Linear\n",
      "encoder.layer.10.output BertOutput\n",
      "encoder.layer.10.output.dense Linear\n",
      "encoder.layer.10.output.LayerNorm LayerNorm\n",
      "encoder.layer.10.output.dropout Dropout\n",
      "encoder.layer.11 BertLayer\n",
      "encoder.layer.11.attention BertAttention\n",
      "encoder.layer.11.attention.self BertSelfAttention\n",
      "encoder.layer.11.attention.self.query Linear\n",
      "encoder.layer.11.attention.self.key Linear\n",
      "encoder.layer.11.attention.self.value Linear\n",
      "encoder.layer.11.attention.self.dropout Dropout\n",
      "encoder.layer.11.attention.output BertSelfOutput\n",
      "encoder.layer.11.attention.output.dense Linear\n",
      "encoder.layer.11.attention.output.LayerNorm LayerNorm\n",
      "encoder.layer.11.attention.output.dropout Dropout\n",
      "encoder.layer.11.intermediate BertIntermediate\n",
      "encoder.layer.11.intermediate.dense Linear\n",
      "encoder.layer.11.output BertOutput\n",
      "encoder.layer.11.output.dense Linear\n",
      "encoder.layer.11.output.LayerNorm LayerNorm\n",
      "encoder.layer.11.output.dropout Dropout\n",
      "pooler BertPooler\n",
      "pooler.dense Linear\n",
      "pooler.activation Tanh\n"
     ]
    }
   ],
   "source": [
    "for name, module in mo.named_modules():\n",
    "    print(name, module.__class__.__name__)\n",
    "    module.register_forward_pre_hook(log_start_builder(name))\n",
    "    module.register_forward_hook(log_end_builder(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:191: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  position_ids = self.position_ids[:, :seq_length]\n",
      "/Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:1673: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  input_tensor.shape == tensor_shape for input_tensor in input_tensors\n"
     ]
    }
   ],
   "source": [
    "trace = torch.jit.trace(model, inputs) # 1605233162.4006221"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":BertModel, 235.874 ms, 26.851236988, 27.087110943\n",
      "embeddings:BertEmbeddings, 0.628 ms, 26.851487946, 26.852115499\n",
      "embeddings.word_embeddings:Embedding, 0.106 ms, 26.85152459, 26.851630708\n",
      "embeddings.position_embeddings:Embedding, 0.088 ms, 26.851645324, 26.851733078\n",
      "embeddings.token_type_embeddings:Embedding, 0.063 ms, 26.851745004, 26.851808246\n",
      "embeddings.LayerNorm:LayerNorm, 0.100 ms, 26.851948506, 26.852048253\n",
      "embeddings.dropout:Dropout, 0.030 ms, 26.852068033, 26.852097813\n",
      "encoder:BertEncoder, 234.649 ms, 26.852132515, 27.086781794\n",
      "encoder.layer.0:BertLayer, 23.709 ms, 26.852157026, 26.875865759\n",
      "encoder.layer.0.attention:BertAttention, 8.718 ms, 26.852171108, 26.860889477\n",
      "encoder.layer.0.attention.self:BertSelfAttention, 6.926 ms, 26.852183936, 26.85911019\n",
      "encoder.layer.0.attention.self.query:Linear, 1.704 ms, 26.852196923, 26.85390104\n",
      "encoder.layer.0.attention.self.key:Linear, 1.708 ms, 26.853926095, 26.855634351\n",
      "encoder.layer.0.attention.self.value:Linear, 1.500 ms, 26.855662104, 26.857162074\n",
      "encoder.layer.0.attention.self.dropout:Dropout, 0.028 ms, 26.858578705, 26.858606567\n",
      "encoder.layer.0.attention.output:BertSelfOutput, 1.745 ms, 26.85912569, 26.860870356\n",
      "encoder.layer.0.attention.output.dense:Linear, 1.450 ms, 26.85913632, 26.860586278\n",
      "encoder.layer.0.attention.output.dropout:Dropout, 0.038 ms, 26.860612926, 26.860651173\n",
      "encoder.layer.0.attention.output.LayerNorm:LayerNorm, 0.112 ms, 26.86073854, 26.860850406\n",
      "encoder.layer.0.intermediate:BertIntermediate, 9.634 ms, 26.861027488, 26.870661602\n",
      "encoder.layer.0.intermediate.dense:Linear, 5.930 ms, 26.861042134, 26.866972612\n",
      "encoder.layer.0.output:BertOutput, 5.150 ms, 26.870690288, 26.875840565\n",
      "encoder.layer.0.output.dense:Linear, 4.840 ms, 26.870707514, 26.875547987\n",
      "encoder.layer.0.output.dropout:Dropout, 0.041 ms, 26.875577857, 26.875619187\n",
      "encoder.layer.0.output.LayerNorm:LayerNorm, 0.112 ms, 26.875706531, 26.875818567\n",
      "encoder.layer.1:BertLayer, 20.536 ms, 26.875882376, 26.896418442\n",
      "encoder.layer.1.attention:BertAttention, 8.651 ms, 26.875899979, 26.884550951\n",
      "encoder.layer.1.attention.self:BertSelfAttention, 7.336 ms, 26.875915202, 26.883250881\n",
      "encoder.layer.1.attention.self.query:Linear, 1.748 ms, 26.875930685, 26.877679056\n",
      "encoder.layer.1.attention.self.key:Linear, 1.707 ms, 26.877707323, 26.879414011\n",
      "encoder.layer.1.attention.self.value:Linear, 1.646 ms, 26.879442845, 26.881089113\n",
      "encoder.layer.1.attention.self.dropout:Dropout, 0.029 ms, 26.882621072, 26.88265032\n",
      "encoder.layer.1.attention.output:BertSelfOutput, 1.267 ms, 26.883271025, 26.884537881\n",
      "encoder.layer.1.attention.output.dense:Linear, 1.029 ms, 26.883282795, 26.884311568\n",
      "encoder.layer.1.attention.output.dropout:Dropout, 0.027 ms, 26.884327487, 26.884354983\n",
      "encoder.layer.1.attention.output.LayerNorm:LayerNorm, 0.091 ms, 26.884430609, 26.884522087\n",
      "encoder.layer.1.intermediate:BertIntermediate, 7.526 ms, 26.884661255, 26.892187401\n",
      "encoder.layer.1.intermediate.dense:Linear, 4.067 ms, 26.884671341, 26.888738481\n",
      "encoder.layer.1.output:BertOutput, 4.182 ms, 26.892215305, 26.896397394\n",
      "encoder.layer.1.output.dense:Linear, 3.869 ms, 26.892232128, 26.896101003\n",
      "encoder.layer.1.output.dropout:Dropout, 0.041 ms, 26.896129605, 26.896170892\n",
      "encoder.layer.1.output.LayerNorm:LayerNorm, 0.111 ms, 26.896267246, 26.896378414\n",
      "encoder.layer.2:BertLayer, 20.366 ms, 26.896439767, 26.916805635\n",
      "encoder.layer.2.attention:BertAttention, 6.128 ms, 26.896456438, 26.902584224\n",
      "encoder.layer.2.attention.self:BertSelfAttention, 4.917 ms, 26.896469633, 26.901386421\n",
      "encoder.layer.2.attention.self.query:Linear, 1.415 ms, 26.896482192, 26.897896869\n",
      "encoder.layer.2.attention.self.key:Linear, 0.922 ms, 26.897919835, 26.898841895\n",
      "encoder.layer.2.attention.self.value:Linear, 0.868 ms, 26.898855761, 26.899723757\n",
      "encoder.layer.2.attention.self.dropout:Dropout, 0.033 ms, 26.900972637, 26.901005387\n",
      "encoder.layer.2.attention.output:BertSelfOutput, 1.173 ms, 26.901399717, 26.902572318\n",
      "encoder.layer.2.attention.output.dense:Linear, 0.954 ms, 26.901410119, 26.902363665\n",
      "encoder.layer.2.attention.output.dropout:Dropout, 0.022 ms, 26.90237736, 26.902399086\n",
      "encoder.layer.2.attention.output.LayerNorm:LayerNorm, 0.089 ms, 26.902469518, 26.902558342\n",
      "encoder.layer.2.intermediate:BertIntermediate, 9.238 ms, 26.902689598, 26.911927219\n",
      "encoder.layer.2.intermediate.dense:Linear, 5.141 ms, 26.902700165, 26.907841013\n",
      "encoder.layer.2.output:BertOutput, 4.826 ms, 26.911965331, 26.916791777\n",
      "encoder.layer.2.output.dense:Linear, 4.555 ms, 26.911988154, 26.916543172\n",
      "encoder.layer.2.output.dropout:Dropout, 0.035 ms, 26.916566714, 26.916601702\n",
      "encoder.layer.2.output.LayerNorm:LayerNorm, 0.094 ms, 26.916679987, 26.916774424\n",
      "encoder.layer.3:BertLayer, 16.761 ms, 26.916821622, 26.93358302\n",
      "encoder.layer.3.attention:BertAttention, 5.585 ms, 26.916834403, 26.922419201\n",
      "encoder.layer.3.attention.self:BertSelfAttention, 4.411 ms, 26.916843484, 26.921254795\n",
      "encoder.layer.3.attention.self.query:Linear, 0.917 ms, 26.916852148, 26.917768961\n",
      "encoder.layer.3.attention.self.key:Linear, 0.868 ms, 26.91778316, 26.918651429\n",
      "encoder.layer.3.attention.self.value:Linear, 1.170 ms, 26.918665541, 26.919835907\n",
      "encoder.layer.3.attention.self.dropout:Dropout, 0.024 ms, 26.920938535, 26.920962665\n",
      "encoder.layer.3.attention.output:BertSelfOutput, 1.139 ms, 26.921267568, 26.922407068\n",
      "encoder.layer.3.attention.output.dense:Linear, 0.926 ms, 26.921277255, 26.922202906\n",
      "encoder.layer.3.attention.output.dropout:Dropout, 0.020 ms, 26.922217189, 26.922237632\n",
      "encoder.layer.3.attention.output.LayerNorm:LayerNorm, 0.088 ms, 26.922305017, 26.922392766\n",
      "encoder.layer.3.intermediate:BertIntermediate, 7.137 ms, 26.922524207, 26.929661606\n",
      "encoder.layer.3.intermediate.dense:Linear, 3.563 ms, 26.922534449, 26.926097296\n",
      "encoder.layer.3.output:BertOutput, 3.880 ms, 26.929687664, 26.933567461\n",
      "encoder.layer.3.output.dense:Linear, 3.581 ms, 26.929703489, 26.933284751\n",
      "encoder.layer.3.output.dropout:Dropout, 0.041 ms, 26.933315454, 26.933356255\n",
      "encoder.layer.3.output.LayerNorm:LayerNorm, 0.111 ms, 26.933440019, 26.933551223\n",
      "encoder.layer.4:BertLayer, 17.760 ms, 26.933597416, 26.951357509\n",
      "encoder.layer.4.attention:BertAttention, 6.405 ms, 26.933610065, 26.940015049\n",
      "encoder.layer.4.attention.self:BertSelfAttention, 5.207 ms, 26.933618694, 26.938825907\n",
      "encoder.layer.4.attention.self.query:Linear, 0.924 ms, 26.933627366, 26.934551278\n",
      "encoder.layer.4.attention.self.key:Linear, 1.064 ms, 26.934565782, 26.935630181\n",
      "encoder.layer.4.attention.self.value:Linear, 1.540 ms, 26.935648054, 26.937188217\n",
      "encoder.layer.4.attention.self.dropout:Dropout, 0.025 ms, 26.938490955, 26.938515812\n",
      "encoder.layer.4.attention.output:BertSelfOutput, 1.163 ms, 26.938839946, 26.940003046\n",
      "encoder.layer.4.attention.output.dense:Linear, 0.945 ms, 26.938849765, 26.939794728\n",
      "encoder.layer.4.attention.output.dropout:Dropout, 0.020 ms, 26.939810161, 26.939830647\n",
      "encoder.layer.4.attention.output.LayerNorm:LayerNorm, 0.088 ms, 26.939898778, 26.939986929\n",
      "encoder.layer.4.intermediate:BertIntermediate, 7.309 ms, 26.940118003, 26.947427335\n",
      "encoder.layer.4.intermediate.dense:Linear, 3.858 ms, 26.940128306, 26.943986236\n",
      "encoder.layer.4.output:BertOutput, 3.888 ms, 26.94745448, 26.951342331\n",
      "encoder.layer.4.output.dense:Linear, 3.635 ms, 26.947471935, 26.9511065\n",
      "encoder.layer.4.output.dropout:Dropout, 0.033 ms, 26.951128597, 26.951162\n",
      "encoder.layer.4.output.LayerNorm:LayerNorm, 0.093 ms, 26.951234897, 26.951327602\n",
      "encoder.layer.5:BertLayer, 19.409 ms, 26.951374145, 26.970782767\n",
      "encoder.layer.5.attention:BertAttention, 5.428 ms, 26.951386051, 26.956813815\n",
      "encoder.layer.5.attention.self:BertSelfAttention, 4.264 ms, 26.951394329, 26.955658431\n",
      "encoder.layer.5.attention.self.query:Linear, 0.921 ms, 26.951402763, 26.952324009\n",
      "encoder.layer.5.attention.self.key:Linear, 1.024 ms, 26.952337787, 26.953361875\n",
      "encoder.layer.5.attention.self.value:Linear, 0.907 ms, 26.953378395, 26.954285166\n",
      "encoder.layer.5.attention.self.dropout:Dropout, 0.024 ms, 26.95535254, 26.95537641\n",
      "encoder.layer.5.attention.output:BertSelfOutput, 1.130 ms, 26.955671134, 26.956801461\n",
      "encoder.layer.5.attention.output.dense:Linear, 0.919 ms, 26.9556804, 26.956599892\n",
      "encoder.layer.5.attention.output.dropout:Dropout, 0.022 ms, 26.956613158, 26.956635311\n",
      "encoder.layer.5.attention.output.LayerNorm:LayerNorm, 0.088 ms, 26.956699622, 26.956787502\n",
      "encoder.layer.5.intermediate:BertIntermediate, 8.278 ms, 26.956916685, 26.96519505\n",
      "encoder.layer.5.intermediate.dense:Linear, 4.071 ms, 26.956926787, 26.960997856\n",
      "encoder.layer.5.output:BertOutput, 5.533 ms, 26.965225405, 26.970758506\n",
      "encoder.layer.5.output.dense:Linear, 5.198 ms, 26.965243532, 26.970441531\n",
      "encoder.layer.5.output.dropout:Dropout, 0.046 ms, 26.970472181, 26.970518372\n",
      "encoder.layer.5.output.LayerNorm:LayerNorm, 0.118 ms, 26.97061741, 26.970735659\n",
      "encoder.layer.6:BertLayer, 21.133 ms, 26.970811801, 26.991944545\n",
      "encoder.layer.6.attention:BertAttention, 8.465 ms, 26.970830209, 26.979295081\n",
      "encoder.layer.6.attention.self:BertSelfAttention, 6.715 ms, 26.970843647, 26.977558157\n",
      "encoder.layer.6.attention.self.query:Linear, 1.509 ms, 26.970857985, 26.972367207\n",
      "encoder.layer.6.attention.self.key:Linear, 1.465 ms, 26.972389048, 26.973853956\n",
      "encoder.layer.6.attention.self.value:Linear, 1.455 ms, 26.973875398, 26.975330332\n",
      "encoder.layer.6.attention.self.dropout:Dropout, 0.041 ms, 26.97692251, 26.976963125\n",
      "encoder.layer.6.attention.output:BertSelfOutput, 1.705 ms, 26.977576534, 26.979281485\n",
      "encoder.layer.6.attention.output.dense:Linear, 1.442 ms, 26.977588452, 26.979030087\n",
      "encoder.layer.6.attention.output.dropout:Dropout, 0.031 ms, 26.979051357, 26.979082354\n",
      "encoder.layer.6.attention.output.LayerNorm:LayerNorm, 0.096 ms, 26.979167468, 26.97926304\n",
      "encoder.layer.6.intermediate:BertIntermediate, 8.904 ms, 26.979405468, 26.988309512\n",
      "encoder.layer.6.intermediate.dense:Linear, 4.760 ms, 26.979415973, 26.984176342\n",
      "encoder.layer.6.output:BertOutput, 3.589 ms, 26.988339014, 26.991928305\n",
      "encoder.layer.6.output.dense:Linear, 3.328 ms, 26.988357334, 26.991685648\n",
      "encoder.layer.6.output.dropout:Dropout, 0.033 ms, 26.991708714, 26.99174155\n",
      "encoder.layer.6.output.LayerNorm:LayerNorm, 0.096 ms, 26.991815215, 26.99191154\n",
      "encoder.layer.7:BertLayer, 17.079 ms, 26.991960029, 27.009038651\n",
      "encoder.layer.7.attention:BertAttention, 5.792 ms, 26.99197218, 26.997764279\n",
      "encoder.layer.7.attention.self:BertSelfAttention, 4.308 ms, 26.991980574, 26.996288972\n",
      "encoder.layer.7.attention.self.query:Linear, 1.132 ms, 26.991988755, 26.993120327\n",
      "encoder.layer.7.attention.self.key:Linear, 0.891 ms, 26.99313586, 26.994027242\n",
      "encoder.layer.7.attention.self.value:Linear, 0.862 ms, 26.994041704, 26.994904086\n",
      "encoder.layer.7.attention.self.dropout:Dropout, 0.026 ms, 26.995972202, 26.995997897\n",
      "encoder.layer.7.attention.output:BertSelfOutput, 1.449 ms, 26.996301728, 26.997751095\n",
      "encoder.layer.7.attention.output.dense:Linear, 1.181 ms, 26.996310483, 26.997491777\n",
      "encoder.layer.7.attention.output.dropout:Dropout, 0.031 ms, 26.997513519, 26.997544569\n",
      "encoder.layer.7.attention.output.LayerNorm:LayerNorm, 0.108 ms, 26.997625182, 26.997733222\n",
      "encoder.layer.7.intermediate:BertIntermediate, 7.391 ms, 26.997870867, 27.005261637\n",
      "encoder.layer.7.intermediate.dense:Linear, 3.922 ms, 26.997881185, 27.001802688\n",
      "encoder.layer.7.output:BertOutput, 3.735 ms, 27.005289418, 27.009024271\n",
      "encoder.layer.7.output.dense:Linear, 3.478 ms, 27.00530718, 27.008785563\n",
      "encoder.layer.7.output.dropout:Dropout, 0.034 ms, 27.008806908, 27.008840572\n",
      "encoder.layer.7.output.LayerNorm:LayerNorm, 0.093 ms, 27.008915016, 27.00900777\n",
      "encoder.layer.8:BertLayer, 17.499 ms, 27.00905353, 27.026552541\n",
      "encoder.layer.8.attention:BertAttention, 6.603 ms, 27.00906561, 27.015668423\n",
      "encoder.layer.8.attention.self:BertSelfAttention, 4.630 ms, 27.009074306, 27.013704279\n",
      "encoder.layer.8.attention.self.query:Linear, 1.220 ms, 27.009082332, 27.010302373\n",
      "encoder.layer.8.attention.self.key:Linear, 0.904 ms, 27.010322658, 27.011226233\n",
      "encoder.layer.8.attention.self.value:Linear, 0.875 ms, 27.011241012, 27.012116311\n",
      "encoder.layer.8.attention.self.dropout:Dropout, 0.025 ms, 27.013240995, 27.013266309\n",
      "encoder.layer.8.attention.output:BertSelfOutput, 1.927 ms, 27.013724746, 27.015652003\n",
      "encoder.layer.8.attention.output.dense:Linear, 1.636 ms, 27.013738928, 27.015374594\n",
      "encoder.layer.8.attention.output.dropout:Dropout, 0.034 ms, 27.015397771, 27.015432058\n",
      "encoder.layer.8.attention.output.LayerNorm:LayerNorm, 0.116 ms, 27.015514225, 27.015630454\n",
      "encoder.layer.8.intermediate:BertIntermediate, 7.016 ms, 27.015775516, 27.022791529\n",
      "encoder.layer.8.intermediate.dense:Linear, 3.478 ms, 27.015786043, 27.019263696\n",
      "encoder.layer.8.output:BertOutput, 3.719 ms, 27.022818504, 27.026537959\n",
      "encoder.layer.8.output.dense:Linear, 3.444 ms, 27.022835367, 27.026279582\n",
      "encoder.layer.8.output.dropout:Dropout, 0.032 ms, 27.026301963, 27.026333646\n",
      "encoder.layer.8.output.LayerNorm:LayerNorm, 0.099 ms, 27.026422787, 27.026521306\n",
      "encoder.layer.9:BertLayer, 22.364 ms, 27.026567712, 27.048931918\n",
      "encoder.layer.9.attention:BertAttention, 6.942 ms, 27.026580121, 27.033521685\n",
      "encoder.layer.9.attention.self:BertSelfAttention, 5.054 ms, 27.026588623, 27.031642529\n",
      "encoder.layer.9.attention.self.query:Linear, 0.991 ms, 27.026596685, 27.027587511\n",
      "encoder.layer.9.attention.self.key:Linear, 0.878 ms, 27.027602556, 27.028480248\n",
      "encoder.layer.9.attention.self.value:Linear, 1.204 ms, 27.028492626, 27.029696597\n",
      "encoder.layer.9.attention.self.dropout:Dropout, 0.030 ms, 27.0310966, 27.031126755\n",
      "encoder.layer.9.attention.output:BertSelfOutput, 1.840 ms, 27.03166267, 27.033502753\n",
      "encoder.layer.9.attention.output.dense:Linear, 1.541 ms, 27.031677524, 27.033218453\n",
      "encoder.layer.9.attention.output.dropout:Dropout, 0.040 ms, 27.033246482, 27.033286449\n",
      "encoder.layer.9.attention.output.LayerNorm:LayerNorm, 0.107 ms, 27.033373431, 27.033480783\n",
      "encoder.layer.9.intermediate:BertIntermediate, 9.284 ms, 27.033658155, 27.042942245\n",
      "encoder.layer.9.intermediate.dense:Linear, 5.625 ms, 27.033673285, 27.039298222\n",
      "encoder.layer.9.output:BertOutput, 5.892 ms, 27.043019496, 27.048911436\n",
      "encoder.layer.9.output.dense:Linear, 5.597 ms, 27.043050114, 27.048646626\n",
      "encoder.layer.9.output.dropout:Dropout, 0.037 ms, 27.048678219, 27.04871568\n",
      "encoder.layer.9.output.LayerNorm:LayerNorm, 0.095 ms, 27.04879636, 27.048891514\n",
      "encoder.layer.10:BertLayer, 21.291 ms, 27.048948168, 27.070238852\n",
      "encoder.layer.10.attention:BertAttention, 8.667 ms, 27.048961214, 27.057628214\n",
      "encoder.layer.10.attention.self:BertSelfAttention, 6.623 ms, 27.048969962, 27.055593077\n",
      "encoder.layer.10.attention.self.query:Linear, 1.656 ms, 27.048978548, 27.050634111\n",
      "encoder.layer.10.attention.self.key:Linear, 1.315 ms, 27.050654032, 27.051969011\n",
      "encoder.layer.10.attention.self.value:Linear, 1.615 ms, 27.051992485, 27.053607589\n",
      "encoder.layer.10.attention.self.dropout:Dropout, 0.037 ms, 27.054995884, 27.055033348\n",
      "encoder.layer.10.attention.output:BertSelfOutput, 2.000 ms, 27.055615667, 27.057615347\n",
      "encoder.layer.10.attention.output.dense:Linear, 1.718 ms, 27.055631555, 27.057349209\n",
      "encoder.layer.10.attention.output.dropout:Dropout, 0.035 ms, 27.057374148, 27.057409216\n",
      "encoder.layer.10.attention.output.LayerNorm:LayerNorm, 0.098 ms, 27.057499099, 27.057597455\n",
      "encoder.layer.10.intermediate:BertIntermediate, 8.806 ms, 27.057738641, 27.066544895\n",
      "encoder.layer.10.intermediate.dense:Linear, 5.189 ms, 27.057749897, 27.062938461\n",
      "encoder.layer.10.output:BertOutput, 3.649 ms, 27.066573935, 27.070223045\n",
      "encoder.layer.10.output.dense:Linear, 3.393 ms, 27.066591725, 27.069984999\n",
      "encoder.layer.10.output.dropout:Dropout, 0.032 ms, 27.07000787, 27.070040001\n",
      "encoder.layer.10.output.LayerNorm:LayerNorm, 0.093 ms, 27.07011341, 27.070206614\n",
      "encoder.layer.11:BertLayer, 16.509 ms, 27.070253711, 27.086762394\n",
      "encoder.layer.11.attention:BertAttention, 5.587 ms, 27.070266596, 27.075853312\n",
      "encoder.layer.11.attention.self:BertSelfAttention, 4.212 ms, 27.07027518, 27.074487558\n",
      "encoder.layer.11.attention.self.query:Linear, 0.905 ms, 27.070283306, 27.071188057\n",
      "encoder.layer.11.attention.self.key:Linear, 1.001 ms, 27.071201286, 27.072201787\n",
      "encoder.layer.11.attention.self.value:Linear, 0.891 ms, 27.072218634, 27.073109708\n",
      "encoder.layer.11.attention.self.dropout:Dropout, 0.024 ms, 27.074172316, 27.074196128\n",
      "encoder.layer.11.attention.output:BertSelfOutput, 1.333 ms, 27.074500163, 27.075833349\n",
      "encoder.layer.11.attention.output.dense:Linear, 1.056 ms, 27.074509776, 27.075565907\n",
      "encoder.layer.11.attention.output.dropout:Dropout, 0.031 ms, 27.075586607, 27.075617813\n",
      "encoder.layer.11.attention.output.LayerNorm:LayerNorm, 0.114 ms, 27.075699118, 27.075813008\n",
      "encoder.layer.11.intermediate:BertIntermediate, 7.020 ms, 27.076005047, 27.083025445\n",
      "encoder.layer.11.intermediate.dense:Linear, 3.567 ms, 27.07602178, 27.079589209\n",
      "encoder.layer.11.output:BertOutput, 3.695 ms, 27.083051933, 27.086746644\n",
      "encoder.layer.11.output.dense:Linear, 3.439 ms, 27.083068841, 27.086508251\n",
      "encoder.layer.11.output.dropout:Dropout, 0.033 ms, 27.086529736, 27.086562465\n",
      "encoder.layer.11.output.LayerNorm:LayerNorm, 0.093 ms, 27.086636171, 27.086728926\n",
      "pooler:BertPooler, 0.297 ms, 27.086796633, 27.08709374\n",
      "pooler.dense:Linear, 0.213 ms, 27.086832736, 27.087045813\n",
      "pooler.activation:Tanh, 0.030 ms, 27.087057319, 27.087087081\n"
     ]
    }
   ],
   "source": [
    "for k, start in start_times.items():\n",
    "    print(f'{k}, {(end_times[k]-start)*1000:.3f} ms, {start}, {end_times[k]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"_name_or_path\": \"prajjwal1/bert-tiny\",\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"hidden_act\": \"gelu_fast\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 128,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 512,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 2,\n",
       "  \"num_hidden_layers\": 2,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"torchscript\": true,\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config=model.config\n",
    "config.hidden_act = 'gelu_fast'\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from transformers.activations import ACT2FN\n",
    "\n",
    "class BertIntermediate(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(config.hidden_size, config.intermediate_size)\n",
    "        if isinstance(config.hidden_act, str):\n",
    "            self.intermediate_act_fn = ACT2FN[config.hidden_act]\n",
    "        else:\n",
    "            self.intermediate_act_fn = config.hidden_act\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        hidden_states = self.dense(hidden_states)\n",
    "#         hidden_states = self.intermediate_act_fn(hidden_states)\n",
    "        return hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertIntermediate(\n",
       "  (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_model = BertIntermediate(config)\n",
    "input_len = 32\n",
    "input_states = torch.rand((input_len, config.hidden_size))\n",
    "fc_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_trace = torch.jit.trace(fc_model, input_states)\n",
    "fc_graph = fc_trace.inlined_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "graph(%self.1 : __torch__.BertIntermediate,\n",
       "      %input : Float(32:128, 128:1)):\n",
       "  %2 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"dense\"](%self.1)\n",
       "  %4 : int = prim::Constant[value=1](), scope: __module.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1674:0\n",
       "  %5 : Tensor = prim::GetAttr[name=\"bias\"](%2)\n",
       "  %6 : Tensor = prim::GetAttr[name=\"weight\"](%2)\n",
       "  %7 : Float(128:1, 512:128) = aten::t(%6), scope: __module.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1674:0\n",
       "  %8 : Float(32:512, 512:1) = aten::addmm(%5, %input, %7, %4, %4), scope: __module.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1674:0\n",
       "  return (%8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[%2 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"dense\"](%self.1),\n",
       " %4 : int = prim::Constant[value=1](), scope: __module.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1674:0,\n",
       " %5 : Tensor = prim::GetAttr[name=\"bias\"](%2),\n",
       " %6 : Tensor = prim::GetAttr[name=\"weight\"](%2),\n",
       " %7 : Float(128:1, 512:128) = aten::t(%6), scope: __module.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1674:0,\n",
       " %8 : Float(32:512, 512:1) = aten::addmm(%5, %input, %7, %4, %4), scope: __module.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1674:0]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(fc_graph.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['copyMetadata',\n",
       " 'debugName',\n",
       " 'inferTypeFrom',\n",
       " 'isCompleteTensor',\n",
       " 'node',\n",
       " 'offset',\n",
       " 'replaceAllUsesWith',\n",
       " 'requiresGrad',\n",
       " 'requires_grad',\n",
       " 'setDebugName',\n",
       " 'setType',\n",
       " 'setTypeAs',\n",
       " 'toIValue',\n",
       " 'type',\n",
       " 'unique',\n",
       " 'uses']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_in_nodes=list(fc_graph.inputs())\n",
    "[i for i in dir(fc_in_nodes[0]) if not i.startswith('__')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'input'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_in_nodes[1].debugName()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8 defined in (%8 : Float(32:512, 512:1) = aten::addmm(%5, %input, %7, %4, %4), scope: __module.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1674:0\n",
       " )]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(fc_graph.outputs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:191: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  position_ids = self.position_ids[:, :seq_length]\n",
      "/Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:1673: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  input_tensor.shape == tensor_shape for input_tensor in input_tensors\n"
     ]
    }
   ],
   "source": [
    "trace = torch.jit.trace(model, inputs)\n",
    "graph = trace.inlined_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "graph(%self.1 : __torch__.transformers.modeling_bert.___torch_mangle_124.BertModel,\n",
       "      %input_ids : Long(1:100, 100:1)):\n",
       "  %2 : __torch__.transformers.modeling_bert.___torch_mangle_123.BertPooler = prim::GetAttr[name=\"pooler\"](%self.1)\n",
       "  %3 : __torch__.transformers.modeling_bert.___torch_mangle_120.BertEncoder = prim::GetAttr[name=\"encoder\"](%self.1)\n",
       "  %4 : __torch__.transformers.modeling_bert.___torch_mangle_84.BertEmbeddings = prim::GetAttr[name=\"embeddings\"](%self.1)\n",
       "  %5 : int = prim::Constant[value=0]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:802:0\n",
       "  %6 : int = aten::size(%input_ids, %5) # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:802:0\n",
       "  %7 : Long() = prim::NumToTensor(%6)\n",
       "  %8 : int = aten::Int(%7)\n",
       "  %9 : int = aten::Int(%7)\n",
       "  %10 : int = prim::Constant[value=1]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:802:0\n",
       "  %11 : int = aten::size(%input_ids, %10) # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:802:0\n",
       "  %12 : Long() = prim::NumToTensor(%11)\n",
       "  %13 : int = aten::Int(%12)\n",
       "  %14 : int = aten::Int(%12)\n",
       "  %15 : int[] = prim::ListConstruct(%9, %14)\n",
       "  %16 : int = prim::Constant[value=6]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:811:0\n",
       "  %17 : int = prim::Constant[value=0]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:811:0\n",
       "  %18 : Device = prim::Constant[value=\"cpu\"]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:811:0\n",
       "  %19 : bool = prim::Constant[value=0]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:811:0\n",
       "  %attention_mask.1 : Float(1:100, 100:1) = aten::ones(%15, %16, %17, %18, %19) # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:811:0\n",
       "  %21 : int[] = prim::ListConstruct(%8, %13)\n",
       "  %22 : int = prim::Constant[value=4]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:813:0\n",
       "  %23 : int = prim::Constant[value=0]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:813:0\n",
       "  %24 : Device = prim::Constant[value=\"cpu\"]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:813:0\n",
       "  %25 : bool = prim::Constant[value=0]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:813:0\n",
       "  %input.2 : Long(1:100, 100:1) = aten::zeros(%21, %22, %23, %24, %25) # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:813:0\n",
       "  %27 : int = prim::Constant[value=0]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:258:0\n",
       "  %28 : int = prim::Constant[value=0]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:258:0\n",
       "  %29 : int = prim::Constant[value=9223372036854775807]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:258:0\n",
       "  %30 : int = prim::Constant[value=1]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:258:0\n",
       "  %31 : Float(1:100, 100:1) = aten::slice(%attention_mask.1, %27, %28, %29, %30) # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:258:0\n",
       "  %32 : int = prim::Constant[value=1]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:258:0\n",
       "  %33 : Float(1:100, 1:100, 100:1) = aten::unsqueeze(%31, %32) # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:258:0\n",
       "  %34 : int = prim::Constant[value=2]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:258:0\n",
       "  %35 : Float(1:100, 1:100, 1:100, 100:1) = aten::unsqueeze(%33, %34) # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:258:0\n",
       "  %36 : int = prim::Constant[value=3]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:258:0\n",
       "  %37 : int = prim::Constant[value=0]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:258:0\n",
       "  %38 : int = prim::Constant[value=9223372036854775807]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:258:0\n",
       "  %39 : int = prim::Constant[value=1]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:258:0\n",
       "  %extended_attention_mask : Float(1:100, 1:100, 1:100, 100:1) = aten::slice(%35, %36, %37, %38, %39) # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:258:0\n",
       "  %41 : int = prim::Constant[value=6]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:271:0\n",
       "  %42 : bool = prim::Constant[value=0]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:271:0\n",
       "  %43 : bool = prim::Constant[value=0]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:271:0\n",
       "  %44 : None = prim::Constant()\n",
       "  %45 : Float(1:100, 1:100, 1:100, 100:1) = aten::to(%extended_attention_mask, %41, %42, %43, %44) # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:271:0\n",
       "  %46 : float = prim::Constant[value=1.]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/tensor.py:396:0\n",
       "  %47 : int = prim::Constant[value=1]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/tensor.py:396:0\n",
       "  %48 : Float(1:100, 1:100, 1:100, 100:1) = aten::rsub(%45, %46, %47) # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/tensor.py:396:0\n",
       "  %49 : Double() = prim::Constant[value={-10000}]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:272:0\n",
       "  %attention_mask : Float(1:100, 1:100, 1:100, 100:1) = aten::mul(%48, %49) # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:272:0\n",
       "  %55 : float = prim::Constant[value=0.10000000000000001](), scope: __module.embeddings/__module.embeddings.dropout # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:973:0\n",
       "  %56 : int = prim::Constant[value=128](), scope: __module.embeddings/__module.embeddings.LayerNorm # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:2048:0\n",
       "  %57 : float = prim::Constant[value=9.9999999999999998e-13](), scope: __module.embeddings/__module.embeddings.LayerNorm # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:2048:0\n",
       "  %58 : bool = prim::Constant[value=1](), scope: __module.embeddings/__module.embeddings.LayerNorm # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:2048:0\n",
       "  %59 : int = prim::Constant[value=-1](), scope: __module.embeddings/__module.embeddings.position_embeddings # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1814:0\n",
       "  %60 : bool = prim::Constant[value=0](), scope: __module.embeddings/__module.embeddings.word_embeddings # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1814:0\n",
       "  %61 : int = prim::Constant[value=9223372036854775807](), scope: __module.embeddings # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:191:0\n",
       "  %62 : int = prim::Constant[value=0](), scope: __module.embeddings # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:191:0\n",
       "  %63 : int = prim::Constant[value=1](), scope: __module.embeddings # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:184:0\n",
       "  %64 : __torch__.torch.nn.modules.normalization.___torch_mangle_82.LayerNorm = prim::GetAttr[name=\"LayerNorm\"](%4)\n",
       "  %65 : __torch__.torch.nn.modules.sparse.___torch_mangle_81.Embedding = prim::GetAttr[name=\"token_type_embeddings\"](%4)\n",
       "  %66 : __torch__.torch.nn.modules.sparse.___torch_mangle_80.Embedding = prim::GetAttr[name=\"position_embeddings\"](%4)\n",
       "  %67 : __torch__.torch.nn.modules.sparse.___torch_mangle_79.Embedding = prim::GetAttr[name=\"word_embeddings\"](%4)\n",
       "  %68 : Tensor = prim::GetAttr[name=\"position_ids\"](%4)\n",
       "  %69 : int = aten::size(%input_ids, %63), scope: __module.embeddings # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:184:0\n",
       "  %70 : Long(1:512, 512:1) = aten::slice(%68, %62, %62, %61, %63), scope: __module.embeddings # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:191:0\n",
       "  %input.1 : Long(1:512, 100:1) = aten::slice(%70, %63, %62, %69, %63), scope: __module.embeddings # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:191:0\n",
       "  %72 : Tensor = prim::GetAttr[name=\"weight\"](%67)\n",
       "  %inputs_embeds : Float(1:12800, 100:128, 128:1) = aten::embedding(%72, %input_ids, %62, %60, %60), scope: __module.embeddings/__module.embeddings.word_embeddings # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1814:0\n",
       "  %74 : Tensor = prim::GetAttr[name=\"weight\"](%66)\n",
       "  %position_embeddings : Float(1:12800, 100:128, 128:1) = aten::embedding(%74, %input.1, %59, %60, %60), scope: __module.embeddings/__module.embeddings.position_embeddings # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1814:0\n",
       "  %76 : Tensor = prim::GetAttr[name=\"weight\"](%65)\n",
       "  %token_type_embeddings : Float(1:12800, 100:128, 128:1) = aten::embedding(%76, %input.2, %59, %60, %60), scope: __module.embeddings/__module.embeddings.token_type_embeddings # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1814:0\n",
       "  %78 : Float(1:12800, 100:128, 128:1) = aten::add(%inputs_embeds, %position_embeddings, %63), scope: __module.embeddings # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:201:0\n",
       "  %input.3 : Float(1:12800, 100:128, 128:1) = aten::add(%78, %token_type_embeddings, %63), scope: __module.embeddings # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:201:0\n",
       "  %80 : Tensor = prim::GetAttr[name=\"bias\"](%64)\n",
       "  %81 : Tensor = prim::GetAttr[name=\"weight\"](%64)\n",
       "  %82 : int[] = prim::ListConstruct(%56), scope: __module.embeddings/__module.embeddings.LayerNorm\n",
       "  %input.4 : Float(1:12800, 100:128, 128:1) = aten::layer_norm(%input.3, %82, %81, %80, %57, %58), scope: __module.embeddings/__module.embeddings.LayerNorm # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:2048:0\n",
       "  %input.5 : Float(1:12800, 100:128, 128:1) = aten::dropout(%input.4, %55, %60), scope: __module.embeddings/__module.embeddings.dropout # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:973:0\n",
       "  %85 : bool = prim::Constant[value=1](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.output/__module.encoder.layer.0.attention.output.LayerNorm # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:2048:0\n",
       "  %86 : float = prim::Constant[value=9.9999999999999998e-13](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.output/__module.encoder.layer.0.attention.output.LayerNorm # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:2048:0\n",
       "  %87 : int = prim::Constant[value=1](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.query # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1678:0\n",
       "  %88 : int = prim::Constant[value=0](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:227:0\n",
       "  %89 : int = prim::Constant[value=2](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:228:0\n",
       "  %90 : int = prim::Constant[value=64](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:228:0\n",
       "  %91 : int = prim::Constant[value=3](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:229:0\n",
       "  %92 : int = prim::Constant[value=-1](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:258:0\n",
       "  %93 : int = prim::Constant[value=-2](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:258:0\n",
       "  %94 : Double() = prim::Constant[value={8}](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:259:0\n",
       "  %95 : None = prim::Constant(), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self\n",
       "  %96 : bool = prim::Constant[value=0](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.dropout # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:973:0\n",
       "  %97 : float = prim::Constant[value=0.10000000000000001](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.dropout # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:973:0\n",
       "  %98 : int = prim::Constant[value=128](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:279:0\n",
       "  %99 : Double() = prim::Constant[value={1}](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.intermediate # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/activations.py:38:0\n",
       "  %100 : Double() = prim::Constant[value={0.044715}](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.intermediate # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/activations.py:38:0\n",
       "  %101 : Double() = prim::Constant[value={0.797885}](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.intermediate # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/activations.py:38:0\n",
       "  %102 : Double() = prim::Constant[value={0.5}](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.intermediate # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/activations.py:38:0\n",
       "  %103 : __torch__.torch.nn.modules.container.___torch_mangle_119.ModuleList = prim::GetAttr[name=\"layer\"](%3)\n",
       "  %104 : __torch__.transformers.modeling_bert.___torch_mangle_118.BertLayer = prim::GetAttr[name=\"1\"](%103)\n",
       "  %105 : __torch__.torch.nn.modules.container.___torch_mangle_119.ModuleList = prim::GetAttr[name=\"layer\"](%3)\n",
       "  %106 : __torch__.transformers.modeling_bert.___torch_mangle_101.BertLayer = prim::GetAttr[name=\"0\"](%105)\n",
       "  %107 : __torch__.transformers.modeling_bert.___torch_mangle_100.BertOutput = prim::GetAttr[name=\"output\"](%106)\n",
       "  %108 : __torch__.transformers.modeling_bert.___torch_mangle_96.BertIntermediate = prim::GetAttr[name=\"intermediate\"](%106)\n",
       "  %109 : __torch__.transformers.modeling_bert.___torch_mangle_94.BertAttention = prim::GetAttr[name=\"attention\"](%106)\n",
       "  %110 : __torch__.transformers.modeling_bert.___torch_mangle_93.BertSelfOutput = prim::GetAttr[name=\"output\"](%109)\n",
       "  %111 : __torch__.transformers.modeling_bert.___torch_mangle_89.BertSelfAttention = prim::GetAttr[name=\"self\"](%109)\n",
       "  %112 : __torch__.torch.nn.modules.linear.___torch_mangle_87.Linear = prim::GetAttr[name=\"value\"](%111)\n",
       "  %113 : __torch__.torch.nn.modules.linear.___torch_mangle_86.Linear = prim::GetAttr[name=\"key\"](%111)\n",
       "  %114 : __torch__.torch.nn.modules.linear.___torch_mangle_85.Linear = prim::GetAttr[name=\"query\"](%111)\n",
       "  %115 : Tensor = prim::GetAttr[name=\"bias\"](%114)\n",
       "  %116 : Tensor = prim::GetAttr[name=\"weight\"](%114)\n",
       "  %117 : Float(128:1, 128:128) = aten::t(%116), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.query # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0\n",
       "  %output.1 : Float(1:12800, 100:128, 128:1) = aten::matmul(%input.5, %117), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.query # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0\n",
       "  %x.1 : Float(1:12800, 100:128, 128:1) = aten::add_(%output.1, %115, %87), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.query # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1678:0\n",
       "  %120 : Tensor = prim::GetAttr[name=\"bias\"](%113)\n",
       "  %121 : Tensor = prim::GetAttr[name=\"weight\"](%113)\n",
       "  %122 : Float(128:1, 128:128) = aten::t(%121), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.key # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0\n",
       "  %output.2 : Float(1:12800, 100:128, 128:1) = aten::matmul(%input.5, %122), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.key # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0\n",
       "  %x.3 : Float(1:12800, 100:128, 128:1) = aten::add_(%output.2, %120, %87), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.key # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1678:0\n",
       "  %125 : Tensor = prim::GetAttr[name=\"bias\"](%112)\n",
       "  %126 : Tensor = prim::GetAttr[name=\"weight\"](%112)\n",
       "  %127 : Float(128:1, 128:128) = aten::t(%126), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.value # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0\n",
       "  %output.3 : Float(1:12800, 100:128, 128:1) = aten::matmul(%input.5, %127), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.value # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0\n",
       "  %x.5 : Float(1:12800, 100:128, 128:1) = aten::add_(%output.3, %125, %87), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.value # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1678:0\n",
       "  %130 : int = aten::size(%x.1, %88), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:227:0\n",
       "  %131 : int = aten::size(%x.1, %87), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:227:0\n",
       "  %132 : int[] = prim::ListConstruct(%130, %131, %89, %90), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self\n",
       "  %x.2 : Float(1:12800, 100:128, 2:64, 64:1) = aten::view(%x.1, %132), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:228:0\n",
       "  %134 : int[] = prim::ListConstruct(%88, %89, %87, %91), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self\n",
       "  %query_layer.1 : Float(1:12800, 2:64, 100:128, 64:1) = aten::permute(%x.2, %134), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:229:0\n",
       "  %136 : int = aten::size(%x.3, %88), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:227:0\n",
       "  %137 : int = aten::size(%x.3, %87), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:227:0\n",
       "  %138 : int[] = prim::ListConstruct(%136, %137, %89, %90), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self\n",
       "  %x.4 : Float(1:12800, 100:128, 2:64, 64:1) = aten::view(%x.3, %138), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:228:0\n",
       "  %140 : int[] = prim::ListConstruct(%88, %89, %87, %91), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self\n",
       "  %key_layer.1 : Float(1:12800, 2:64, 100:128, 64:1) = aten::permute(%x.4, %140), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:229:0\n",
       "  %142 : int = aten::size(%x.5, %88), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:227:0\n",
       "  %143 : int = aten::size(%x.5, %87), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:227:0\n",
       "  %144 : int[] = prim::ListConstruct(%142, %143, %89, %90), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self\n",
       "  %x.6 : Float(1:12800, 100:128, 2:64, 64:1) = aten::view(%x.5, %144), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:228:0\n",
       "  %146 : int[] = prim::ListConstruct(%88, %89, %87, %91), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self\n",
       "  %value_layer.1 : Float(1:12800, 2:64, 100:128, 64:1) = aten::permute(%x.6, %146), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:229:0\n",
       "  %148 : Float(1:12800, 2:64, 64:1, 100:128) = aten::transpose(%key_layer.1, %92, %93), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:258:0\n",
       "  %attention_scores.1 : Float(1:20000, 2:10000, 100:100, 100:1) = aten::matmul(%query_layer.1, %148), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:258:0\n",
       "  %attention_scores.2 : Float(1:20000, 2:10000, 100:100, 100:1) = aten::div(%attention_scores.1, %94), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:259:0\n",
       "  %input.6 : Float(1:20000, 2:10000, 100:100, 100:1) = aten::add(%attention_scores.2, %attention_mask, %87), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:262:0\n",
       "  %input.7 : Float(1:20000, 2:10000, 100:100, 100:1) = aten::softmax(%input.6, %92, %95), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1498:0\n",
       "  %attention_probs.1 : Float(1:20000, 2:10000, 100:100, 100:1) = aten::dropout(%input.7, %97, %96), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.dropout # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:973:0\n",
       "  %context_layer.1 : Float(1:12800, 2:6400, 100:64, 64:1) = aten::matmul(%attention_probs.1, %value_layer.1), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:275:0\n",
       "  %155 : int[] = prim::ListConstruct(%88, %89, %87, %91), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self\n",
       "  %156 : Float(1:12800, 100:64, 2:6400, 64:1) = aten::permute(%context_layer.1, %155), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:277:0\n",
       "  %context_layer.2 : Float(1:12800, 100:128, 2:64, 64:1) = aten::contiguous(%156, %88), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:277:0\n",
       "  %158 : int = aten::size(%context_layer.2, %88), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:278:0\n",
       "  %159 : int = aten::size(%context_layer.2, %87), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:278:0\n",
       "  %160 : int[] = prim::ListConstruct(%158, %159, %98), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self\n",
       "  %input.8 : Float(1:12800, 100:128, 128:1) = aten::view(%context_layer.2, %160), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:279:0\n",
       "  %162 : __torch__.torch.nn.modules.normalization.___torch_mangle_91.LayerNorm = prim::GetAttr[name=\"LayerNorm\"](%110)\n",
       "  %163 : __torch__.torch.nn.modules.linear.___torch_mangle_90.Linear = prim::GetAttr[name=\"dense\"](%110)\n",
       "  %164 : Tensor = prim::GetAttr[name=\"bias\"](%163)\n",
       "  %165 : Tensor = prim::GetAttr[name=\"weight\"](%163)\n",
       "  %166 : Float(128:1, 128:128) = aten::t(%165), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.output/__module.encoder.layer.0.attention.output.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0\n",
       "  %output.4 : Float(1:12800, 100:128, 128:1) = aten::matmul(%input.8, %166), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.output/__module.encoder.layer.0.attention.output.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0\n",
       "  %input.9 : Float(1:12800, 100:128, 128:1) = aten::add_(%output.4, %164, %87), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.output/__module.encoder.layer.0.attention.output.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1678:0\n",
       "  %hidden_states.1 : Float(1:12800, 100:128, 128:1) = aten::dropout(%input.9, %97, %96), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.output/__module.encoder.layer.0.attention.output.dropout # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:973:0\n",
       "  %input.10 : Float(1:12800, 100:128, 128:1) = aten::add(%hidden_states.1, %input.5, %87), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.output # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:295:0\n",
       "  %171 : Tensor = prim::GetAttr[name=\"bias\"](%162)\n",
       "  %172 : Tensor = prim::GetAttr[name=\"weight\"](%162)\n",
       "  %173 : int[] = prim::ListConstruct(%98), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.output/__module.encoder.layer.0.attention.output.LayerNorm\n",
       "  %input_tensor.1 : Float(1:12800, 100:128, 128:1) = aten::layer_norm(%input.10, %173, %172, %171, %86, %85), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.output/__module.encoder.layer.0.attention.output.LayerNorm # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:2048:0\n",
       "  %175 : __torch__.torch.nn.modules.linear.___torch_mangle_95.Linear = prim::GetAttr[name=\"dense\"](%108)\n",
       "  %176 : Tensor = prim::GetAttr[name=\"bias\"](%175)\n",
       "  %177 : Tensor = prim::GetAttr[name=\"weight\"](%175)\n",
       "  %178 : Float(128:1, 512:128) = aten::t(%177), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.intermediate/__module.encoder.layer.0.intermediate.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0\n",
       "  %output.5 : Float(1:51200, 100:512, 512:1) = aten::matmul(%input_tensor.1, %178), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.intermediate/__module.encoder.layer.0.intermediate.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0\n",
       "  %x.7 : Float(1:51200, 100:512, 512:1) = aten::add_(%output.5, %176, %87), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.intermediate/__module.encoder.layer.0.intermediate.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1678:0\n",
       "  %181 : Float(1:51200, 100:512, 512:1) = aten::mul(%x.7, %102), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.intermediate # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/activations.py:38:0\n",
       "  %182 : Float(1:51200, 100:512, 512:1) = aten::mul(%x.7, %101), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.intermediate # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/activations.py:38:0\n",
       "  %183 : Float(1:51200, 100:512, 512:1) = aten::mul(%x.7, %100), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.intermediate # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/activations.py:38:0\n",
       "  %184 : Float(1:51200, 100:512, 512:1) = aten::mul(%183, %x.7), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.intermediate # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/activations.py:38:0\n",
       "  %185 : Float(1:51200, 100:512, 512:1) = aten::add(%184, %99, %87), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.intermediate # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/activations.py:38:0\n",
       "  %186 : Float(1:51200, 100:512, 512:1) = aten::mul(%182, %185), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.intermediate # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/activations.py:38:0\n",
       "  %187 : Float(1:51200, 100:512, 512:1) = aten::tanh(%186), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.intermediate # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/activations.py:38:0\n",
       "  %188 : Float(1:51200, 100:512, 512:1) = aten::add(%187, %99, %87), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.intermediate # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/activations.py:38:0\n",
       "  %input.11 : Float(1:51200, 100:512, 512:1) = aten::mul(%181, %188), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.intermediate # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/activations.py:38:0\n",
       "  %190 : __torch__.torch.nn.modules.normalization.___torch_mangle_98.LayerNorm = prim::GetAttr[name=\"LayerNorm\"](%107)\n",
       "  %191 : __torch__.torch.nn.modules.linear.___torch_mangle_97.Linear = prim::GetAttr[name=\"dense\"](%107)\n",
       "  %192 : Tensor = prim::GetAttr[name=\"bias\"](%191)\n",
       "  %193 : Tensor = prim::GetAttr[name=\"weight\"](%191)\n",
       "  %194 : Float(512:1, 128:512) = aten::t(%193), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.output/__module.encoder.layer.0.output.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0\n",
       "  %output.6 : Float(1:12800, 100:128, 128:1) = aten::matmul(%input.11, %194), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.output/__module.encoder.layer.0.output.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0\n",
       "  %input.12 : Float(1:12800, 100:128, 128:1) = aten::add_(%output.6, %192, %87), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.output/__module.encoder.layer.0.output.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1678:0\n",
       "  %hidden_states.2 : Float(1:12800, 100:128, 128:1) = aten::dropout(%input.12, %97, %96), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.output/__module.encoder.layer.0.output.dropout # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:973:0\n",
       "  %input.13 : Float(1:12800, 100:128, 128:1) = aten::add(%hidden_states.2, %input_tensor.1, %87), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.output # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:371:0\n",
       "  %199 : Tensor = prim::GetAttr[name=\"bias\"](%190)\n",
       "  %200 : Tensor = prim::GetAttr[name=\"weight\"](%190)\n",
       "  %201 : int[] = prim::ListConstruct(%98), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.output/__module.encoder.layer.0.output.LayerNorm\n",
       "  %input.14 : Float(1:12800, 100:128, 128:1) = aten::layer_norm(%input.13, %201, %200, %199, %86, %85), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.output/__module.encoder.layer.0.output.LayerNorm # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:2048:0\n",
       "  %203 : __torch__.transformers.modeling_bert.___torch_mangle_117.BertOutput = prim::GetAttr[name=\"output\"](%104)\n",
       "  %204 : __torch__.transformers.modeling_bert.___torch_mangle_113.BertIntermediate = prim::GetAttr[name=\"intermediate\"](%104)\n",
       "  %205 : __torch__.transformers.modeling_bert.___torch_mangle_111.BertAttention = prim::GetAttr[name=\"attention\"](%104)\n",
       "  %206 : __torch__.transformers.modeling_bert.___torch_mangle_110.BertSelfOutput = prim::GetAttr[name=\"output\"](%205)\n",
       "  %207 : __torch__.transformers.modeling_bert.___torch_mangle_106.BertSelfAttention = prim::GetAttr[name=\"self\"](%205)\n",
       "  %208 : __torch__.torch.nn.modules.linear.___torch_mangle_104.Linear = prim::GetAttr[name=\"value\"](%207)\n",
       "  %209 : __torch__.torch.nn.modules.linear.___torch_mangle_103.Linear = prim::GetAttr[name=\"key\"](%207)\n",
       "  %210 : __torch__.torch.nn.modules.linear.___torch_mangle_102.Linear = prim::GetAttr[name=\"query\"](%207)\n",
       "  %211 : Tensor = prim::GetAttr[name=\"bias\"](%210)\n",
       "  %212 : Tensor = prim::GetAttr[name=\"weight\"](%210)\n",
       "  %213 : Float(128:1, 128:128) = aten::t(%212), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self/__module.encoder.layer.1.attention.self.query # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0\n",
       "  %output.7 : Float(1:12800, 100:128, 128:1) = aten::matmul(%input.14, %213), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self/__module.encoder.layer.1.attention.self.query # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0\n",
       "  %x.8 : Float(1:12800, 100:128, 128:1) = aten::add_(%output.7, %211, %87), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self/__module.encoder.layer.1.attention.self.query # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1678:0\n",
       "  %216 : Tensor = prim::GetAttr[name=\"bias\"](%209)\n",
       "  %217 : Tensor = prim::GetAttr[name=\"weight\"](%209)\n",
       "  %218 : Float(128:1, 128:128) = aten::t(%217), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self/__module.encoder.layer.1.attention.self.key # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0\n",
       "  %output.8 : Float(1:12800, 100:128, 128:1) = aten::matmul(%input.14, %218), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self/__module.encoder.layer.1.attention.self.key # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0\n",
       "  %x.10 : Float(1:12800, 100:128, 128:1) = aten::add_(%output.8, %216, %87), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self/__module.encoder.layer.1.attention.self.key # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1678:0\n",
       "  %221 : Tensor = prim::GetAttr[name=\"bias\"](%208)\n",
       "  %222 : Tensor = prim::GetAttr[name=\"weight\"](%208)\n",
       "  %223 : Float(128:1, 128:128) = aten::t(%222), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self/__module.encoder.layer.1.attention.self.value # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0\n",
       "  %output.9 : Float(1:12800, 100:128, 128:1) = aten::matmul(%input.14, %223), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self/__module.encoder.layer.1.attention.self.value # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0\n",
       "  %x.12 : Float(1:12800, 100:128, 128:1) = aten::add_(%output.9, %221, %87), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self/__module.encoder.layer.1.attention.self.value # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1678:0\n",
       "  %226 : int = aten::size(%x.8, %88), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:227:0\n",
       "  %227 : int = aten::size(%x.8, %87), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:227:0\n",
       "  %228 : int[] = prim::ListConstruct(%226, %227, %89, %90), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self\n",
       "  %x.9 : Float(1:12800, 100:128, 2:64, 64:1) = aten::view(%x.8, %228), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:228:0\n",
       "  %230 : int[] = prim::ListConstruct(%88, %89, %87, %91), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self\n",
       "  %query_layer : Float(1:12800, 2:64, 100:128, 64:1) = aten::permute(%x.9, %230), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:229:0\n",
       "  %232 : int = aten::size(%x.10, %88), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:227:0\n",
       "  %233 : int = aten::size(%x.10, %87), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:227:0\n",
       "  %234 : int[] = prim::ListConstruct(%232, %233, %89, %90), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self\n",
       "  %x.11 : Float(1:12800, 100:128, 2:64, 64:1) = aten::view(%x.10, %234), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:228:0\n",
       "  %236 : int[] = prim::ListConstruct(%88, %89, %87, %91), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self\n",
       "  %key_layer : Float(1:12800, 2:64, 100:128, 64:1) = aten::permute(%x.11, %236), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:229:0\n",
       "  %238 : int = aten::size(%x.12, %88), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:227:0\n",
       "  %239 : int = aten::size(%x.12, %87), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:227:0\n",
       "  %240 : int[] = prim::ListConstruct(%238, %239, %89, %90), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self\n",
       "  %x.13 : Float(1:12800, 100:128, 2:64, 64:1) = aten::view(%x.12, %240), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:228:0\n",
       "  %242 : int[] = prim::ListConstruct(%88, %89, %87, %91), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self\n",
       "  %value_layer : Float(1:12800, 2:64, 100:128, 64:1) = aten::permute(%x.13, %242), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:229:0\n",
       "  %244 : Float(1:12800, 2:64, 64:1, 100:128) = aten::transpose(%key_layer, %92, %93), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:258:0\n",
       "  %attention_scores.3 : Float(1:20000, 2:10000, 100:100, 100:1) = aten::matmul(%query_layer, %244), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:258:0\n",
       "  %attention_scores : Float(1:20000, 2:10000, 100:100, 100:1) = aten::div(%attention_scores.3, %94), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:259:0\n",
       "  %input.15 : Float(1:20000, 2:10000, 100:100, 100:1) = aten::add(%attention_scores, %attention_mask, %87), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:262:0\n",
       "  %input.16 : Float(1:20000, 2:10000, 100:100, 100:1) = aten::softmax(%input.15, %92, %95), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1498:0\n",
       "  %attention_probs : Float(1:20000, 2:10000, 100:100, 100:1) = aten::dropout(%input.16, %97, %96), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self/__module.encoder.layer.1.attention.self.dropout # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:973:0\n",
       "  %context_layer.3 : Float(1:12800, 2:6400, 100:64, 64:1) = aten::matmul(%attention_probs, %value_layer), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:275:0\n",
       "  %251 : int[] = prim::ListConstruct(%88, %89, %87, %91), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self\n",
       "  %252 : Float(1:12800, 100:64, 2:6400, 64:1) = aten::permute(%context_layer.3, %251), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:277:0\n",
       "  %context_layer : Float(1:12800, 100:128, 2:64, 64:1) = aten::contiguous(%252, %88), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:277:0\n",
       "  %254 : int = aten::size(%context_layer, %88), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:278:0\n",
       "  %255 : int = aten::size(%context_layer, %87), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:278:0\n",
       "  %256 : int[] = prim::ListConstruct(%254, %255, %98), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self\n",
       "  %input.17 : Float(1:12800, 100:128, 128:1) = aten::view(%context_layer, %256), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:279:0\n",
       "  %258 : __torch__.torch.nn.modules.normalization.___torch_mangle_108.LayerNorm = prim::GetAttr[name=\"LayerNorm\"](%206)\n",
       "  %259 : __torch__.torch.nn.modules.linear.___torch_mangle_107.Linear = prim::GetAttr[name=\"dense\"](%206)\n",
       "  %260 : Tensor = prim::GetAttr[name=\"bias\"](%259)\n",
       "  %261 : Tensor = prim::GetAttr[name=\"weight\"](%259)\n",
       "  %262 : Float(128:1, 128:128) = aten::t(%261), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.output/__module.encoder.layer.1.attention.output.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0\n",
       "  %output.10 : Float(1:12800, 100:128, 128:1) = aten::matmul(%input.17, %262), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.output/__module.encoder.layer.1.attention.output.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0\n",
       "  %input.18 : Float(1:12800, 100:128, 128:1) = aten::add_(%output.10, %260, %87), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.output/__module.encoder.layer.1.attention.output.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1678:0\n",
       "  %hidden_states.3 : Float(1:12800, 100:128, 128:1) = aten::dropout(%input.18, %97, %96), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.output/__module.encoder.layer.1.attention.output.dropout # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:973:0\n",
       "  %input.19 : Float(1:12800, 100:128, 128:1) = aten::add(%hidden_states.3, %input.14, %87), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.output # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:295:0\n",
       "  %267 : Tensor = prim::GetAttr[name=\"bias\"](%258)\n",
       "  %268 : Tensor = prim::GetAttr[name=\"weight\"](%258)\n",
       "  %269 : int[] = prim::ListConstruct(%98), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.output/__module.encoder.layer.1.attention.output.LayerNorm\n",
       "  %input_tensor : Float(1:12800, 100:128, 128:1) = aten::layer_norm(%input.19, %269, %268, %267, %86, %85), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.output/__module.encoder.layer.1.attention.output.LayerNorm # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:2048:0\n",
       "  %271 : __torch__.torch.nn.modules.linear.___torch_mangle_112.Linear = prim::GetAttr[name=\"dense\"](%204)\n",
       "  %272 : Tensor = prim::GetAttr[name=\"bias\"](%271)\n",
       "  %273 : Tensor = prim::GetAttr[name=\"weight\"](%271)\n",
       "  %274 : Float(128:1, 512:128) = aten::t(%273), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.intermediate/__module.encoder.layer.1.intermediate.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0\n",
       "  %output.11 : Float(1:51200, 100:512, 512:1) = aten::matmul(%input_tensor, %274), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.intermediate/__module.encoder.layer.1.intermediate.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0\n",
       "  %x : Float(1:51200, 100:512, 512:1) = aten::add_(%output.11, %272, %87), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.intermediate/__module.encoder.layer.1.intermediate.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1678:0\n",
       "  %277 : Float(1:51200, 100:512, 512:1) = aten::mul(%x, %102), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.intermediate # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/activations.py:38:0\n",
       "  %278 : Float(1:51200, 100:512, 512:1) = aten::mul(%x, %101), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.intermediate # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/activations.py:38:0\n",
       "  %279 : Float(1:51200, 100:512, 512:1) = aten::mul(%x, %100), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.intermediate # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/activations.py:38:0\n",
       "  %280 : Float(1:51200, 100:512, 512:1) = aten::mul(%279, %x), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.intermediate # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/activations.py:38:0\n",
       "  %281 : Float(1:51200, 100:512, 512:1) = aten::add(%280, %99, %87), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.intermediate # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/activations.py:38:0\n",
       "  %282 : Float(1:51200, 100:512, 512:1) = aten::mul(%278, %281), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.intermediate # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/activations.py:38:0\n",
       "  %283 : Float(1:51200, 100:512, 512:1) = aten::tanh(%282), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.intermediate # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/activations.py:38:0\n",
       "  %284 : Float(1:51200, 100:512, 512:1) = aten::add(%283, %99, %87), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.intermediate # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/activations.py:38:0\n",
       "  %input.20 : Float(1:51200, 100:512, 512:1) = aten::mul(%277, %284), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.intermediate # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/activations.py:38:0\n",
       "  %286 : __torch__.torch.nn.modules.normalization.___torch_mangle_115.LayerNorm = prim::GetAttr[name=\"LayerNorm\"](%203)\n",
       "  %287 : __torch__.torch.nn.modules.linear.___torch_mangle_114.Linear = prim::GetAttr[name=\"dense\"](%203)\n",
       "  %288 : Tensor = prim::GetAttr[name=\"bias\"](%287)\n",
       "  %289 : Tensor = prim::GetAttr[name=\"weight\"](%287)\n",
       "  %290 : Float(512:1, 128:512) = aten::t(%289), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.output/__module.encoder.layer.1.output.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0\n",
       "  %output : Float(1:12800, 100:128, 128:1) = aten::matmul(%input.20, %290), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.output/__module.encoder.layer.1.output.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0\n",
       "  %input.21 : Float(1:12800, 100:128, 128:1) = aten::add_(%output, %288, %87), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.output/__module.encoder.layer.1.output.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1678:0\n",
       "  %hidden_states.4 : Float(1:12800, 100:128, 128:1) = aten::dropout(%input.21, %97, %96), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.output/__module.encoder.layer.1.output.dropout # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:973:0\n",
       "  %input.22 : Float(1:12800, 100:128, 128:1) = aten::add(%hidden_states.4, %input_tensor, %87), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.output # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:371:0\n",
       "  %295 : Tensor = prim::GetAttr[name=\"bias\"](%286)\n",
       "  %296 : Tensor = prim::GetAttr[name=\"weight\"](%286)\n",
       "  %297 : int[] = prim::ListConstruct(%98), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.output/__module.encoder.layer.1.output.LayerNorm\n",
       "  %hidden_states : Float(1:12800, 100:128, 128:1) = aten::layer_norm(%input.22, %297, %296, %295, %86, %85), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.output/__module.encoder.layer.1.output.LayerNorm # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:2048:0\n",
       "  %299 : int = prim::Constant[value=1](), scope: __module.pooler # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:517:0\n",
       "  %300 : int = prim::Constant[value=9223372036854775807](), scope: __module.pooler # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:517:0\n",
       "  %301 : int = prim::Constant[value=0](), scope: __module.pooler # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:517:0\n",
       "  %302 : __torch__.torch.nn.modules.linear.___torch_mangle_121.Linear = prim::GetAttr[name=\"dense\"](%2)\n",
       "  %303 : Float(1:12800, 100:128, 128:1) = aten::slice(%hidden_states, %301, %301, %300, %299), scope: __module.pooler # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:517:0\n",
       "  %input.23 : Float(1:12800, 128:1) = aten::select(%303, %299, %301), scope: __module.pooler # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:517:0\n",
       "  %305 : Tensor = prim::GetAttr[name=\"bias\"](%302)\n",
       "  %306 : Tensor = prim::GetAttr[name=\"weight\"](%302)\n",
       "  %307 : Float(128:1, 128:128) = aten::t(%306), scope: __module.pooler/__module.pooler.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1674:0\n",
       "  %input : Float(1:128, 128:1) = aten::addmm(%305, %input.23, %307, %299, %299), scope: __module.pooler/__module.pooler.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1674:0\n",
       "  %309 : Float(1:128, 128:1) = aten::tanh(%input), scope: __module.pooler/__module.pooler.activation # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/modules/activation.py:350:0\n",
       "  %54 : (Float(1:12800, 100:128, 128:1), Float(1:128, 128:1)) = prim::TupleConstruct(%hidden_states, %309)\n",
       "  return (%54)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[%2 : __torch__.transformers.modeling_bert.BertPooler = prim::GetAttr[name=\"pooler\"](%self.1),\n",
       " %3 : __torch__.transformers.modeling_bert.BertEncoder = prim::GetAttr[name=\"encoder\"](%self.1),\n",
       " %4 : __torch__.transformers.modeling_bert.BertEmbeddings = prim::GetAttr[name=\"embeddings\"](%self.1),\n",
       " %5 : int = prim::Constant[value=0]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:802:0,\n",
       " %6 : int = aten::size(%input_ids, %5) # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:802:0,\n",
       " %7 : Long() = prim::NumToTensor(%6),\n",
       " %8 : int = aten::Int(%7),\n",
       " %9 : int = aten::Int(%7),\n",
       " %10 : int = prim::Constant[value=1]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:802:0,\n",
       " %11 : int = aten::size(%input_ids, %10) # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:802:0,\n",
       " %12 : Long() = prim::NumToTensor(%11),\n",
       " %13 : int = aten::Int(%12),\n",
       " %14 : int = aten::Int(%12),\n",
       " %15 : int[] = prim::ListConstruct(%9, %14),\n",
       " %16 : int = prim::Constant[value=6]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:811:0,\n",
       " %17 : int = prim::Constant[value=0]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:811:0,\n",
       " %18 : Device = prim::Constant[value=\"cpu\"]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:811:0,\n",
       " %19 : bool = prim::Constant[value=0]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:811:0,\n",
       " %attention_mask.1 : Float(1:100, 100:1) = aten::ones(%15, %16, %17, %18, %19) # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:811:0,\n",
       " %21 : int[] = prim::ListConstruct(%8, %13),\n",
       " %22 : int = prim::Constant[value=4]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:813:0,\n",
       " %23 : int = prim::Constant[value=0]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:813:0,\n",
       " %24 : Device = prim::Constant[value=\"cpu\"]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:813:0,\n",
       " %25 : bool = prim::Constant[value=0]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:813:0,\n",
       " %input.2 : Long(1:100, 100:1) = aten::zeros(%21, %22, %23, %24, %25) # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:813:0,\n",
       " %27 : int = prim::Constant[value=0]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:258:0,\n",
       " %28 : int = prim::Constant[value=0]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:258:0,\n",
       " %29 : int = prim::Constant[value=9223372036854775807]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:258:0,\n",
       " %30 : int = prim::Constant[value=1]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:258:0,\n",
       " %31 : Float(1:100, 100:1) = aten::slice(%attention_mask.1, %27, %28, %29, %30) # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:258:0,\n",
       " %32 : int = prim::Constant[value=1]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:258:0,\n",
       " %33 : Float(1:100, 1:100, 100:1) = aten::unsqueeze(%31, %32) # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:258:0,\n",
       " %34 : int = prim::Constant[value=2]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:258:0,\n",
       " %35 : Float(1:100, 1:100, 1:100, 100:1) = aten::unsqueeze(%33, %34) # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:258:0,\n",
       " %36 : int = prim::Constant[value=3]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:258:0,\n",
       " %37 : int = prim::Constant[value=0]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:258:0,\n",
       " %38 : int = prim::Constant[value=9223372036854775807]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:258:0,\n",
       " %39 : int = prim::Constant[value=1]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:258:0,\n",
       " %extended_attention_mask : Float(1:100, 1:100, 1:100, 100:1) = aten::slice(%35, %36, %37, %38, %39) # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:258:0,\n",
       " %41 : int = prim::Constant[value=6]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:271:0,\n",
       " %42 : bool = prim::Constant[value=0]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:271:0,\n",
       " %43 : bool = prim::Constant[value=0]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:271:0,\n",
       " %44 : None = prim::Constant(),\n",
       " %45 : Float(1:100, 1:100, 1:100, 100:1) = aten::to(%extended_attention_mask, %41, %42, %43, %44) # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:271:0,\n",
       " %46 : float = prim::Constant[value=1.]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/tensor.py:396:0,\n",
       " %47 : int = prim::Constant[value=1]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/tensor.py:396:0,\n",
       " %48 : Float(1:100, 1:100, 1:100, 100:1) = aten::rsub(%45, %46, %47) # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/tensor.py:396:0,\n",
       " %49 : Double() = prim::Constant[value={-10000}]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:272:0,\n",
       " %attention_mask : Float(1:100, 1:100, 1:100, 100:1) = aten::mul(%48, %49) # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:272:0,\n",
       " %55 : float = prim::Constant[value=0.10000000000000001](), scope: __module.embeddings/__module.embeddings.dropout # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:973:0,\n",
       " %56 : int = prim::Constant[value=128](), scope: __module.embeddings/__module.embeddings.LayerNorm # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:2048:0,\n",
       " %57 : float = prim::Constant[value=9.9999999999999998e-13](), scope: __module.embeddings/__module.embeddings.LayerNorm # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:2048:0,\n",
       " %58 : bool = prim::Constant[value=1](), scope: __module.embeddings/__module.embeddings.LayerNorm # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:2048:0,\n",
       " %59 : int = prim::Constant[value=-1](), scope: __module.embeddings/__module.embeddings.position_embeddings # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1814:0,\n",
       " %60 : bool = prim::Constant[value=0](), scope: __module.embeddings/__module.embeddings.word_embeddings # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1814:0,\n",
       " %61 : int = prim::Constant[value=9223372036854775807](), scope: __module.embeddings # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:191:0,\n",
       " %62 : int = prim::Constant[value=0](), scope: __module.embeddings # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:191:0,\n",
       " %63 : int = prim::Constant[value=1](), scope: __module.embeddings # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:184:0,\n",
       " %64 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name=\"LayerNorm\"](%4),\n",
       " %65 : __torch__.torch.nn.modules.sparse.___torch_mangle_3.Embedding = prim::GetAttr[name=\"token_type_embeddings\"](%4),\n",
       " %66 : __torch__.torch.nn.modules.sparse.___torch_mangle_2.Embedding = prim::GetAttr[name=\"position_embeddings\"](%4),\n",
       " %67 : __torch__.torch.nn.modules.sparse.Embedding = prim::GetAttr[name=\"word_embeddings\"](%4),\n",
       " %68 : Tensor = prim::GetAttr[name=\"position_ids\"](%4),\n",
       " %69 : int = aten::size(%input_ids, %63), scope: __module.embeddings # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:184:0,\n",
       " %70 : Long(1:512, 512:1) = aten::slice(%68, %62, %62, %61, %63), scope: __module.embeddings # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:191:0,\n",
       " %input.1 : Long(1:512, 100:1) = aten::slice(%70, %63, %62, %69, %63), scope: __module.embeddings # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:191:0,\n",
       " %72 : Tensor = prim::GetAttr[name=\"weight\"](%67),\n",
       " %inputs_embeds : Float(1:12800, 100:128, 128:1) = aten::embedding(%72, %input_ids, %62, %60, %60), scope: __module.embeddings/__module.embeddings.word_embeddings # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1814:0,\n",
       " %74 : Tensor = prim::GetAttr[name=\"weight\"](%66),\n",
       " %position_embeddings : Float(1:12800, 100:128, 128:1) = aten::embedding(%74, %input.1, %59, %60, %60), scope: __module.embeddings/__module.embeddings.position_embeddings # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1814:0,\n",
       " %76 : Tensor = prim::GetAttr[name=\"weight\"](%65),\n",
       " %token_type_embeddings : Float(1:12800, 100:128, 128:1) = aten::embedding(%76, %input.2, %59, %60, %60), scope: __module.embeddings/__module.embeddings.token_type_embeddings # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1814:0,\n",
       " %78 : Float(1:12800, 100:128, 128:1) = aten::add(%inputs_embeds, %position_embeddings, %63), scope: __module.embeddings # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:201:0,\n",
       " %input.3 : Float(1:12800, 100:128, 128:1) = aten::add(%78, %token_type_embeddings, %63), scope: __module.embeddings # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:201:0,\n",
       " %80 : Tensor = prim::GetAttr[name=\"bias\"](%64),\n",
       " %81 : Tensor = prim::GetAttr[name=\"weight\"](%64),\n",
       " %82 : int[] = prim::ListConstruct(%56), scope: __module.embeddings/__module.embeddings.LayerNorm,\n",
       " %input.4 : Float(1:12800, 100:128, 128:1) = aten::layer_norm(%input.3, %82, %81, %80, %57, %58), scope: __module.embeddings/__module.embeddings.LayerNorm # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:2048:0,\n",
       " %input.5 : Float(1:12800, 100:128, 128:1) = aten::dropout(%input.4, %55, %60), scope: __module.embeddings/__module.embeddings.dropout # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:973:0,\n",
       " %85 : bool = prim::Constant[value=1](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.output/__module.encoder.layer.0.attention.output.LayerNorm # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:2048:0,\n",
       " %86 : float = prim::Constant[value=9.9999999999999998e-13](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.output/__module.encoder.layer.0.attention.output.LayerNorm # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:2048:0,\n",
       " %87 : int = prim::Constant[value=1](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.query # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1678:0,\n",
       " %88 : int = prim::Constant[value=0](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:227:0,\n",
       " %89 : int = prim::Constant[value=2](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:228:0,\n",
       " %90 : int = prim::Constant[value=64](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:228:0,\n",
       " %91 : int = prim::Constant[value=3](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:229:0,\n",
       " %92 : int = prim::Constant[value=-1](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:258:0,\n",
       " %93 : int = prim::Constant[value=-2](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:258:0,\n",
       " %94 : Double() = prim::Constant[value={8}](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:259:0,\n",
       " %95 : None = prim::Constant(), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self,\n",
       " %96 : bool = prim::Constant[value=0](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.dropout # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:973:0,\n",
       " %97 : float = prim::Constant[value=0.10000000000000001](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.dropout # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:973:0,\n",
       " %98 : int = prim::Constant[value=128](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:279:0,\n",
       " %99 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name=\"layer\"](%3),\n",
       " %100 : __torch__.transformers.modeling_bert.___torch_mangle_31.BertLayer = prim::GetAttr[name=\"1\"](%99),\n",
       " %101 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name=\"layer\"](%3),\n",
       " %102 : __torch__.transformers.modeling_bert.BertLayer = prim::GetAttr[name=\"0\"](%101),\n",
       " %103 : __torch__.transformers.modeling_bert.BertOutput = prim::GetAttr[name=\"output\"](%102),\n",
       " %104 : __torch__.transformers.modeling_bert.BertIntermediate = prim::GetAttr[name=\"intermediate\"](%102),\n",
       " %105 : __torch__.transformers.modeling_bert.BertAttention = prim::GetAttr[name=\"attention\"](%102),\n",
       " %106 : __torch__.transformers.modeling_bert.BertSelfOutput = prim::GetAttr[name=\"output\"](%105),\n",
       " %107 : __torch__.transformers.modeling_bert.BertSelfAttention = prim::GetAttr[name=\"self\"](%105),\n",
       " %108 : __torch__.torch.nn.modules.linear.___torch_mangle_6.Linear = prim::GetAttr[name=\"value\"](%107),\n",
       " %109 : __torch__.torch.nn.modules.linear.___torch_mangle_5.Linear = prim::GetAttr[name=\"key\"](%107),\n",
       " %110 : __torch__.torch.nn.modules.linear.___torch_mangle_4.Linear = prim::GetAttr[name=\"query\"](%107),\n",
       " %111 : Tensor = prim::GetAttr[name=\"bias\"](%110),\n",
       " %112 : Tensor = prim::GetAttr[name=\"weight\"](%110),\n",
       " %113 : Float(128:1, 128:128) = aten::t(%112), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.query # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0,\n",
       " %output.1 : Float(1:12800, 100:128, 128:1) = aten::matmul(%input.5, %113), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.query # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0,\n",
       " %x.1 : Float(1:12800, 100:128, 128:1) = aten::add_(%output.1, %111, %87), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.query # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1678:0,\n",
       " %116 : Tensor = prim::GetAttr[name=\"bias\"](%109),\n",
       " %117 : Tensor = prim::GetAttr[name=\"weight\"](%109),\n",
       " %118 : Float(128:1, 128:128) = aten::t(%117), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.key # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0,\n",
       " %output.2 : Float(1:12800, 100:128, 128:1) = aten::matmul(%input.5, %118), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.key # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0,\n",
       " %x.3 : Float(1:12800, 100:128, 128:1) = aten::add_(%output.2, %116, %87), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.key # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1678:0,\n",
       " %121 : Tensor = prim::GetAttr[name=\"bias\"](%108),\n",
       " %122 : Tensor = prim::GetAttr[name=\"weight\"](%108),\n",
       " %123 : Float(128:1, 128:128) = aten::t(%122), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.value # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0,\n",
       " %output.3 : Float(1:12800, 100:128, 128:1) = aten::matmul(%input.5, %123), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.value # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0,\n",
       " %x.5 : Float(1:12800, 100:128, 128:1) = aten::add_(%output.3, %121, %87), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.value # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1678:0,\n",
       " %126 : int = aten::size(%x.1, %88), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:227:0,\n",
       " %127 : int = aten::size(%x.1, %87), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:227:0,\n",
       " %128 : int[] = prim::ListConstruct(%126, %127, %89, %90), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self,\n",
       " %x.2 : Float(1:12800, 100:128, 2:64, 64:1) = aten::view(%x.1, %128), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:228:0,\n",
       " %130 : int[] = prim::ListConstruct(%88, %89, %87, %91), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self,\n",
       " %query_layer.1 : Float(1:12800, 2:64, 100:128, 64:1) = aten::permute(%x.2, %130), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:229:0,\n",
       " %132 : int = aten::size(%x.3, %88), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:227:0,\n",
       " %133 : int = aten::size(%x.3, %87), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:227:0,\n",
       " %134 : int[] = prim::ListConstruct(%132, %133, %89, %90), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self,\n",
       " %x.4 : Float(1:12800, 100:128, 2:64, 64:1) = aten::view(%x.3, %134), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:228:0,\n",
       " %136 : int[] = prim::ListConstruct(%88, %89, %87, %91), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self,\n",
       " %key_layer.1 : Float(1:12800, 2:64, 100:128, 64:1) = aten::permute(%x.4, %136), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:229:0,\n",
       " %138 : int = aten::size(%x.5, %88), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:227:0,\n",
       " %139 : int = aten::size(%x.5, %87), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:227:0,\n",
       " %140 : int[] = prim::ListConstruct(%138, %139, %89, %90), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self,\n",
       " %x.6 : Float(1:12800, 100:128, 2:64, 64:1) = aten::view(%x.5, %140), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:228:0,\n",
       " %142 : int[] = prim::ListConstruct(%88, %89, %87, %91), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self,\n",
       " %value_layer.1 : Float(1:12800, 2:64, 100:128, 64:1) = aten::permute(%x.6, %142), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:229:0,\n",
       " %144 : Float(1:12800, 2:64, 64:1, 100:128) = aten::transpose(%key_layer.1, %92, %93), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:258:0,\n",
       " %attention_scores.1 : Float(1:20000, 2:10000, 100:100, 100:1) = aten::matmul(%query_layer.1, %144), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:258:0,\n",
       " %attention_scores.2 : Float(1:20000, 2:10000, 100:100, 100:1) = aten::div(%attention_scores.1, %94), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:259:0,\n",
       " %input.6 : Float(1:20000, 2:10000, 100:100, 100:1) = aten::add(%attention_scores.2, %attention_mask, %87), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:262:0,\n",
       " %input.7 : Float(1:20000, 2:10000, 100:100, 100:1) = aten::softmax(%input.6, %92, %95), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1498:0,\n",
       " %attention_probs.1 : Float(1:20000, 2:10000, 100:100, 100:1) = aten::dropout(%input.7, %97, %96), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.dropout # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:973:0,\n",
       " %context_layer.1 : Float(1:12800, 2:6400, 100:64, 64:1) = aten::matmul(%attention_probs.1, %value_layer.1), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:275:0,\n",
       " %151 : int[] = prim::ListConstruct(%88, %89, %87, %91), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self,\n",
       " %152 : Float(1:12800, 100:64, 2:6400, 64:1) = aten::permute(%context_layer.1, %151), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:277:0,\n",
       " %context_layer.2 : Float(1:12800, 100:128, 2:64, 64:1) = aten::contiguous(%152, %88), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:277:0,\n",
       " %154 : int = aten::size(%context_layer.2, %88), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:278:0,\n",
       " %155 : int = aten::size(%context_layer.2, %87), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:278:0,\n",
       " %156 : int[] = prim::ListConstruct(%154, %155, %98), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self,\n",
       " %input.8 : Float(1:12800, 100:128, 128:1) = aten::view(%context_layer.2, %156), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:279:0,\n",
       " %158 : __torch__.torch.nn.modules.normalization.___torch_mangle_9.LayerNorm = prim::GetAttr[name=\"LayerNorm\"](%106),\n",
       " %159 : __torch__.torch.nn.modules.linear.___torch_mangle_8.Linear = prim::GetAttr[name=\"dense\"](%106),\n",
       " %160 : Tensor = prim::GetAttr[name=\"bias\"](%159),\n",
       " %161 : Tensor = prim::GetAttr[name=\"weight\"](%159),\n",
       " %162 : Float(128:1, 128:128) = aten::t(%161), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.output/__module.encoder.layer.0.attention.output.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0,\n",
       " %output.4 : Float(1:12800, 100:128, 128:1) = aten::matmul(%input.8, %162), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.output/__module.encoder.layer.0.attention.output.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0,\n",
       " %input.9 : Float(1:12800, 100:128, 128:1) = aten::add_(%output.4, %160, %87), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.output/__module.encoder.layer.0.attention.output.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1678:0,\n",
       " %hidden_states.1 : Float(1:12800, 100:128, 128:1) = aten::dropout(%input.9, %97, %96), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.output/__module.encoder.layer.0.attention.output.dropout # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:973:0,\n",
       " %input.10 : Float(1:12800, 100:128, 128:1) = aten::add(%hidden_states.1, %input.5, %87), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.output # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:295:0,\n",
       " %167 : Tensor = prim::GetAttr[name=\"bias\"](%158),\n",
       " %168 : Tensor = prim::GetAttr[name=\"weight\"](%158),\n",
       " %169 : int[] = prim::ListConstruct(%98), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.output/__module.encoder.layer.0.attention.output.LayerNorm,\n",
       " %input_tensor.1 : Float(1:12800, 100:128, 128:1) = aten::layer_norm(%input.10, %169, %168, %167, %86, %85), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.output/__module.encoder.layer.0.attention.output.LayerNorm # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:2048:0,\n",
       " %171 : __torch__.torch.nn.modules.linear.___torch_mangle_11.Linear = prim::GetAttr[name=\"dense\"](%104),\n",
       " %172 : Tensor = prim::GetAttr[name=\"bias\"](%171),\n",
       " %173 : Tensor = prim::GetAttr[name=\"weight\"](%171),\n",
       " %174 : Float(128:1, 512:128) = aten::t(%173), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.intermediate/__module.encoder.layer.0.intermediate.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0,\n",
       " %output.5 : Float(1:51200, 100:512, 512:1) = aten::matmul(%input_tensor.1, %174), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.intermediate/__module.encoder.layer.0.intermediate.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0,\n",
       " %input.11 : Float(1:51200, 100:512, 512:1) = aten::add_(%output.5, %172, %87), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.intermediate/__module.encoder.layer.0.intermediate.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1678:0,\n",
       " %input.12 : Float(1:51200, 100:512, 512:1) = aten::gelu(%input.11), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.intermediate # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1369:0,\n",
       " %178 : __torch__.torch.nn.modules.normalization.___torch_mangle_13.LayerNorm = prim::GetAttr[name=\"LayerNorm\"](%103),\n",
       " %179 : __torch__.torch.nn.modules.linear.___torch_mangle_12.Linear = prim::GetAttr[name=\"dense\"](%103),\n",
       " %180 : Tensor = prim::GetAttr[name=\"bias\"](%179),\n",
       " %181 : Tensor = prim::GetAttr[name=\"weight\"](%179),\n",
       " %182 : Float(512:1, 128:512) = aten::t(%181), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.output/__module.encoder.layer.0.output.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0,\n",
       " %output.6 : Float(1:12800, 100:128, 128:1) = aten::matmul(%input.12, %182), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.output/__module.encoder.layer.0.output.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0,\n",
       " %input.13 : Float(1:12800, 100:128, 128:1) = aten::add_(%output.6, %180, %87), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.output/__module.encoder.layer.0.output.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1678:0,\n",
       " %hidden_states.2 : Float(1:12800, 100:128, 128:1) = aten::dropout(%input.13, %97, %96), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.output/__module.encoder.layer.0.output.dropout # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:973:0,\n",
       " %input.14 : Float(1:12800, 100:128, 128:1) = aten::add(%hidden_states.2, %input_tensor.1, %87), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.output # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:371:0,\n",
       " %187 : Tensor = prim::GetAttr[name=\"bias\"](%178),\n",
       " %188 : Tensor = prim::GetAttr[name=\"weight\"](%178),\n",
       " %189 : int[] = prim::ListConstruct(%98), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.output/__module.encoder.layer.0.output.LayerNorm,\n",
       " %input.15 : Float(1:12800, 100:128, 128:1) = aten::layer_norm(%input.14, %189, %188, %187, %86, %85), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.output/__module.encoder.layer.0.output.LayerNorm # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:2048:0,\n",
       " %191 : __torch__.transformers.modeling_bert.___torch_mangle_30.BertOutput = prim::GetAttr[name=\"output\"](%100),\n",
       " %192 : __torch__.transformers.modeling_bert.___torch_mangle_26.BertIntermediate = prim::GetAttr[name=\"intermediate\"](%100),\n",
       " %193 : __torch__.transformers.modeling_bert.___torch_mangle_24.BertAttention = prim::GetAttr[name=\"attention\"](%100),\n",
       " %194 : __torch__.transformers.modeling_bert.___torch_mangle_23.BertSelfOutput = prim::GetAttr[name=\"output\"](%193),\n",
       " %195 : __torch__.transformers.modeling_bert.___torch_mangle_19.BertSelfAttention = prim::GetAttr[name=\"self\"](%193),\n",
       " %196 : __torch__.torch.nn.modules.linear.___torch_mangle_17.Linear = prim::GetAttr[name=\"value\"](%195),\n",
       " %197 : __torch__.torch.nn.modules.linear.___torch_mangle_16.Linear = prim::GetAttr[name=\"key\"](%195),\n",
       " %198 : __torch__.torch.nn.modules.linear.___torch_mangle_15.Linear = prim::GetAttr[name=\"query\"](%195),\n",
       " %199 : Tensor = prim::GetAttr[name=\"bias\"](%198),\n",
       " %200 : Tensor = prim::GetAttr[name=\"weight\"](%198),\n",
       " %201 : Float(128:1, 128:128) = aten::t(%200), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self/__module.encoder.layer.1.attention.self.query # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0,\n",
       " %output.7 : Float(1:12800, 100:128, 128:1) = aten::matmul(%input.15, %201), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self/__module.encoder.layer.1.attention.self.query # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0,\n",
       " %x.7 : Float(1:12800, 100:128, 128:1) = aten::add_(%output.7, %199, %87), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self/__module.encoder.layer.1.attention.self.query # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1678:0,\n",
       " %204 : Tensor = prim::GetAttr[name=\"bias\"](%197),\n",
       " %205 : Tensor = prim::GetAttr[name=\"weight\"](%197),\n",
       " %206 : Float(128:1, 128:128) = aten::t(%205), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self/__module.encoder.layer.1.attention.self.key # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0,\n",
       " %output.8 : Float(1:12800, 100:128, 128:1) = aten::matmul(%input.15, %206), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self/__module.encoder.layer.1.attention.self.key # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0,\n",
       " %x.9 : Float(1:12800, 100:128, 128:1) = aten::add_(%output.8, %204, %87), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self/__module.encoder.layer.1.attention.self.key # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1678:0,\n",
       " %209 : Tensor = prim::GetAttr[name=\"bias\"](%196),\n",
       " %210 : Tensor = prim::GetAttr[name=\"weight\"](%196),\n",
       " %211 : Float(128:1, 128:128) = aten::t(%210), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self/__module.encoder.layer.1.attention.self.value # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0,\n",
       " %output.9 : Float(1:12800, 100:128, 128:1) = aten::matmul(%input.15, %211), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self/__module.encoder.layer.1.attention.self.value # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0,\n",
       " %x.11 : Float(1:12800, 100:128, 128:1) = aten::add_(%output.9, %209, %87), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self/__module.encoder.layer.1.attention.self.value # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1678:0,\n",
       " %214 : int = aten::size(%x.7, %88), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:227:0,\n",
       " %215 : int = aten::size(%x.7, %87), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:227:0,\n",
       " %216 : int[] = prim::ListConstruct(%214, %215, %89, %90), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self,\n",
       " %x.8 : Float(1:12800, 100:128, 2:64, 64:1) = aten::view(%x.7, %216), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:228:0,\n",
       " %218 : int[] = prim::ListConstruct(%88, %89, %87, %91), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self,\n",
       " %query_layer : Float(1:12800, 2:64, 100:128, 64:1) = aten::permute(%x.8, %218), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:229:0,\n",
       " %220 : int = aten::size(%x.9, %88), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:227:0,\n",
       " %221 : int = aten::size(%x.9, %87), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:227:0,\n",
       " %222 : int[] = prim::ListConstruct(%220, %221, %89, %90), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self,\n",
       " %x.10 : Float(1:12800, 100:128, 2:64, 64:1) = aten::view(%x.9, %222), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:228:0,\n",
       " %224 : int[] = prim::ListConstruct(%88, %89, %87, %91), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self,\n",
       " %key_layer : Float(1:12800, 2:64, 100:128, 64:1) = aten::permute(%x.10, %224), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:229:0,\n",
       " %226 : int = aten::size(%x.11, %88), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:227:0,\n",
       " %227 : int = aten::size(%x.11, %87), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:227:0,\n",
       " %228 : int[] = prim::ListConstruct(%226, %227, %89, %90), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self,\n",
       " %x : Float(1:12800, 100:128, 2:64, 64:1) = aten::view(%x.11, %228), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:228:0,\n",
       " %230 : int[] = prim::ListConstruct(%88, %89, %87, %91), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self,\n",
       " %value_layer : Float(1:12800, 2:64, 100:128, 64:1) = aten::permute(%x, %230), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:229:0,\n",
       " %232 : Float(1:12800, 2:64, 64:1, 100:128) = aten::transpose(%key_layer, %92, %93), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:258:0,\n",
       " %attention_scores.3 : Float(1:20000, 2:10000, 100:100, 100:1) = aten::matmul(%query_layer, %232), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:258:0,\n",
       " %attention_scores : Float(1:20000, 2:10000, 100:100, 100:1) = aten::div(%attention_scores.3, %94), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:259:0,\n",
       " %input.16 : Float(1:20000, 2:10000, 100:100, 100:1) = aten::add(%attention_scores, %attention_mask, %87), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:262:0,\n",
       " %input.17 : Float(1:20000, 2:10000, 100:100, 100:1) = aten::softmax(%input.16, %92, %95), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1498:0,\n",
       " %attention_probs : Float(1:20000, 2:10000, 100:100, 100:1) = aten::dropout(%input.17, %97, %96), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self/__module.encoder.layer.1.attention.self.dropout # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:973:0,\n",
       " %context_layer.3 : Float(1:12800, 2:6400, 100:64, 64:1) = aten::matmul(%attention_probs, %value_layer), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:275:0,\n",
       " %239 : int[] = prim::ListConstruct(%88, %89, %87, %91), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self,\n",
       " %240 : Float(1:12800, 100:64, 2:6400, 64:1) = aten::permute(%context_layer.3, %239), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:277:0,\n",
       " %context_layer : Float(1:12800, 100:128, 2:64, 64:1) = aten::contiguous(%240, %88), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:277:0,\n",
       " %242 : int = aten::size(%context_layer, %88), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:278:0,\n",
       " %243 : int = aten::size(%context_layer, %87), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:278:0,\n",
       " %244 : int[] = prim::ListConstruct(%242, %243, %98), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self,\n",
       " %input.18 : Float(1:12800, 100:128, 128:1) = aten::view(%context_layer, %244), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:279:0,\n",
       " %246 : __torch__.torch.nn.modules.normalization.___torch_mangle_21.LayerNorm = prim::GetAttr[name=\"LayerNorm\"](%194),\n",
       " %247 : __torch__.torch.nn.modules.linear.___torch_mangle_20.Linear = prim::GetAttr[name=\"dense\"](%194),\n",
       " %248 : Tensor = prim::GetAttr[name=\"bias\"](%247),\n",
       " %249 : Tensor = prim::GetAttr[name=\"weight\"](%247),\n",
       " %250 : Float(128:1, 128:128) = aten::t(%249), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.output/__module.encoder.layer.1.attention.output.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0,\n",
       " %output.10 : Float(1:12800, 100:128, 128:1) = aten::matmul(%input.18, %250), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.output/__module.encoder.layer.1.attention.output.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0,\n",
       " %input.19 : Float(1:12800, 100:128, 128:1) = aten::add_(%output.10, %248, %87), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.output/__module.encoder.layer.1.attention.output.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1678:0,\n",
       " %hidden_states.3 : Float(1:12800, 100:128, 128:1) = aten::dropout(%input.19, %97, %96), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.output/__module.encoder.layer.1.attention.output.dropout # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:973:0,\n",
       " %input.20 : Float(1:12800, 100:128, 128:1) = aten::add(%hidden_states.3, %input.15, %87), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.output # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:295:0,\n",
       " %255 : Tensor = prim::GetAttr[name=\"bias\"](%246),\n",
       " %256 : Tensor = prim::GetAttr[name=\"weight\"](%246),\n",
       " %257 : int[] = prim::ListConstruct(%98), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.output/__module.encoder.layer.1.attention.output.LayerNorm,\n",
       " %input_tensor : Float(1:12800, 100:128, 128:1) = aten::layer_norm(%input.20, %257, %256, %255, %86, %85), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.output/__module.encoder.layer.1.attention.output.LayerNorm # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:2048:0,\n",
       " %259 : __torch__.torch.nn.modules.linear.___torch_mangle_25.Linear = prim::GetAttr[name=\"dense\"](%192),\n",
       " %260 : Tensor = prim::GetAttr[name=\"bias\"](%259),\n",
       " %261 : Tensor = prim::GetAttr[name=\"weight\"](%259),\n",
       " %262 : Float(128:1, 512:128) = aten::t(%261), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.intermediate/__module.encoder.layer.1.intermediate.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0,\n",
       " %output.11 : Float(1:51200, 100:512, 512:1) = aten::matmul(%input_tensor, %262), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.intermediate/__module.encoder.layer.1.intermediate.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0,\n",
       " %input.21 : Float(1:51200, 100:512, 512:1) = aten::add_(%output.11, %260, %87), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.intermediate/__module.encoder.layer.1.intermediate.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1678:0,\n",
       " %input.22 : Float(1:51200, 100:512, 512:1) = aten::gelu(%input.21), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.intermediate # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1369:0,\n",
       " %266 : __torch__.torch.nn.modules.normalization.___torch_mangle_28.LayerNorm = prim::GetAttr[name=\"LayerNorm\"](%191),\n",
       " %267 : __torch__.torch.nn.modules.linear.___torch_mangle_27.Linear = prim::GetAttr[name=\"dense\"](%191),\n",
       " %268 : Tensor = prim::GetAttr[name=\"bias\"](%267),\n",
       " %269 : Tensor = prim::GetAttr[name=\"weight\"](%267),\n",
       " %270 : Float(512:1, 128:512) = aten::t(%269), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.output/__module.encoder.layer.1.output.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0,\n",
       " %output : Float(1:12800, 100:128, 128:1) = aten::matmul(%input.22, %270), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.output/__module.encoder.layer.1.output.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0,\n",
       " %input.23 : Float(1:12800, 100:128, 128:1) = aten::add_(%output, %268, %87), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.output/__module.encoder.layer.1.output.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1678:0,\n",
       " %hidden_states.4 : Float(1:12800, 100:128, 128:1) = aten::dropout(%input.23, %97, %96), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.output/__module.encoder.layer.1.output.dropout # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:973:0,\n",
       " %input.24 : Float(1:12800, 100:128, 128:1) = aten::add(%hidden_states.4, %input_tensor, %87), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.output # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:371:0,\n",
       " %275 : Tensor = prim::GetAttr[name=\"bias\"](%266),\n",
       " %276 : Tensor = prim::GetAttr[name=\"weight\"](%266),\n",
       " %277 : int[] = prim::ListConstruct(%98), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.output/__module.encoder.layer.1.output.LayerNorm,\n",
       " %hidden_states : Float(1:12800, 100:128, 128:1) = aten::layer_norm(%input.24, %277, %276, %275, %86, %85), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.output/__module.encoder.layer.1.output.LayerNorm # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:2048:0,\n",
       " %279 : int = prim::Constant[value=1](), scope: __module.pooler # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:517:0,\n",
       " %280 : int = prim::Constant[value=9223372036854775807](), scope: __module.pooler # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:517:0,\n",
       " %281 : int = prim::Constant[value=0](), scope: __module.pooler # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:517:0,\n",
       " %282 : __torch__.torch.nn.modules.linear.___torch_mangle_32.Linear = prim::GetAttr[name=\"dense\"](%2),\n",
       " %283 : Float(1:12800, 100:128, 128:1) = aten::slice(%hidden_states, %281, %281, %280, %279), scope: __module.pooler # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:517:0,\n",
       " %input.25 : Float(1:12800, 128:1) = aten::select(%283, %279, %281), scope: __module.pooler # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:517:0,\n",
       " %285 : Tensor = prim::GetAttr[name=\"bias\"](%282),\n",
       " %286 : Tensor = prim::GetAttr[name=\"weight\"](%282),\n",
       " %287 : Float(128:1, 128:128) = aten::t(%286), scope: __module.pooler/__module.pooler.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1674:0,\n",
       " %input : Float(1:128, 128:1) = aten::addmm(%285, %input.25, %287, %279, %279), scope: __module.pooler/__module.pooler.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1674:0,\n",
       " %289 : Float(1:128, 128:1) = aten::tanh(%input), scope: __module.pooler/__module.pooler.activation # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/modules/activation.py:350:0,\n",
       " %54 : (Float(1:12800, 100:128, 128:1), Float(1:128, 128:1)) = prim::TupleConstruct(%hidden_states, %289)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ni=list(graph.nodes())\n",
    "ni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "%2 : __torch__.transformers.modeling_bert.BertPooler = prim::GetAttr[name=\"pooler\"](%self.1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ni[0].output().node()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2 defined in (%2 : __torch__.transformers.modeling_bert.BertPooler = prim::GetAttr[name=\"pooler\"](%self.1)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ni[0].output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78 defined in (%78 : Float(1:12800, 100:128, 128:1) = aten::add(%inputs_embeds, %position_embeddings, %63), scope: __module.embeddings # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:201:0\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ni[72].output() # build all input leaf data nodes, then construct the opnode with input and output nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "%2 : __torch__.transformers.modeling_bert.BertPooler = prim::GetAttr[name=\"pooler\"](%self.1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ni[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2 defined in (%2 : __torch__.transformers.modeling_bert.BertPooler = prim::GetAttr[name=\"pooler\"](%self.1)\n",
       " )]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ni[0].outputs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[self.1 defined in (%self.1 : __torch__.transformers.modeling_bert.BertModel, %input_ids : Long(1:100, 100:1) = prim::Param()\n",
       " )]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ni[0].inputs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "%self.1 : __torch__.transformers.modeling_bert.BertModel, %input_ids : Long(1:100, 100:1) = prim::Param()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pn=ni[0].input().node()\n",
    "pn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[self.1 defined in (%self.1 : __torch__.transformers.modeling_bert.BertModel, %input_ids : Long(1:100, 100:1) = prim::Param()\n",
       " ),\n",
       " input_ids defined in (%self.1 : __torch__.transformers.modeling_bert.BertModel, %input_ids : Long(1:100, 100:1) = prim::Param()\n",
       " )]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gi=list(graph.inputs())\n",
    "gi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__torch__.transformers.modeling_bert.BertModel"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(gi[0].node().outputs())[0].type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 100]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(gi[1].node().outputs())[1].type().sizes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'encoder.layer.0.attention.output'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'encoder/encoder.layer.0/encoder.layer.0.attention/encoder.layer.0.attention.output'.split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%self.1 : __torch__.transformers.modeling_bert.BertModel, %input_ids : Long(1:100, 100:1) = prim::Param()\n",
      "\n",
      "%self.1 : __torch__.transformers.modeling_bert.BertModel, %input_ids : Long(1:100, 100:1) = prim::Param()\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(pn)\n",
    "print(gi[1].node())\n",
    "pn==gi[0].node()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[%2 : __torch__.transformers.modeling_bert.BertPooler = prim::GetAttr[name=\"pooler\"](%self.1),\n",
       " %3 : __torch__.transformers.modeling_bert.BertEncoder = prim::GetAttr[name=\"encoder\"](%self.1),\n",
       " %4 : __torch__.transformers.modeling_bert.BertEmbeddings = prim::GetAttr[name=\"embeddings\"](%self.1)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i.user for i in gi[0].uses()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[54 defined in (%54 : (Float(1:12800, 100:128, 128:1), Float(1:128, 128:1)) = prim::TupleConstruct(%hidden_states, %289)\n",
       " )]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "go=list(graph.outputs())\n",
    "go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.44.1 (20200629.0846)\n",
       " -->\n",
       "<!-- Title: G Pages: 1 -->\n",
       "<svg width=\"296pt\" height=\"438pt\"\n",
       " viewBox=\"0.00 0.00 296.00 438.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 434)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-434 292,-434 292,4 -4,4\"/>\n",
       "<g id=\"clust1\" class=\"cluster\">\n",
       "<title>cluster_0</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"lightgrey\" points=\"8,-56 8,-386 180,-386 180,-56 8,-56\"/>\n",
       "<text text-anchor=\"middle\" x=\"94\" y=\"-370.8\" font-family=\"Times,serif\" font-size=\"14.00\">process #1</text>\n",
       "</g>\n",
       "<g id=\"clust2\" class=\"cluster\">\n",
       "<title>cluster_0</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"lightblue\" points=\"98,-64 98,-355 172,-355 172,-64 98,-64\"/>\n",
       "<text text-anchor=\"middle\" x=\"135\" y=\"-339.8\" font-family=\"Times,serif\" font-size=\"14.00\">process #3</text>\n",
       "</g>\n",
       "<g id=\"clust3\" class=\"cluster\">\n",
       "<title>cluster_1</title>\n",
       "<polygon fill=\"none\" stroke=\"blue\" points=\"206,-64 206,-355 280,-355 280,-64 206,-64\"/>\n",
       "<text text-anchor=\"middle\" x=\"243\" y=\"-339.8\" font-family=\"Times,serif\" font-size=\"14.00\">process #2</text>\n",
       "</g>\n",
       "<!-- a0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>a0</title>\n",
       "<ellipse fill=\"white\" stroke=\"white\" cx=\"63\" cy=\"-306\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"63\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">a0</text>\n",
       "</g>\n",
       "<!-- a1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>a1</title>\n",
       "<ellipse fill=\"white\" stroke=\"white\" cx=\"63\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"63\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">a1</text>\n",
       "</g>\n",
       "<!-- a0&#45;&gt;a1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>a0&#45;&gt;a1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M63,-287.7C63,-279.98 63,-270.71 63,-262.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"66.5,-262.1 63,-252.1 59.5,-262.1 66.5,-262.1\"/>\n",
       "</g>\n",
       "<!-- a2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>a2</title>\n",
       "<ellipse fill=\"white\" stroke=\"white\" cx=\"63\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"63\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">a2</text>\n",
       "</g>\n",
       "<!-- a1&#45;&gt;a2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>a1&#45;&gt;a2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M63,-215.7C63,-207.98 63,-198.71 63,-190.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"66.5,-190.1 63,-180.1 59.5,-190.1 66.5,-190.1\"/>\n",
       "</g>\n",
       "<!-- b3 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>b3</title>\n",
       "<ellipse fill=\"lightgrey\" stroke=\"black\" cx=\"241\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"241\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">b3</text>\n",
       "</g>\n",
       "<!-- a1&#45;&gt;b3 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>a1&#45;&gt;b3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M82.88,-221.77C86.54,-219.79 90.37,-217.79 94,-216 129.71,-198.41 144.97,-204.93 176,-180 187.85,-170.48 210.03,-138.49 225.16,-115.59\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"228.21,-117.31 230.76,-107.02 222.36,-113.47 228.21,-117.31\"/>\n",
       "</g>\n",
       "<!-- a3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>a3</title>\n",
       "<ellipse fill=\"white\" stroke=\"white\" cx=\"63\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"63\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">a3</text>\n",
       "</g>\n",
       "<!-- a2&#45;&gt;a3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>a2&#45;&gt;a3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M63,-143.7C63,-135.98 63,-126.71 63,-118.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"66.5,-118.1 63,-108.1 59.5,-118.1 66.5,-118.1\"/>\n",
       "</g>\n",
       "<!-- a3&#45;&gt;a0 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>a3&#45;&gt;a0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M49.25,-105.93C41.04,-115.9 31.38,-129.75 27,-144 12.89,-189.88 12.89,-206.12 27,-252 30.29,-262.69 36.54,-273.15 42.93,-281.92\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"40.35,-284.31 49.25,-290.07 45.88,-280.02 40.35,-284.31\"/>\n",
       "</g>\n",
       "<!-- end -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>end</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"170,-36 134,-36 134,0 170,0 170,-36\"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"146,-36 134,-24 \"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"134,-12 146,0 \"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"158,0 170,-12 \"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"170,-24 158,-36 \"/>\n",
       "<text text-anchor=\"middle\" x=\"152\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">end</text>\n",
       "</g>\n",
       "<!-- a3&#45;&gt;end -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>a3&#45;&gt;end</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M75.85,-73.77C81.17,-67.89 87.59,-61.32 94,-56 103.57,-48.06 114.95,-40.46 125.09,-34.23\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"127.17,-37.07 133.96,-28.93 123.58,-31.06 127.17,-37.07\"/>\n",
       "</g>\n",
       "<!-- c0 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>c0</title>\n",
       "<ellipse fill=\"white\" stroke=\"white\" cx=\"135\" cy=\"-306\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"135\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">c0</text>\n",
       "</g>\n",
       "<!-- c1 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>c1</title>\n",
       "<ellipse fill=\"white\" stroke=\"white\" cx=\"135\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"135\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">c1</text>\n",
       "</g>\n",
       "<!-- c0&#45;&gt;c1 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>c0&#45;&gt;c1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M135,-287.7C135,-279.98 135,-270.71 135,-262.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"138.5,-262.1 135,-252.1 131.5,-262.1 138.5,-262.1\"/>\n",
       "</g>\n",
       "<!-- c2 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>c2</title>\n",
       "<ellipse fill=\"white\" stroke=\"white\" cx=\"135\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"135\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">c2</text>\n",
       "</g>\n",
       "<!-- c1&#45;&gt;c2 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>c1&#45;&gt;c2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M135,-215.7C135,-207.98 135,-198.71 135,-190.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"138.5,-190.1 135,-180.1 131.5,-190.1 138.5,-190.1\"/>\n",
       "</g>\n",
       "<!-- c3 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>c3</title>\n",
       "<ellipse fill=\"white\" stroke=\"white\" cx=\"135\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"135\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">c3</text>\n",
       "</g>\n",
       "<!-- c2&#45;&gt;c3 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>c2&#45;&gt;c3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M135,-143.7C135,-135.98 135,-126.71 135,-118.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"138.5,-118.1 135,-108.1 131.5,-118.1 138.5,-118.1\"/>\n",
       "</g>\n",
       "<!-- b0 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>b0</title>\n",
       "<ellipse fill=\"lightgrey\" stroke=\"black\" cx=\"241\" cy=\"-306\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"241\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">b0</text>\n",
       "</g>\n",
       "<!-- b1 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>b1</title>\n",
       "<ellipse fill=\"lightgrey\" stroke=\"black\" cx=\"243\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"243\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">b1</text>\n",
       "</g>\n",
       "<!-- b0&#45;&gt;b1 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>b0&#45;&gt;b1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M241.49,-287.7C241.71,-279.98 241.98,-270.71 242.23,-262.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"245.72,-262.2 242.51,-252.1 238.73,-262 245.72,-262.2\"/>\n",
       "</g>\n",
       "<!-- b2 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>b2</title>\n",
       "<ellipse fill=\"lightgrey\" stroke=\"black\" cx=\"245\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"245\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">b2</text>\n",
       "</g>\n",
       "<!-- b1&#45;&gt;b2 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>b1&#45;&gt;b2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M243.49,-215.7C243.71,-207.98 243.98,-198.71 244.23,-190.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"247.72,-190.2 244.51,-180.1 240.73,-190 247.72,-190.2\"/>\n",
       "</g>\n",
       "<!-- b2&#45;&gt;a3 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>b2&#45;&gt;a3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M220.73,-153.83C190.49,-144.6 137.52,-127.41 94,-108 93.31,-107.69 92.61,-107.37 91.9,-107.04\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"93.28,-103.82 82.77,-102.47 90.14,-110.07 93.28,-103.82\"/>\n",
       "</g>\n",
       "<!-- b2&#45;&gt;b3 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>b2&#45;&gt;b3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M244.01,-143.7C243.57,-135.98 243.04,-126.71 242.55,-118.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"246.04,-117.89 241.98,-108.1 239.05,-118.29 246.04,-117.89\"/>\n",
       "</g>\n",
       "<!-- b3&#45;&gt;end -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>b3&#45;&gt;end</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M224.26,-75.83C211.26,-65.61 193,-51.24 178.08,-39.51\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"180.22,-36.74 170.2,-33.31 175.89,-42.25 180.22,-36.74\"/>\n",
       "</g>\n",
       "<!-- start -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>start</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"152,-430 115.47,-412 152,-394 188.53,-412 152,-430\"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"126.23,-417.3 126.23,-406.7 \"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"141.24,-399.3 162.76,-399.3 \"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"177.77,-406.7 177.77,-417.3 \"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"162.76,-424.7 141.24,-424.7 \"/>\n",
       "<text text-anchor=\"middle\" x=\"152\" y=\"-408.3\" font-family=\"Times,serif\" font-size=\"14.00\">start</text>\n",
       "</g>\n",
       "<!-- start&#45;&gt;a0 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>start&#45;&gt;a0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M128.61,-405.52C116.91,-401.74 103.3,-395.61 94,-386 80.26,-371.79 72.4,-350.78 68.04,-334\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"71.44,-333.14 65.76,-324.19 64.62,-334.73 71.44,-333.14\"/>\n",
       "</g>\n",
       "<!-- start&#45;&gt;b0 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>start&#45;&gt;b0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M163.42,-399.47C167.47,-395.29 172,-390.5 176,-386 192.13,-367.86 209.57,-346.57 222.32,-330.66\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"225.38,-332.43 228.88,-322.43 219.91,-328.07 225.38,-332.43\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x1393f1700>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from graphviz import Digraph\n",
    "\n",
    "g = Digraph('G')\n",
    "\n",
    "c0 = Digraph('cluster_0')\n",
    "c0.body.append('style=filled')\n",
    "c0.body.append('color=lightgrey')\n",
    "c0.node_attr.update(style='filled', color='white')\n",
    "c0.edges([('a0', 'a1'), ('a1', 'a2'), ('a2', 'a3')])\n",
    "c0.body.append('label =\"process #1\"')\n",
    "\n",
    "c2 = Digraph('cluster_0')\n",
    "c2.body.append('style=filled')\n",
    "c2.body.append('color=lightgrey')\n",
    "c2.node_attr.update(style='filled', color='white')\n",
    "c2.edges([('c0', 'c1'), ('c1', 'c2'), ('c2', 'c3')])\n",
    "c2.body.append('label =\"process #3\"')\n",
    "c2.body.append('color=lightblue')\n",
    "c0.subgraph(c2)\n",
    "\n",
    "c1 = Digraph('cluster_1')\n",
    "c1.node_attr.update(style='filled')\n",
    "c1.edges([('b0', 'b1'), ('b1', 'b2'), ('b2', 'b3')])\n",
    "c1.body.append('label =\"process #2\"')\n",
    "c1.body.append('color=blue')\n",
    "\n",
    "g.subgraph(c0)\n",
    "g.subgraph(c1)\n",
    "\n",
    "g.edge('start', 'a0')\n",
    "g.edge('start', 'b0')\n",
    "g.edge('a1', 'b3')\n",
    "g.edge('b2', 'a3')\n",
    "g.edge('a3', 'a0')\n",
    "g.edge('a3', 'end')\n",
    "g.edge('b3', 'end')\n",
    "\n",
    "g.node('start', shape='Mdiamond')\n",
    "g.node('end', shape='Msquare')\n",
    "\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub_scopes='encoder.layer.0.attention.output.LayerNorm'.split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'false'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'true' if '' and len(''.split('.')) else 'false'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 encoder.layer.0.attention.output encoder.layer.0.attention.output.LayerNorm\n",
      "5 encoder.layer.0.attention encoder.layer.0.attention.output\n",
      "4 encoder.layer.0 encoder.layer.0.attention\n",
      "3 encoder.layer encoder.layer.0\n",
      "2 encoder encoder.layer\n",
      "1  encoder\n"
     ]
    }
   ],
   "source": [
    "sub_scopes='encoder.layer.0.attention.output.LayerNorm'.split('.')\n",
    "for si in range(len(sub_scopes), 0, -1):\n",
    "    p_scope = '.'.join(sub_scopes[0:si-1])\n",
    "    child_scope = '.'.join(sub_scopes[0:si])\n",
    "    print(si, p_scope, child_scope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
