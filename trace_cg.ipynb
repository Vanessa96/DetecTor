{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# import autoreload\n",
    "# ?autoreload\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import time\n",
    "from transformers import AutoModel\n",
    "from transformers import AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calibrate_e_ml import calibrate_e_ml\n",
    "from cg.node import construct_aggregation_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 100\n",
    "bs = 4\n",
    "input_ids = torch.randint(1000, size=(bs, seq_len), dtype=torch.long, device='cpu')\n",
    "model_name = \"prajjwal1/bert-tiny\"\n",
    "\n",
    "information = calibrate_e_ml(model_name, bs, seq_len, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'embedding': [{'name': 'embeddings.word_embeddings:Embedding',\n",
       "               'module': Embedding(30522, 128, padding_idx=0),\n",
       "               'inputs': (torch.Size([4, 100]), torch.int64),\n",
       "               'outputs': (torch.Size([4, 100, 128]), torch.float32),\n",
       "               'runtime': 0.00029243610333651304},\n",
       "              {'name': 'embeddings.position_embeddings:Embedding',\n",
       "               'module': Embedding(512, 128),\n",
       "               'inputs': (torch.Size([1, 100]), torch.int64),\n",
       "               'outputs': (torch.Size([1, 100, 128]), torch.float32),\n",
       "               'runtime': 0.00010158796794712543},\n",
       "              {'name': 'embeddings.token_type_embeddings:Embedding',\n",
       "               'module': Embedding(2, 128),\n",
       "               'inputs': (torch.Size([4, 100]), torch.int64),\n",
       "               'outputs': (torch.Size([4, 100, 128]), torch.float32),\n",
       "               'runtime': 0.0001900040078908205}],\n",
       "             'layernorm': [{'name': 'embeddings.LayerNorm:LayerNorm',\n",
       "               'module': LayerNorm((128,), eps=1e-12, elementwise_affine=True),\n",
       "               'inputs': (torch.Size([4, 100, 128]), torch.float32),\n",
       "               'outputs': (torch.Size([4, 100, 128]), torch.float32),\n",
       "               'runtime': 0.00021478300914168358},\n",
       "              {'name': 'encoder.layer.0.attention.output.LayerNorm:LayerNorm',\n",
       "               'module': LayerNorm((128,), eps=1e-12, elementwise_affine=True),\n",
       "               'inputs': (torch.Size([4, 100, 128]), torch.float32),\n",
       "               'outputs': (torch.Size([4, 100, 128]), torch.float32),\n",
       "               'runtime': 0.0002074039075523615},\n",
       "              {'name': 'encoder.layer.0.output.LayerNorm:LayerNorm',\n",
       "               'module': LayerNorm((128,), eps=1e-12, elementwise_affine=True),\n",
       "               'inputs': (torch.Size([4, 100, 128]), torch.float32),\n",
       "               'outputs': (torch.Size([4, 100, 128]), torch.float32),\n",
       "               'runtime': 0.0001484300009906292},\n",
       "              {'name': 'encoder.layer.1.attention.output.LayerNorm:LayerNorm',\n",
       "               'module': LayerNorm((128,), eps=1e-12, elementwise_affine=True),\n",
       "               'inputs': (torch.Size([4, 100, 128]), torch.float32),\n",
       "               'outputs': (torch.Size([4, 100, 128]), torch.float32),\n",
       "               'runtime': 9.803194552659988e-05},\n",
       "              {'name': 'encoder.layer.1.output.LayerNorm:LayerNorm',\n",
       "               'module': LayerNorm((128,), eps=1e-12, elementwise_affine=True),\n",
       "               'inputs': (torch.Size([4, 100, 128]), torch.float32),\n",
       "               'outputs': (torch.Size([4, 100, 128]), torch.float32),\n",
       "               'runtime': 0.00016096897888928652}],\n",
       "             'dropout': [{'name': 'embeddings.dropout:Dropout',\n",
       "               'module': Dropout(p=0.1, inplace=False),\n",
       "               'inputs': (torch.Size([4, 100, 128]), torch.float32),\n",
       "               'outputs': (torch.Size([4, 100, 128]), torch.float32),\n",
       "               'runtime': 4.0643964894115925e-05},\n",
       "              {'name': 'encoder.layer.0.attention.self.dropout:Dropout',\n",
       "               'module': Dropout(p=0.1, inplace=False),\n",
       "               'inputs': (torch.Size([4, 2, 100, 100]), torch.float32),\n",
       "               'outputs': (torch.Size([4, 2, 100, 100]), torch.float32),\n",
       "               'runtime': 2.8898008167743683e-05},\n",
       "              {'name': 'encoder.layer.0.attention.output.dropout:Dropout',\n",
       "               'module': Dropout(p=0.1, inplace=False),\n",
       "               'inputs': (torch.Size([4, 100, 128]), torch.float32),\n",
       "               'outputs': (torch.Size([4, 100, 128]), torch.float32),\n",
       "               'runtime': 2.889393363147974e-05},\n",
       "              {'name': 'encoder.layer.0.output.dropout:Dropout',\n",
       "               'module': Dropout(p=0.1, inplace=False),\n",
       "               'inputs': (torch.Size([4, 100, 128]), torch.float32),\n",
       "               'outputs': (torch.Size([4, 100, 128]), torch.float32),\n",
       "               'runtime': 2.873293124139309e-05},\n",
       "              {'name': 'encoder.layer.1.attention.self.dropout:Dropout',\n",
       "               'module': Dropout(p=0.1, inplace=False),\n",
       "               'inputs': (torch.Size([4, 2, 100, 100]), torch.float32),\n",
       "               'outputs': (torch.Size([4, 2, 100, 100]), torch.float32),\n",
       "               'runtime': 2.663105260580778e-05},\n",
       "              {'name': 'encoder.layer.1.attention.output.dropout:Dropout',\n",
       "               'module': Dropout(p=0.1, inplace=False),\n",
       "               'inputs': (torch.Size([4, 100, 128]), torch.float32),\n",
       "               'outputs': (torch.Size([4, 100, 128]), torch.float32),\n",
       "               'runtime': 1.8456019461154938e-05},\n",
       "              {'name': 'encoder.layer.1.output.dropout:Dropout',\n",
       "               'module': Dropout(p=0.1, inplace=False),\n",
       "               'inputs': (torch.Size([4, 100, 128]), torch.float32),\n",
       "               'outputs': (torch.Size([4, 100, 128]), torch.float32),\n",
       "               'runtime': 2.538005355745554e-05}],\n",
       "             'linear': [{'name': 'encoder.layer.0.attention.self.query:Linear',\n",
       "               'module': Linear(in_features=128, out_features=128, bias=True),\n",
       "               'inputs': (torch.Size([4, 100, 128]), torch.float32),\n",
       "               'outputs': (torch.Size([4, 100, 128]), torch.float32),\n",
       "               'runtime': 0.0007346970960497856},\n",
       "              {'name': 'encoder.layer.0.attention.self.key:Linear',\n",
       "               'module': Linear(in_features=128, out_features=128, bias=True),\n",
       "               'inputs': (torch.Size([4, 100, 128]), torch.float32),\n",
       "               'outputs': (torch.Size([4, 100, 128]), torch.float32),\n",
       "               'runtime': 0.0006267359713092446},\n",
       "              {'name': 'encoder.layer.0.attention.self.value:Linear',\n",
       "               'module': Linear(in_features=128, out_features=128, bias=True),\n",
       "               'inputs': (torch.Size([4, 100, 128]), torch.float32),\n",
       "               'outputs': (torch.Size([4, 100, 128]), torch.float32),\n",
       "               'runtime': 0.0006038571009412408},\n",
       "              {'name': 'encoder.layer.0.attention.output.dense:Linear',\n",
       "               'module': Linear(in_features=128, out_features=128, bias=True),\n",
       "               'inputs': (torch.Size([4, 100, 128]), torch.float32),\n",
       "               'outputs': (torch.Size([4, 100, 128]), torch.float32),\n",
       "               'runtime': 0.0006669990252703428},\n",
       "              {'name': 'encoder.layer.0.intermediate.dense:Linear',\n",
       "               'module': Linear(in_features=128, out_features=512, bias=True),\n",
       "               'inputs': (torch.Size([4, 100, 128]), torch.float32),\n",
       "               'outputs': (torch.Size([4, 100, 512]), torch.float32),\n",
       "               'runtime': 0.0019912280840799212},\n",
       "              {'name': 'encoder.layer.0.output.dense:Linear',\n",
       "               'module': Linear(in_features=512, out_features=128, bias=True),\n",
       "               'inputs': (torch.Size([4, 100, 512]), torch.float32),\n",
       "               'outputs': (torch.Size([4, 100, 128]), torch.float32),\n",
       "               'runtime': 0.0015629059635102749},\n",
       "              {'name': 'encoder.layer.1.attention.self.query:Linear',\n",
       "               'module': Linear(in_features=128, out_features=128, bias=True),\n",
       "               'inputs': (torch.Size([4, 100, 128]), torch.float32),\n",
       "               'outputs': (torch.Size([4, 100, 128]), torch.float32),\n",
       "               'runtime': 0.0004700570134446025},\n",
       "              {'name': 'encoder.layer.1.attention.self.key:Linear',\n",
       "               'module': Linear(in_features=128, out_features=128, bias=True),\n",
       "               'inputs': (torch.Size([4, 100, 128]), torch.float32),\n",
       "               'outputs': (torch.Size([4, 100, 128]), torch.float32),\n",
       "               'runtime': 0.00043580704368650913},\n",
       "              {'name': 'encoder.layer.1.attention.self.value:Linear',\n",
       "               'module': Linear(in_features=128, out_features=128, bias=True),\n",
       "               'inputs': (torch.Size([4, 100, 128]), torch.float32),\n",
       "               'outputs': (torch.Size([4, 100, 128]), torch.float32),\n",
       "               'runtime': 0.0004233700456097722},\n",
       "              {'name': 'encoder.layer.1.attention.output.dense:Linear',\n",
       "               'module': Linear(in_features=128, out_features=128, bias=True),\n",
       "               'inputs': (torch.Size([4, 100, 128]), torch.float32),\n",
       "               'outputs': (torch.Size([4, 100, 128]), torch.float32),\n",
       "               'runtime': 0.00042350892908871174},\n",
       "              {'name': 'encoder.layer.1.intermediate.dense:Linear',\n",
       "               'module': Linear(in_features=128, out_features=512, bias=True),\n",
       "               'inputs': (torch.Size([4, 100, 128]), torch.float32),\n",
       "               'outputs': (torch.Size([4, 100, 512]), torch.float32),\n",
       "               'runtime': 0.0013938279589638114},\n",
       "              {'name': 'encoder.layer.1.output.dense:Linear',\n",
       "               'module': Linear(in_features=512, out_features=128, bias=True),\n",
       "               'inputs': (torch.Size([4, 100, 512]), torch.float32),\n",
       "               'outputs': (torch.Size([4, 100, 128]), torch.float32),\n",
       "               'runtime': 0.0014983209548518062},\n",
       "              {'name': 'pooler.dense:Linear',\n",
       "               'module': Linear(in_features=128, out_features=128, bias=True),\n",
       "               'inputs': (torch.Size([4, 128]), torch.float32),\n",
       "               'outputs': (torch.Size([4, 128]), torch.float32),\n",
       "               'runtime': 8.357793558388948e-05}]})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'encoder.layer.0.attention.self.query:Linear', 'module': Linear(in_features=128, out_features=128, bias=True), 'inputs': (torch.Size([4, 100, 128]), torch.float32), 'outputs': (torch.Size([4, 100, 128]), torch.float32), 'runtime': 0.0007346970960497856}\n"
     ]
    }
   ],
   "source": [
    "level = information['linear'][0]\n",
    "print(level)\n",
    "fn = level['module']\n",
    "fname=level['name']\n",
    "fi_size, fi_dtype = level['inputs']\n",
    "fo_size, fo_dtype = level['outputs']\n",
    "fi = torch.rand(fi_size, dtype=fi_dtype)\n",
    "fo = torch.rand(fo_size, dtype=fo_dtype)\n",
    "\n",
    "fo_call = fn(fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.047593432012945\n"
     ]
    }
   ],
   "source": [
    "f_start = time.perf_counter()\n",
    "for _ in range(10000):\n",
    "    fo_call = fn(fi)\n",
    "f_end = time.perf_counter()\n",
    "print(f_end-f_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "graph(%self : __torch__.torch.nn.modules.linear.___torch_mangle_3.Linear,\n",
       "      %input : Float(4:12800, 100:128, 128:1, requires_grad=0, device=cpu)):\n",
       "  %2 : Tensor = prim::GetAttr[name=\"bias\"](%self)\n",
       "  %3 : Tensor = prim::GetAttr[name=\"weight\"](%self)\n",
       "  %4 : Float(128:1, 128:128, requires_grad=1, device=cpu) = aten::t(%3) # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1692:0\n",
       "  %output : Float(4:12800, 100:128, 128:1, requires_grad=0, device=cpu) = aten::matmul(%input, %4) # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1692:0\n",
       "  %6 : int = prim::Constant[value=1]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1694:0\n",
       "  %m_out : Float(4:12800, 100:128, 128:1, requires_grad=0, device=cpu) = aten::add_(%output, %2, %6) # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1694:0\n",
       "  return (%m_out)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace = torch.jit.trace(fn, fi)\n",
    "trace_graph = trace.inlined_graph\n",
    "trace_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qqcao/work/DetecTor/cg/op_counter.py:125: UserWarning: no counter available for prim::GetAttr!\n",
      "  warnings.warn(f'no counter available for {node.op}!')\n",
      "/Users/qqcao/work/DetecTor/cg/op_counter.py:125: UserWarning: no counter available for aten::t!\n",
      "  warnings.warn(f'no counter available for {node.op}!')\n",
      "/Users/qqcao/work/DetecTor/cg/op_counter.py:125: UserWarning: no counter available for prim::Constant!\n",
      "  warnings.warn(f'no counter available for {node.op}!')\n"
     ]
    }
   ],
   "source": [
    "graph, op_data_types = construct_aggregation_graph(trace_graph, fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(name=encoder.layer.0.attention.self.query:Linear,\n",
       "\tinputs=[\n",
       "\t\tDataNode(id=self, dtype=__torch__.torch.nn.modules.linear.___torch_mangle_3.Linear)\n",
       "\t\tDataNode(id=input, dtype=Float, shape=[4, 100, 128])],\n",
       "\tnodes=[\n",
       "\t\tOpNode(id=2, op=prim::GetAttr, \n",
       "\t\t\tinputs=[\n",
       "\t\t\t\tDataNode(id=self, dtype=__torch__.torch.nn.modules.linear.___torch_mangle_3.Linear)],\n",
       "\t\t\toutputs=[\n",
       "\t\t\t\tDataNode(id=2, dtype=None)],)\n",
       "\t\tOpNode(id=3, op=prim::GetAttr, \n",
       "\t\t\tinputs=[\n",
       "\t\t\t\tDataNode(id=self, dtype=__torch__.torch.nn.modules.linear.___torch_mangle_3.Linear)],\n",
       "\t\t\toutputs=[\n",
       "\t\t\t\tDataNode(id=3, dtype=None)],)\n",
       "\t\tOpNode(id=4, op=aten::t, \n",
       "\t\t\tinputs=[\n",
       "\t\t\t\tDataNode(id=3, dtype=None)],\n",
       "\t\t\toutputs=[\n",
       "\t\t\t\tDataNode(id=4, dtype=Float, shape=[128, 128])],)\n",
       "\t\tOpNode(id=output, op=aten::matmul, flops=13107200, mem_bytes=671744, \n",
       "\t\t\tinputs=[\n",
       "\t\t\t\tDataNode(id=input, dtype=Float, shape=[4, 100, 128])\n",
       "\t\t\t\tDataNode(id=4, dtype=Float, shape=[128, 128])],\n",
       "\t\t\toutputs=[\n",
       "\t\t\t\tDataNode(id=output, dtype=Float, shape=[4, 100, 128])],)\n",
       "\t\tOpNode(id=6, op=prim::Constant, \n",
       "\t\t\toutputs=[\n",
       "\t\t\t\tDataNode(id=6, dtype=int)],)\n",
       "\t\tOpNode(id=m_out, op=aten::add_, flops=51200, mem_bytes=409600, \n",
       "\t\t\tinputs=[\n",
       "\t\t\t\tDataNode(id=output, dtype=Float, shape=[4, 100, 128])\n",
       "\t\t\t\tDataNode(id=2, dtype=None)\n",
       "\t\t\t\tDataNode(id=6, dtype=int)],\n",
       "\t\t\toutputs=[\n",
       "\t\t\t\tDataNode(id=m_out, dtype=Float, shape=[4, 100, 128])],)]\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "print(datetime.fromtimestamp(1605498402.136237))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# config = AutoConfig.from_pretrained(\"prajjwal1/bert-tiny\")\n",
    "config = AutoConfig.from_pretrained(\"albert-base-v2\")\n",
    "config.hidden_act = 'gelu_fast'\n",
    "config.torchscript = True\n",
    "model = AutoModel.from_config(config)\n",
    "inputs = torch.randint(1000, size=(1, 100)).long()\n",
    "# model()\n",
    "# with torch.onnx.select_model_mode_for_export(model, False):\n",
    "  # trace, _ = torch.jit._get_trace_graph(model, args=(inputs,))\n",
    "#     trace = torch.jit.trace(model, (inputs, ))\n",
    "mo=model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}