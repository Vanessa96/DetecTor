{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# import autoreload\n",
    "# ?autoreload\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "from transformers import BertModel\n",
    "from transformers import AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(\"prajjwal1/bert-tiny\")\n",
    "config.hidden_act = 'gelu_fast'\n",
    "config.torchscript = True\n",
    "model = BertModel(config)\n",
    "inputs = torch.randint(1000, size=(1, 100)).long()\n",
    "# model()\n",
    "# with torch.onnx.select_model_mode_for_export(model, False):\n",
    "  # trace, _ = torch.jit._get_trace_graph(model, args=(inputs,))\n",
    "#     trace = torch.jit.trace(model, (inputs, ))\n",
    "mo=model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 128)\n",
       "    (token_type_embeddings): Embedding(2, 128)\n",
       "    (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"_name_or_path\": \"prajjwal1/bert-tiny\",\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"hidden_act\": \"gelu_fast\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 128,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 512,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 2,\n",
       "  \"num_hidden_layers\": 2,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"torchscript\": true,\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config=model.config\n",
    "config.hidden_act = 'gelu_fast'\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from transformers.activations import ACT2FN\n",
    "\n",
    "class BertIntermediate(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(config.hidden_size, config.intermediate_size)\n",
    "        if isinstance(config.hidden_act, str):\n",
    "            self.intermediate_act_fn = ACT2FN[config.hidden_act]\n",
    "        else:\n",
    "            self.intermediate_act_fn = config.hidden_act\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        hidden_states = self.dense(hidden_states)\n",
    "#         hidden_states = self.intermediate_act_fn(hidden_states)\n",
    "        return hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertIntermediate(\n",
       "  (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_model = BertIntermediate(config)\n",
    "input_len = 32\n",
    "input_states = torch.rand((input_len, config.hidden_size))\n",
    "fc_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_trace = torch.jit.trace(fc_model, input_states)\n",
    "fc_graph = fc_trace.inlined_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "graph(%self.1 : __torch__.BertIntermediate,\n",
       "      %input : Float(32:128, 128:1)):\n",
       "  %2 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"dense\"](%self.1)\n",
       "  %4 : int = prim::Constant[value=1](), scope: __module.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1674:0\n",
       "  %5 : Tensor = prim::GetAttr[name=\"bias\"](%2)\n",
       "  %6 : Tensor = prim::GetAttr[name=\"weight\"](%2)\n",
       "  %7 : Float(128:1, 512:128) = aten::t(%6), scope: __module.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1674:0\n",
       "  %8 : Float(32:512, 512:1) = aten::addmm(%5, %input, %7, %4, %4), scope: __module.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1674:0\n",
       "  return (%8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[%2 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"dense\"](%self.1),\n",
       " %4 : int = prim::Constant[value=1](), scope: __module.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1674:0,\n",
       " %5 : Tensor = prim::GetAttr[name=\"bias\"](%2),\n",
       " %6 : Tensor = prim::GetAttr[name=\"weight\"](%2),\n",
       " %7 : Float(128:1, 512:128) = aten::t(%6), scope: __module.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1674:0,\n",
       " %8 : Float(32:512, 512:1) = aten::addmm(%5, %input, %7, %4, %4), scope: __module.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1674:0]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(fc_graph.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['copyMetadata',\n",
       " 'debugName',\n",
       " 'inferTypeFrom',\n",
       " 'isCompleteTensor',\n",
       " 'node',\n",
       " 'offset',\n",
       " 'replaceAllUsesWith',\n",
       " 'requiresGrad',\n",
       " 'requires_grad',\n",
       " 'setDebugName',\n",
       " 'setType',\n",
       " 'setTypeAs',\n",
       " 'toIValue',\n",
       " 'type',\n",
       " 'unique',\n",
       " 'uses']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_in_nodes=list(fc_graph.inputs())\n",
    "[i for i in dir(fc_in_nodes[0]) if not i.startswith('__')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'input'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_in_nodes[1].debugName()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8 defined in (%8 : Float(32:512, 512:1) = aten::addmm(%5, %input, %7, %4, %4), scope: __module.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1674:0\n",
       " )]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(fc_graph.outputs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:191: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  position_ids = self.position_ids[:, :seq_length]\n",
      "/Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:1673: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  input_tensor.shape == tensor_shape for input_tensor in input_tensors\n"
     ]
    }
   ],
   "source": [
    "trace = torch.jit.trace(model, inputs)\n",
    "graph = trace.inlined_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "graph(%self.1 : __torch__.transformers.modeling_bert.___torch_mangle_124.BertModel,\n",
       "      %input_ids : Long(1:100, 100:1)):\n",
       "  %2 : __torch__.transformers.modeling_bert.___torch_mangle_123.BertPooler = prim::GetAttr[name=\"pooler\"](%self.1)\n",
       "  %3 : __torch__.transformers.modeling_bert.___torch_mangle_120.BertEncoder = prim::GetAttr[name=\"encoder\"](%self.1)\n",
       "  %4 : __torch__.transformers.modeling_bert.___torch_mangle_84.BertEmbeddings = prim::GetAttr[name=\"embeddings\"](%self.1)\n",
       "  %5 : int = prim::Constant[value=0]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:802:0\n",
       "  %6 : int = aten::size(%input_ids, %5) # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:802:0\n",
       "  %7 : Long() = prim::NumToTensor(%6)\n",
       "  %8 : int = aten::Int(%7)\n",
       "  %9 : int = aten::Int(%7)\n",
       "  %10 : int = prim::Constant[value=1]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:802:0\n",
       "  %11 : int = aten::size(%input_ids, %10) # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:802:0\n",
       "  %12 : Long() = prim::NumToTensor(%11)\n",
       "  %13 : int = aten::Int(%12)\n",
       "  %14 : int = aten::Int(%12)\n",
       "  %15 : int[] = prim::ListConstruct(%9, %14)\n",
       "  %16 : int = prim::Constant[value=6]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:811:0\n",
       "  %17 : int = prim::Constant[value=0]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:811:0\n",
       "  %18 : Device = prim::Constant[value=\"cpu\"]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:811:0\n",
       "  %19 : bool = prim::Constant[value=0]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:811:0\n",
       "  %attention_mask.1 : Float(1:100, 100:1) = aten::ones(%15, %16, %17, %18, %19) # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:811:0\n",
       "  %21 : int[] = prim::ListConstruct(%8, %13)\n",
       "  %22 : int = prim::Constant[value=4]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:813:0\n",
       "  %23 : int = prim::Constant[value=0]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:813:0\n",
       "  %24 : Device = prim::Constant[value=\"cpu\"]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:813:0\n",
       "  %25 : bool = prim::Constant[value=0]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:813:0\n",
       "  %input.2 : Long(1:100, 100:1) = aten::zeros(%21, %22, %23, %24, %25) # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:813:0\n",
       "  %27 : int = prim::Constant[value=0]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:258:0\n",
       "  %28 : int = prim::Constant[value=0]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:258:0\n",
       "  %29 : int = prim::Constant[value=9223372036854775807]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:258:0\n",
       "  %30 : int = prim::Constant[value=1]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:258:0\n",
       "  %31 : Float(1:100, 100:1) = aten::slice(%attention_mask.1, %27, %28, %29, %30) # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:258:0\n",
       "  %32 : int = prim::Constant[value=1]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:258:0\n",
       "  %33 : Float(1:100, 1:100, 100:1) = aten::unsqueeze(%31, %32) # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:258:0\n",
       "  %34 : int = prim::Constant[value=2]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:258:0\n",
       "  %35 : Float(1:100, 1:100, 1:100, 100:1) = aten::unsqueeze(%33, %34) # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:258:0\n",
       "  %36 : int = prim::Constant[value=3]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:258:0\n",
       "  %37 : int = prim::Constant[value=0]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:258:0\n",
       "  %38 : int = prim::Constant[value=9223372036854775807]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:258:0\n",
       "  %39 : int = prim::Constant[value=1]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:258:0\n",
       "  %extended_attention_mask : Float(1:100, 1:100, 1:100, 100:1) = aten::slice(%35, %36, %37, %38, %39) # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:258:0\n",
       "  %41 : int = prim::Constant[value=6]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:271:0\n",
       "  %42 : bool = prim::Constant[value=0]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:271:0\n",
       "  %43 : bool = prim::Constant[value=0]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:271:0\n",
       "  %44 : None = prim::Constant()\n",
       "  %45 : Float(1:100, 1:100, 1:100, 100:1) = aten::to(%extended_attention_mask, %41, %42, %43, %44) # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:271:0\n",
       "  %46 : float = prim::Constant[value=1.]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/tensor.py:396:0\n",
       "  %47 : int = prim::Constant[value=1]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/tensor.py:396:0\n",
       "  %48 : Float(1:100, 1:100, 1:100, 100:1) = aten::rsub(%45, %46, %47) # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/tensor.py:396:0\n",
       "  %49 : Double() = prim::Constant[value={-10000}]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:272:0\n",
       "  %attention_mask : Float(1:100, 1:100, 1:100, 100:1) = aten::mul(%48, %49) # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:272:0\n",
       "  %55 : float = prim::Constant[value=0.10000000000000001](), scope: __module.embeddings/__module.embeddings.dropout # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:973:0\n",
       "  %56 : int = prim::Constant[value=128](), scope: __module.embeddings/__module.embeddings.LayerNorm # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:2048:0\n",
       "  %57 : float = prim::Constant[value=9.9999999999999998e-13](), scope: __module.embeddings/__module.embeddings.LayerNorm # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:2048:0\n",
       "  %58 : bool = prim::Constant[value=1](), scope: __module.embeddings/__module.embeddings.LayerNorm # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:2048:0\n",
       "  %59 : int = prim::Constant[value=-1](), scope: __module.embeddings/__module.embeddings.position_embeddings # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1814:0\n",
       "  %60 : bool = prim::Constant[value=0](), scope: __module.embeddings/__module.embeddings.word_embeddings # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1814:0\n",
       "  %61 : int = prim::Constant[value=9223372036854775807](), scope: __module.embeddings # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:191:0\n",
       "  %62 : int = prim::Constant[value=0](), scope: __module.embeddings # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:191:0\n",
       "  %63 : int = prim::Constant[value=1](), scope: __module.embeddings # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:184:0\n",
       "  %64 : __torch__.torch.nn.modules.normalization.___torch_mangle_82.LayerNorm = prim::GetAttr[name=\"LayerNorm\"](%4)\n",
       "  %65 : __torch__.torch.nn.modules.sparse.___torch_mangle_81.Embedding = prim::GetAttr[name=\"token_type_embeddings\"](%4)\n",
       "  %66 : __torch__.torch.nn.modules.sparse.___torch_mangle_80.Embedding = prim::GetAttr[name=\"position_embeddings\"](%4)\n",
       "  %67 : __torch__.torch.nn.modules.sparse.___torch_mangle_79.Embedding = prim::GetAttr[name=\"word_embeddings\"](%4)\n",
       "  %68 : Tensor = prim::GetAttr[name=\"position_ids\"](%4)\n",
       "  %69 : int = aten::size(%input_ids, %63), scope: __module.embeddings # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:184:0\n",
       "  %70 : Long(1:512, 512:1) = aten::slice(%68, %62, %62, %61, %63), scope: __module.embeddings # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:191:0\n",
       "  %input.1 : Long(1:512, 100:1) = aten::slice(%70, %63, %62, %69, %63), scope: __module.embeddings # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:191:0\n",
       "  %72 : Tensor = prim::GetAttr[name=\"weight\"](%67)\n",
       "  %inputs_embeds : Float(1:12800, 100:128, 128:1) = aten::embedding(%72, %input_ids, %62, %60, %60), scope: __module.embeddings/__module.embeddings.word_embeddings # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1814:0\n",
       "  %74 : Tensor = prim::GetAttr[name=\"weight\"](%66)\n",
       "  %position_embeddings : Float(1:12800, 100:128, 128:1) = aten::embedding(%74, %input.1, %59, %60, %60), scope: __module.embeddings/__module.embeddings.position_embeddings # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1814:0\n",
       "  %76 : Tensor = prim::GetAttr[name=\"weight\"](%65)\n",
       "  %token_type_embeddings : Float(1:12800, 100:128, 128:1) = aten::embedding(%76, %input.2, %59, %60, %60), scope: __module.embeddings/__module.embeddings.token_type_embeddings # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1814:0\n",
       "  %78 : Float(1:12800, 100:128, 128:1) = aten::add(%inputs_embeds, %position_embeddings, %63), scope: __module.embeddings # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:201:0\n",
       "  %input.3 : Float(1:12800, 100:128, 128:1) = aten::add(%78, %token_type_embeddings, %63), scope: __module.embeddings # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:201:0\n",
       "  %80 : Tensor = prim::GetAttr[name=\"bias\"](%64)\n",
       "  %81 : Tensor = prim::GetAttr[name=\"weight\"](%64)\n",
       "  %82 : int[] = prim::ListConstruct(%56), scope: __module.embeddings/__module.embeddings.LayerNorm\n",
       "  %input.4 : Float(1:12800, 100:128, 128:1) = aten::layer_norm(%input.3, %82, %81, %80, %57, %58), scope: __module.embeddings/__module.embeddings.LayerNorm # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:2048:0\n",
       "  %input.5 : Float(1:12800, 100:128, 128:1) = aten::dropout(%input.4, %55, %60), scope: __module.embeddings/__module.embeddings.dropout # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:973:0\n",
       "  %85 : bool = prim::Constant[value=1](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.output/__module.encoder.layer.0.attention.output.LayerNorm # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:2048:0\n",
       "  %86 : float = prim::Constant[value=9.9999999999999998e-13](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.output/__module.encoder.layer.0.attention.output.LayerNorm # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:2048:0\n",
       "  %87 : int = prim::Constant[value=1](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.query # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1678:0\n",
       "  %88 : int = prim::Constant[value=0](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:227:0\n",
       "  %89 : int = prim::Constant[value=2](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:228:0\n",
       "  %90 : int = prim::Constant[value=64](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:228:0\n",
       "  %91 : int = prim::Constant[value=3](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:229:0\n",
       "  %92 : int = prim::Constant[value=-1](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:258:0\n",
       "  %93 : int = prim::Constant[value=-2](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:258:0\n",
       "  %94 : Double() = prim::Constant[value={8}](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:259:0\n",
       "  %95 : None = prim::Constant(), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self\n",
       "  %96 : bool = prim::Constant[value=0](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.dropout # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:973:0\n",
       "  %97 : float = prim::Constant[value=0.10000000000000001](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.dropout # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:973:0\n",
       "  %98 : int = prim::Constant[value=128](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:279:0\n",
       "  %99 : Double() = prim::Constant[value={1}](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.intermediate # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/activations.py:38:0\n",
       "  %100 : Double() = prim::Constant[value={0.044715}](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.intermediate # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/activations.py:38:0\n",
       "  %101 : Double() = prim::Constant[value={0.797885}](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.intermediate # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/activations.py:38:0\n",
       "  %102 : Double() = prim::Constant[value={0.5}](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.intermediate # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/activations.py:38:0\n",
       "  %103 : __torch__.torch.nn.modules.container.___torch_mangle_119.ModuleList = prim::GetAttr[name=\"layer\"](%3)\n",
       "  %104 : __torch__.transformers.modeling_bert.___torch_mangle_118.BertLayer = prim::GetAttr[name=\"1\"](%103)\n",
       "  %105 : __torch__.torch.nn.modules.container.___torch_mangle_119.ModuleList = prim::GetAttr[name=\"layer\"](%3)\n",
       "  %106 : __torch__.transformers.modeling_bert.___torch_mangle_101.BertLayer = prim::GetAttr[name=\"0\"](%105)\n",
       "  %107 : __torch__.transformers.modeling_bert.___torch_mangle_100.BertOutput = prim::GetAttr[name=\"output\"](%106)\n",
       "  %108 : __torch__.transformers.modeling_bert.___torch_mangle_96.BertIntermediate = prim::GetAttr[name=\"intermediate\"](%106)\n",
       "  %109 : __torch__.transformers.modeling_bert.___torch_mangle_94.BertAttention = prim::GetAttr[name=\"attention\"](%106)\n",
       "  %110 : __torch__.transformers.modeling_bert.___torch_mangle_93.BertSelfOutput = prim::GetAttr[name=\"output\"](%109)\n",
       "  %111 : __torch__.transformers.modeling_bert.___torch_mangle_89.BertSelfAttention = prim::GetAttr[name=\"self\"](%109)\n",
       "  %112 : __torch__.torch.nn.modules.linear.___torch_mangle_87.Linear = prim::GetAttr[name=\"value\"](%111)\n",
       "  %113 : __torch__.torch.nn.modules.linear.___torch_mangle_86.Linear = prim::GetAttr[name=\"key\"](%111)\n",
       "  %114 : __torch__.torch.nn.modules.linear.___torch_mangle_85.Linear = prim::GetAttr[name=\"query\"](%111)\n",
       "  %115 : Tensor = prim::GetAttr[name=\"bias\"](%114)\n",
       "  %116 : Tensor = prim::GetAttr[name=\"weight\"](%114)\n",
       "  %117 : Float(128:1, 128:128) = aten::t(%116), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.query # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0\n",
       "  %output.1 : Float(1:12800, 100:128, 128:1) = aten::matmul(%input.5, %117), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.query # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0\n",
       "  %x.1 : Float(1:12800, 100:128, 128:1) = aten::add_(%output.1, %115, %87), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.query # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1678:0\n",
       "  %120 : Tensor = prim::GetAttr[name=\"bias\"](%113)\n",
       "  %121 : Tensor = prim::GetAttr[name=\"weight\"](%113)\n",
       "  %122 : Float(128:1, 128:128) = aten::t(%121), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.key # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0\n",
       "  %output.2 : Float(1:12800, 100:128, 128:1) = aten::matmul(%input.5, %122), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.key # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0\n",
       "  %x.3 : Float(1:12800, 100:128, 128:1) = aten::add_(%output.2, %120, %87), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.key # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1678:0\n",
       "  %125 : Tensor = prim::GetAttr[name=\"bias\"](%112)\n",
       "  %126 : Tensor = prim::GetAttr[name=\"weight\"](%112)\n",
       "  %127 : Float(128:1, 128:128) = aten::t(%126), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.value # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0\n",
       "  %output.3 : Float(1:12800, 100:128, 128:1) = aten::matmul(%input.5, %127), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.value # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0\n",
       "  %x.5 : Float(1:12800, 100:128, 128:1) = aten::add_(%output.3, %125, %87), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.value # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1678:0\n",
       "  %130 : int = aten::size(%x.1, %88), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:227:0\n",
       "  %131 : int = aten::size(%x.1, %87), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:227:0\n",
       "  %132 : int[] = prim::ListConstruct(%130, %131, %89, %90), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self\n",
       "  %x.2 : Float(1:12800, 100:128, 2:64, 64:1) = aten::view(%x.1, %132), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:228:0\n",
       "  %134 : int[] = prim::ListConstruct(%88, %89, %87, %91), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self\n",
       "  %query_layer.1 : Float(1:12800, 2:64, 100:128, 64:1) = aten::permute(%x.2, %134), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:229:0\n",
       "  %136 : int = aten::size(%x.3, %88), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:227:0\n",
       "  %137 : int = aten::size(%x.3, %87), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:227:0\n",
       "  %138 : int[] = prim::ListConstruct(%136, %137, %89, %90), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self\n",
       "  %x.4 : Float(1:12800, 100:128, 2:64, 64:1) = aten::view(%x.3, %138), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:228:0\n",
       "  %140 : int[] = prim::ListConstruct(%88, %89, %87, %91), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self\n",
       "  %key_layer.1 : Float(1:12800, 2:64, 100:128, 64:1) = aten::permute(%x.4, %140), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:229:0\n",
       "  %142 : int = aten::size(%x.5, %88), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:227:0\n",
       "  %143 : int = aten::size(%x.5, %87), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:227:0\n",
       "  %144 : int[] = prim::ListConstruct(%142, %143, %89, %90), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self\n",
       "  %x.6 : Float(1:12800, 100:128, 2:64, 64:1) = aten::view(%x.5, %144), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:228:0\n",
       "  %146 : int[] = prim::ListConstruct(%88, %89, %87, %91), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self\n",
       "  %value_layer.1 : Float(1:12800, 2:64, 100:128, 64:1) = aten::permute(%x.6, %146), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:229:0\n",
       "  %148 : Float(1:12800, 2:64, 64:1, 100:128) = aten::transpose(%key_layer.1, %92, %93), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:258:0\n",
       "  %attention_scores.1 : Float(1:20000, 2:10000, 100:100, 100:1) = aten::matmul(%query_layer.1, %148), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:258:0\n",
       "  %attention_scores.2 : Float(1:20000, 2:10000, 100:100, 100:1) = aten::div(%attention_scores.1, %94), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:259:0\n",
       "  %input.6 : Float(1:20000, 2:10000, 100:100, 100:1) = aten::add(%attention_scores.2, %attention_mask, %87), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:262:0\n",
       "  %input.7 : Float(1:20000, 2:10000, 100:100, 100:1) = aten::softmax(%input.6, %92, %95), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1498:0\n",
       "  %attention_probs.1 : Float(1:20000, 2:10000, 100:100, 100:1) = aten::dropout(%input.7, %97, %96), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.dropout # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:973:0\n",
       "  %context_layer.1 : Float(1:12800, 2:6400, 100:64, 64:1) = aten::matmul(%attention_probs.1, %value_layer.1), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:275:0\n",
       "  %155 : int[] = prim::ListConstruct(%88, %89, %87, %91), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self\n",
       "  %156 : Float(1:12800, 100:64, 2:6400, 64:1) = aten::permute(%context_layer.1, %155), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:277:0\n",
       "  %context_layer.2 : Float(1:12800, 100:128, 2:64, 64:1) = aten::contiguous(%156, %88), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:277:0\n",
       "  %158 : int = aten::size(%context_layer.2, %88), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:278:0\n",
       "  %159 : int = aten::size(%context_layer.2, %87), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:278:0\n",
       "  %160 : int[] = prim::ListConstruct(%158, %159, %98), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self\n",
       "  %input.8 : Float(1:12800, 100:128, 128:1) = aten::view(%context_layer.2, %160), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:279:0\n",
       "  %162 : __torch__.torch.nn.modules.normalization.___torch_mangle_91.LayerNorm = prim::GetAttr[name=\"LayerNorm\"](%110)\n",
       "  %163 : __torch__.torch.nn.modules.linear.___torch_mangle_90.Linear = prim::GetAttr[name=\"dense\"](%110)\n",
       "  %164 : Tensor = prim::GetAttr[name=\"bias\"](%163)\n",
       "  %165 : Tensor = prim::GetAttr[name=\"weight\"](%163)\n",
       "  %166 : Float(128:1, 128:128) = aten::t(%165), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.output/__module.encoder.layer.0.attention.output.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0\n",
       "  %output.4 : Float(1:12800, 100:128, 128:1) = aten::matmul(%input.8, %166), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.output/__module.encoder.layer.0.attention.output.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0\n",
       "  %input.9 : Float(1:12800, 100:128, 128:1) = aten::add_(%output.4, %164, %87), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.output/__module.encoder.layer.0.attention.output.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1678:0\n",
       "  %hidden_states.1 : Float(1:12800, 100:128, 128:1) = aten::dropout(%input.9, %97, %96), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.output/__module.encoder.layer.0.attention.output.dropout # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:973:0\n",
       "  %input.10 : Float(1:12800, 100:128, 128:1) = aten::add(%hidden_states.1, %input.5, %87), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.output # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:295:0\n",
       "  %171 : Tensor = prim::GetAttr[name=\"bias\"](%162)\n",
       "  %172 : Tensor = prim::GetAttr[name=\"weight\"](%162)\n",
       "  %173 : int[] = prim::ListConstruct(%98), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.output/__module.encoder.layer.0.attention.output.LayerNorm\n",
       "  %input_tensor.1 : Float(1:12800, 100:128, 128:1) = aten::layer_norm(%input.10, %173, %172, %171, %86, %85), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.output/__module.encoder.layer.0.attention.output.LayerNorm # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:2048:0\n",
       "  %175 : __torch__.torch.nn.modules.linear.___torch_mangle_95.Linear = prim::GetAttr[name=\"dense\"](%108)\n",
       "  %176 : Tensor = prim::GetAttr[name=\"bias\"](%175)\n",
       "  %177 : Tensor = prim::GetAttr[name=\"weight\"](%175)\n",
       "  %178 : Float(128:1, 512:128) = aten::t(%177), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.intermediate/__module.encoder.layer.0.intermediate.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0\n",
       "  %output.5 : Float(1:51200, 100:512, 512:1) = aten::matmul(%input_tensor.1, %178), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.intermediate/__module.encoder.layer.0.intermediate.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0\n",
       "  %x.7 : Float(1:51200, 100:512, 512:1) = aten::add_(%output.5, %176, %87), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.intermediate/__module.encoder.layer.0.intermediate.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1678:0\n",
       "  %181 : Float(1:51200, 100:512, 512:1) = aten::mul(%x.7, %102), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.intermediate # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/activations.py:38:0\n",
       "  %182 : Float(1:51200, 100:512, 512:1) = aten::mul(%x.7, %101), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.intermediate # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/activations.py:38:0\n",
       "  %183 : Float(1:51200, 100:512, 512:1) = aten::mul(%x.7, %100), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.intermediate # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/activations.py:38:0\n",
       "  %184 : Float(1:51200, 100:512, 512:1) = aten::mul(%183, %x.7), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.intermediate # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/activations.py:38:0\n",
       "  %185 : Float(1:51200, 100:512, 512:1) = aten::add(%184, %99, %87), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.intermediate # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/activations.py:38:0\n",
       "  %186 : Float(1:51200, 100:512, 512:1) = aten::mul(%182, %185), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.intermediate # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/activations.py:38:0\n",
       "  %187 : Float(1:51200, 100:512, 512:1) = aten::tanh(%186), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.intermediate # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/activations.py:38:0\n",
       "  %188 : Float(1:51200, 100:512, 512:1) = aten::add(%187, %99, %87), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.intermediate # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/activations.py:38:0\n",
       "  %input.11 : Float(1:51200, 100:512, 512:1) = aten::mul(%181, %188), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.intermediate # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/activations.py:38:0\n",
       "  %190 : __torch__.torch.nn.modules.normalization.___torch_mangle_98.LayerNorm = prim::GetAttr[name=\"LayerNorm\"](%107)\n",
       "  %191 : __torch__.torch.nn.modules.linear.___torch_mangle_97.Linear = prim::GetAttr[name=\"dense\"](%107)\n",
       "  %192 : Tensor = prim::GetAttr[name=\"bias\"](%191)\n",
       "  %193 : Tensor = prim::GetAttr[name=\"weight\"](%191)\n",
       "  %194 : Float(512:1, 128:512) = aten::t(%193), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.output/__module.encoder.layer.0.output.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0\n",
       "  %output.6 : Float(1:12800, 100:128, 128:1) = aten::matmul(%input.11, %194), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.output/__module.encoder.layer.0.output.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0\n",
       "  %input.12 : Float(1:12800, 100:128, 128:1) = aten::add_(%output.6, %192, %87), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.output/__module.encoder.layer.0.output.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1678:0\n",
       "  %hidden_states.2 : Float(1:12800, 100:128, 128:1) = aten::dropout(%input.12, %97, %96), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.output/__module.encoder.layer.0.output.dropout # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:973:0\n",
       "  %input.13 : Float(1:12800, 100:128, 128:1) = aten::add(%hidden_states.2, %input_tensor.1, %87), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.output # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:371:0\n",
       "  %199 : Tensor = prim::GetAttr[name=\"bias\"](%190)\n",
       "  %200 : Tensor = prim::GetAttr[name=\"weight\"](%190)\n",
       "  %201 : int[] = prim::ListConstruct(%98), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.output/__module.encoder.layer.0.output.LayerNorm\n",
       "  %input.14 : Float(1:12800, 100:128, 128:1) = aten::layer_norm(%input.13, %201, %200, %199, %86, %85), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.output/__module.encoder.layer.0.output.LayerNorm # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:2048:0\n",
       "  %203 : __torch__.transformers.modeling_bert.___torch_mangle_117.BertOutput = prim::GetAttr[name=\"output\"](%104)\n",
       "  %204 : __torch__.transformers.modeling_bert.___torch_mangle_113.BertIntermediate = prim::GetAttr[name=\"intermediate\"](%104)\n",
       "  %205 : __torch__.transformers.modeling_bert.___torch_mangle_111.BertAttention = prim::GetAttr[name=\"attention\"](%104)\n",
       "  %206 : __torch__.transformers.modeling_bert.___torch_mangle_110.BertSelfOutput = prim::GetAttr[name=\"output\"](%205)\n",
       "  %207 : __torch__.transformers.modeling_bert.___torch_mangle_106.BertSelfAttention = prim::GetAttr[name=\"self\"](%205)\n",
       "  %208 : __torch__.torch.nn.modules.linear.___torch_mangle_104.Linear = prim::GetAttr[name=\"value\"](%207)\n",
       "  %209 : __torch__.torch.nn.modules.linear.___torch_mangle_103.Linear = prim::GetAttr[name=\"key\"](%207)\n",
       "  %210 : __torch__.torch.nn.modules.linear.___torch_mangle_102.Linear = prim::GetAttr[name=\"query\"](%207)\n",
       "  %211 : Tensor = prim::GetAttr[name=\"bias\"](%210)\n",
       "  %212 : Tensor = prim::GetAttr[name=\"weight\"](%210)\n",
       "  %213 : Float(128:1, 128:128) = aten::t(%212), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self/__module.encoder.layer.1.attention.self.query # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0\n",
       "  %output.7 : Float(1:12800, 100:128, 128:1) = aten::matmul(%input.14, %213), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self/__module.encoder.layer.1.attention.self.query # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0\n",
       "  %x.8 : Float(1:12800, 100:128, 128:1) = aten::add_(%output.7, %211, %87), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self/__module.encoder.layer.1.attention.self.query # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1678:0\n",
       "  %216 : Tensor = prim::GetAttr[name=\"bias\"](%209)\n",
       "  %217 : Tensor = prim::GetAttr[name=\"weight\"](%209)\n",
       "  %218 : Float(128:1, 128:128) = aten::t(%217), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self/__module.encoder.layer.1.attention.self.key # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0\n",
       "  %output.8 : Float(1:12800, 100:128, 128:1) = aten::matmul(%input.14, %218), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self/__module.encoder.layer.1.attention.self.key # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0\n",
       "  %x.10 : Float(1:12800, 100:128, 128:1) = aten::add_(%output.8, %216, %87), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self/__module.encoder.layer.1.attention.self.key # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1678:0\n",
       "  %221 : Tensor = prim::GetAttr[name=\"bias\"](%208)\n",
       "  %222 : Tensor = prim::GetAttr[name=\"weight\"](%208)\n",
       "  %223 : Float(128:1, 128:128) = aten::t(%222), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self/__module.encoder.layer.1.attention.self.value # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0\n",
       "  %output.9 : Float(1:12800, 100:128, 128:1) = aten::matmul(%input.14, %223), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self/__module.encoder.layer.1.attention.self.value # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0\n",
       "  %x.12 : Float(1:12800, 100:128, 128:1) = aten::add_(%output.9, %221, %87), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self/__module.encoder.layer.1.attention.self.value # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1678:0\n",
       "  %226 : int = aten::size(%x.8, %88), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:227:0\n",
       "  %227 : int = aten::size(%x.8, %87), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:227:0\n",
       "  %228 : int[] = prim::ListConstruct(%226, %227, %89, %90), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self\n",
       "  %x.9 : Float(1:12800, 100:128, 2:64, 64:1) = aten::view(%x.8, %228), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:228:0\n",
       "  %230 : int[] = prim::ListConstruct(%88, %89, %87, %91), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self\n",
       "  %query_layer : Float(1:12800, 2:64, 100:128, 64:1) = aten::permute(%x.9, %230), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:229:0\n",
       "  %232 : int = aten::size(%x.10, %88), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:227:0\n",
       "  %233 : int = aten::size(%x.10, %87), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:227:0\n",
       "  %234 : int[] = prim::ListConstruct(%232, %233, %89, %90), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self\n",
       "  %x.11 : Float(1:12800, 100:128, 2:64, 64:1) = aten::view(%x.10, %234), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:228:0\n",
       "  %236 : int[] = prim::ListConstruct(%88, %89, %87, %91), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self\n",
       "  %key_layer : Float(1:12800, 2:64, 100:128, 64:1) = aten::permute(%x.11, %236), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:229:0\n",
       "  %238 : int = aten::size(%x.12, %88), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:227:0\n",
       "  %239 : int = aten::size(%x.12, %87), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:227:0\n",
       "  %240 : int[] = prim::ListConstruct(%238, %239, %89, %90), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self\n",
       "  %x.13 : Float(1:12800, 100:128, 2:64, 64:1) = aten::view(%x.12, %240), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:228:0\n",
       "  %242 : int[] = prim::ListConstruct(%88, %89, %87, %91), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self\n",
       "  %value_layer : Float(1:12800, 2:64, 100:128, 64:1) = aten::permute(%x.13, %242), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:229:0\n",
       "  %244 : Float(1:12800, 2:64, 64:1, 100:128) = aten::transpose(%key_layer, %92, %93), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:258:0\n",
       "  %attention_scores.3 : Float(1:20000, 2:10000, 100:100, 100:1) = aten::matmul(%query_layer, %244), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:258:0\n",
       "  %attention_scores : Float(1:20000, 2:10000, 100:100, 100:1) = aten::div(%attention_scores.3, %94), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:259:0\n",
       "  %input.15 : Float(1:20000, 2:10000, 100:100, 100:1) = aten::add(%attention_scores, %attention_mask, %87), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:262:0\n",
       "  %input.16 : Float(1:20000, 2:10000, 100:100, 100:1) = aten::softmax(%input.15, %92, %95), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1498:0\n",
       "  %attention_probs : Float(1:20000, 2:10000, 100:100, 100:1) = aten::dropout(%input.16, %97, %96), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self/__module.encoder.layer.1.attention.self.dropout # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:973:0\n",
       "  %context_layer.3 : Float(1:12800, 2:6400, 100:64, 64:1) = aten::matmul(%attention_probs, %value_layer), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:275:0\n",
       "  %251 : int[] = prim::ListConstruct(%88, %89, %87, %91), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self\n",
       "  %252 : Float(1:12800, 100:64, 2:6400, 64:1) = aten::permute(%context_layer.3, %251), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:277:0\n",
       "  %context_layer : Float(1:12800, 100:128, 2:64, 64:1) = aten::contiguous(%252, %88), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:277:0\n",
       "  %254 : int = aten::size(%context_layer, %88), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:278:0\n",
       "  %255 : int = aten::size(%context_layer, %87), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:278:0\n",
       "  %256 : int[] = prim::ListConstruct(%254, %255, %98), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self\n",
       "  %input.17 : Float(1:12800, 100:128, 128:1) = aten::view(%context_layer, %256), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:279:0\n",
       "  %258 : __torch__.torch.nn.modules.normalization.___torch_mangle_108.LayerNorm = prim::GetAttr[name=\"LayerNorm\"](%206)\n",
       "  %259 : __torch__.torch.nn.modules.linear.___torch_mangle_107.Linear = prim::GetAttr[name=\"dense\"](%206)\n",
       "  %260 : Tensor = prim::GetAttr[name=\"bias\"](%259)\n",
       "  %261 : Tensor = prim::GetAttr[name=\"weight\"](%259)\n",
       "  %262 : Float(128:1, 128:128) = aten::t(%261), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.output/__module.encoder.layer.1.attention.output.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0\n",
       "  %output.10 : Float(1:12800, 100:128, 128:1) = aten::matmul(%input.17, %262), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.output/__module.encoder.layer.1.attention.output.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0\n",
       "  %input.18 : Float(1:12800, 100:128, 128:1) = aten::add_(%output.10, %260, %87), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.output/__module.encoder.layer.1.attention.output.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1678:0\n",
       "  %hidden_states.3 : Float(1:12800, 100:128, 128:1) = aten::dropout(%input.18, %97, %96), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.output/__module.encoder.layer.1.attention.output.dropout # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:973:0\n",
       "  %input.19 : Float(1:12800, 100:128, 128:1) = aten::add(%hidden_states.3, %input.14, %87), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.output # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:295:0\n",
       "  %267 : Tensor = prim::GetAttr[name=\"bias\"](%258)\n",
       "  %268 : Tensor = prim::GetAttr[name=\"weight\"](%258)\n",
       "  %269 : int[] = prim::ListConstruct(%98), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.output/__module.encoder.layer.1.attention.output.LayerNorm\n",
       "  %input_tensor : Float(1:12800, 100:128, 128:1) = aten::layer_norm(%input.19, %269, %268, %267, %86, %85), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.output/__module.encoder.layer.1.attention.output.LayerNorm # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:2048:0\n",
       "  %271 : __torch__.torch.nn.modules.linear.___torch_mangle_112.Linear = prim::GetAttr[name=\"dense\"](%204)\n",
       "  %272 : Tensor = prim::GetAttr[name=\"bias\"](%271)\n",
       "  %273 : Tensor = prim::GetAttr[name=\"weight\"](%271)\n",
       "  %274 : Float(128:1, 512:128) = aten::t(%273), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.intermediate/__module.encoder.layer.1.intermediate.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0\n",
       "  %output.11 : Float(1:51200, 100:512, 512:1) = aten::matmul(%input_tensor, %274), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.intermediate/__module.encoder.layer.1.intermediate.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0\n",
       "  %x : Float(1:51200, 100:512, 512:1) = aten::add_(%output.11, %272, %87), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.intermediate/__module.encoder.layer.1.intermediate.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1678:0\n",
       "  %277 : Float(1:51200, 100:512, 512:1) = aten::mul(%x, %102), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.intermediate # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/activations.py:38:0\n",
       "  %278 : Float(1:51200, 100:512, 512:1) = aten::mul(%x, %101), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.intermediate # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/activations.py:38:0\n",
       "  %279 : Float(1:51200, 100:512, 512:1) = aten::mul(%x, %100), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.intermediate # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/activations.py:38:0\n",
       "  %280 : Float(1:51200, 100:512, 512:1) = aten::mul(%279, %x), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.intermediate # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/activations.py:38:0\n",
       "  %281 : Float(1:51200, 100:512, 512:1) = aten::add(%280, %99, %87), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.intermediate # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/activations.py:38:0\n",
       "  %282 : Float(1:51200, 100:512, 512:1) = aten::mul(%278, %281), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.intermediate # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/activations.py:38:0\n",
       "  %283 : Float(1:51200, 100:512, 512:1) = aten::tanh(%282), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.intermediate # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/activations.py:38:0\n",
       "  %284 : Float(1:51200, 100:512, 512:1) = aten::add(%283, %99, %87), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.intermediate # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/activations.py:38:0\n",
       "  %input.20 : Float(1:51200, 100:512, 512:1) = aten::mul(%277, %284), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.intermediate # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/activations.py:38:0\n",
       "  %286 : __torch__.torch.nn.modules.normalization.___torch_mangle_115.LayerNorm = prim::GetAttr[name=\"LayerNorm\"](%203)\n",
       "  %287 : __torch__.torch.nn.modules.linear.___torch_mangle_114.Linear = prim::GetAttr[name=\"dense\"](%203)\n",
       "  %288 : Tensor = prim::GetAttr[name=\"bias\"](%287)\n",
       "  %289 : Tensor = prim::GetAttr[name=\"weight\"](%287)\n",
       "  %290 : Float(512:1, 128:512) = aten::t(%289), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.output/__module.encoder.layer.1.output.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0\n",
       "  %output : Float(1:12800, 100:128, 128:1) = aten::matmul(%input.20, %290), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.output/__module.encoder.layer.1.output.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0\n",
       "  %input.21 : Float(1:12800, 100:128, 128:1) = aten::add_(%output, %288, %87), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.output/__module.encoder.layer.1.output.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1678:0\n",
       "  %hidden_states.4 : Float(1:12800, 100:128, 128:1) = aten::dropout(%input.21, %97, %96), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.output/__module.encoder.layer.1.output.dropout # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:973:0\n",
       "  %input.22 : Float(1:12800, 100:128, 128:1) = aten::add(%hidden_states.4, %input_tensor, %87), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.output # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:371:0\n",
       "  %295 : Tensor = prim::GetAttr[name=\"bias\"](%286)\n",
       "  %296 : Tensor = prim::GetAttr[name=\"weight\"](%286)\n",
       "  %297 : int[] = prim::ListConstruct(%98), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.output/__module.encoder.layer.1.output.LayerNorm\n",
       "  %hidden_states : Float(1:12800, 100:128, 128:1) = aten::layer_norm(%input.22, %297, %296, %295, %86, %85), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.output/__module.encoder.layer.1.output.LayerNorm # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:2048:0\n",
       "  %299 : int = prim::Constant[value=1](), scope: __module.pooler # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:517:0\n",
       "  %300 : int = prim::Constant[value=9223372036854775807](), scope: __module.pooler # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:517:0\n",
       "  %301 : int = prim::Constant[value=0](), scope: __module.pooler # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:517:0\n",
       "  %302 : __torch__.torch.nn.modules.linear.___torch_mangle_121.Linear = prim::GetAttr[name=\"dense\"](%2)\n",
       "  %303 : Float(1:12800, 100:128, 128:1) = aten::slice(%hidden_states, %301, %301, %300, %299), scope: __module.pooler # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:517:0\n",
       "  %input.23 : Float(1:12800, 128:1) = aten::select(%303, %299, %301), scope: __module.pooler # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:517:0\n",
       "  %305 : Tensor = prim::GetAttr[name=\"bias\"](%302)\n",
       "  %306 : Tensor = prim::GetAttr[name=\"weight\"](%302)\n",
       "  %307 : Float(128:1, 128:128) = aten::t(%306), scope: __module.pooler/__module.pooler.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1674:0\n",
       "  %input : Float(1:128, 128:1) = aten::addmm(%305, %input.23, %307, %299, %299), scope: __module.pooler/__module.pooler.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1674:0\n",
       "  %309 : Float(1:128, 128:1) = aten::tanh(%input), scope: __module.pooler/__module.pooler.activation # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/modules/activation.py:350:0\n",
       "  %54 : (Float(1:12800, 100:128, 128:1), Float(1:128, 128:1)) = prim::TupleConstruct(%hidden_states, %309)\n",
       "  return (%54)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[%2 : __torch__.transformers.modeling_bert.BertPooler = prim::GetAttr[name=\"pooler\"](%self.1),\n",
       " %3 : __torch__.transformers.modeling_bert.BertEncoder = prim::GetAttr[name=\"encoder\"](%self.1),\n",
       " %4 : __torch__.transformers.modeling_bert.BertEmbeddings = prim::GetAttr[name=\"embeddings\"](%self.1),\n",
       " %5 : int = prim::Constant[value=0]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:802:0,\n",
       " %6 : int = aten::size(%input_ids, %5) # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:802:0,\n",
       " %7 : Long() = prim::NumToTensor(%6),\n",
       " %8 : int = aten::Int(%7),\n",
       " %9 : int = aten::Int(%7),\n",
       " %10 : int = prim::Constant[value=1]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:802:0,\n",
       " %11 : int = aten::size(%input_ids, %10) # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:802:0,\n",
       " %12 : Long() = prim::NumToTensor(%11),\n",
       " %13 : int = aten::Int(%12),\n",
       " %14 : int = aten::Int(%12),\n",
       " %15 : int[] = prim::ListConstruct(%9, %14),\n",
       " %16 : int = prim::Constant[value=6]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:811:0,\n",
       " %17 : int = prim::Constant[value=0]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:811:0,\n",
       " %18 : Device = prim::Constant[value=\"cpu\"]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:811:0,\n",
       " %19 : bool = prim::Constant[value=0]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:811:0,\n",
       " %attention_mask.1 : Float(1:100, 100:1) = aten::ones(%15, %16, %17, %18, %19) # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:811:0,\n",
       " %21 : int[] = prim::ListConstruct(%8, %13),\n",
       " %22 : int = prim::Constant[value=4]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:813:0,\n",
       " %23 : int = prim::Constant[value=0]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:813:0,\n",
       " %24 : Device = prim::Constant[value=\"cpu\"]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:813:0,\n",
       " %25 : bool = prim::Constant[value=0]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:813:0,\n",
       " %input.2 : Long(1:100, 100:1) = aten::zeros(%21, %22, %23, %24, %25) # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:813:0,\n",
       " %27 : int = prim::Constant[value=0]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:258:0,\n",
       " %28 : int = prim::Constant[value=0]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:258:0,\n",
       " %29 : int = prim::Constant[value=9223372036854775807]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:258:0,\n",
       " %30 : int = prim::Constant[value=1]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:258:0,\n",
       " %31 : Float(1:100, 100:1) = aten::slice(%attention_mask.1, %27, %28, %29, %30) # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:258:0,\n",
       " %32 : int = prim::Constant[value=1]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:258:0,\n",
       " %33 : Float(1:100, 1:100, 100:1) = aten::unsqueeze(%31, %32) # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:258:0,\n",
       " %34 : int = prim::Constant[value=2]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:258:0,\n",
       " %35 : Float(1:100, 1:100, 1:100, 100:1) = aten::unsqueeze(%33, %34) # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:258:0,\n",
       " %36 : int = prim::Constant[value=3]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:258:0,\n",
       " %37 : int = prim::Constant[value=0]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:258:0,\n",
       " %38 : int = prim::Constant[value=9223372036854775807]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:258:0,\n",
       " %39 : int = prim::Constant[value=1]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:258:0,\n",
       " %extended_attention_mask : Float(1:100, 1:100, 1:100, 100:1) = aten::slice(%35, %36, %37, %38, %39) # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:258:0,\n",
       " %41 : int = prim::Constant[value=6]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:271:0,\n",
       " %42 : bool = prim::Constant[value=0]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:271:0,\n",
       " %43 : bool = prim::Constant[value=0]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:271:0,\n",
       " %44 : None = prim::Constant(),\n",
       " %45 : Float(1:100, 1:100, 1:100, 100:1) = aten::to(%extended_attention_mask, %41, %42, %43, %44) # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:271:0,\n",
       " %46 : float = prim::Constant[value=1.]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/tensor.py:396:0,\n",
       " %47 : int = prim::Constant[value=1]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/tensor.py:396:0,\n",
       " %48 : Float(1:100, 1:100, 1:100, 100:1) = aten::rsub(%45, %46, %47) # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/tensor.py:396:0,\n",
       " %49 : Double() = prim::Constant[value={-10000}]() # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:272:0,\n",
       " %attention_mask : Float(1:100, 1:100, 1:100, 100:1) = aten::mul(%48, %49) # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_utils.py:272:0,\n",
       " %55 : float = prim::Constant[value=0.10000000000000001](), scope: __module.embeddings/__module.embeddings.dropout # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:973:0,\n",
       " %56 : int = prim::Constant[value=128](), scope: __module.embeddings/__module.embeddings.LayerNorm # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:2048:0,\n",
       " %57 : float = prim::Constant[value=9.9999999999999998e-13](), scope: __module.embeddings/__module.embeddings.LayerNorm # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:2048:0,\n",
       " %58 : bool = prim::Constant[value=1](), scope: __module.embeddings/__module.embeddings.LayerNorm # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:2048:0,\n",
       " %59 : int = prim::Constant[value=-1](), scope: __module.embeddings/__module.embeddings.position_embeddings # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1814:0,\n",
       " %60 : bool = prim::Constant[value=0](), scope: __module.embeddings/__module.embeddings.word_embeddings # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1814:0,\n",
       " %61 : int = prim::Constant[value=9223372036854775807](), scope: __module.embeddings # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:191:0,\n",
       " %62 : int = prim::Constant[value=0](), scope: __module.embeddings # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:191:0,\n",
       " %63 : int = prim::Constant[value=1](), scope: __module.embeddings # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:184:0,\n",
       " %64 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name=\"LayerNorm\"](%4),\n",
       " %65 : __torch__.torch.nn.modules.sparse.___torch_mangle_3.Embedding = prim::GetAttr[name=\"token_type_embeddings\"](%4),\n",
       " %66 : __torch__.torch.nn.modules.sparse.___torch_mangle_2.Embedding = prim::GetAttr[name=\"position_embeddings\"](%4),\n",
       " %67 : __torch__.torch.nn.modules.sparse.Embedding = prim::GetAttr[name=\"word_embeddings\"](%4),\n",
       " %68 : Tensor = prim::GetAttr[name=\"position_ids\"](%4),\n",
       " %69 : int = aten::size(%input_ids, %63), scope: __module.embeddings # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:184:0,\n",
       " %70 : Long(1:512, 512:1) = aten::slice(%68, %62, %62, %61, %63), scope: __module.embeddings # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:191:0,\n",
       " %input.1 : Long(1:512, 100:1) = aten::slice(%70, %63, %62, %69, %63), scope: __module.embeddings # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:191:0,\n",
       " %72 : Tensor = prim::GetAttr[name=\"weight\"](%67),\n",
       " %inputs_embeds : Float(1:12800, 100:128, 128:1) = aten::embedding(%72, %input_ids, %62, %60, %60), scope: __module.embeddings/__module.embeddings.word_embeddings # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1814:0,\n",
       " %74 : Tensor = prim::GetAttr[name=\"weight\"](%66),\n",
       " %position_embeddings : Float(1:12800, 100:128, 128:1) = aten::embedding(%74, %input.1, %59, %60, %60), scope: __module.embeddings/__module.embeddings.position_embeddings # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1814:0,\n",
       " %76 : Tensor = prim::GetAttr[name=\"weight\"](%65),\n",
       " %token_type_embeddings : Float(1:12800, 100:128, 128:1) = aten::embedding(%76, %input.2, %59, %60, %60), scope: __module.embeddings/__module.embeddings.token_type_embeddings # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1814:0,\n",
       " %78 : Float(1:12800, 100:128, 128:1) = aten::add(%inputs_embeds, %position_embeddings, %63), scope: __module.embeddings # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:201:0,\n",
       " %input.3 : Float(1:12800, 100:128, 128:1) = aten::add(%78, %token_type_embeddings, %63), scope: __module.embeddings # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:201:0,\n",
       " %80 : Tensor = prim::GetAttr[name=\"bias\"](%64),\n",
       " %81 : Tensor = prim::GetAttr[name=\"weight\"](%64),\n",
       " %82 : int[] = prim::ListConstruct(%56), scope: __module.embeddings/__module.embeddings.LayerNorm,\n",
       " %input.4 : Float(1:12800, 100:128, 128:1) = aten::layer_norm(%input.3, %82, %81, %80, %57, %58), scope: __module.embeddings/__module.embeddings.LayerNorm # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:2048:0,\n",
       " %input.5 : Float(1:12800, 100:128, 128:1) = aten::dropout(%input.4, %55, %60), scope: __module.embeddings/__module.embeddings.dropout # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:973:0,\n",
       " %85 : bool = prim::Constant[value=1](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.output/__module.encoder.layer.0.attention.output.LayerNorm # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:2048:0,\n",
       " %86 : float = prim::Constant[value=9.9999999999999998e-13](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.output/__module.encoder.layer.0.attention.output.LayerNorm # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:2048:0,\n",
       " %87 : int = prim::Constant[value=1](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.query # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1678:0,\n",
       " %88 : int = prim::Constant[value=0](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:227:0,\n",
       " %89 : int = prim::Constant[value=2](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:228:0,\n",
       " %90 : int = prim::Constant[value=64](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:228:0,\n",
       " %91 : int = prim::Constant[value=3](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:229:0,\n",
       " %92 : int = prim::Constant[value=-1](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:258:0,\n",
       " %93 : int = prim::Constant[value=-2](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:258:0,\n",
       " %94 : Double() = prim::Constant[value={8}](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:259:0,\n",
       " %95 : None = prim::Constant(), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self,\n",
       " %96 : bool = prim::Constant[value=0](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.dropout # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:973:0,\n",
       " %97 : float = prim::Constant[value=0.10000000000000001](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.dropout # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:973:0,\n",
       " %98 : int = prim::Constant[value=128](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:279:0,\n",
       " %99 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name=\"layer\"](%3),\n",
       " %100 : __torch__.transformers.modeling_bert.___torch_mangle_31.BertLayer = prim::GetAttr[name=\"1\"](%99),\n",
       " %101 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name=\"layer\"](%3),\n",
       " %102 : __torch__.transformers.modeling_bert.BertLayer = prim::GetAttr[name=\"0\"](%101),\n",
       " %103 : __torch__.transformers.modeling_bert.BertOutput = prim::GetAttr[name=\"output\"](%102),\n",
       " %104 : __torch__.transformers.modeling_bert.BertIntermediate = prim::GetAttr[name=\"intermediate\"](%102),\n",
       " %105 : __torch__.transformers.modeling_bert.BertAttention = prim::GetAttr[name=\"attention\"](%102),\n",
       " %106 : __torch__.transformers.modeling_bert.BertSelfOutput = prim::GetAttr[name=\"output\"](%105),\n",
       " %107 : __torch__.transformers.modeling_bert.BertSelfAttention = prim::GetAttr[name=\"self\"](%105),\n",
       " %108 : __torch__.torch.nn.modules.linear.___torch_mangle_6.Linear = prim::GetAttr[name=\"value\"](%107),\n",
       " %109 : __torch__.torch.nn.modules.linear.___torch_mangle_5.Linear = prim::GetAttr[name=\"key\"](%107),\n",
       " %110 : __torch__.torch.nn.modules.linear.___torch_mangle_4.Linear = prim::GetAttr[name=\"query\"](%107),\n",
       " %111 : Tensor = prim::GetAttr[name=\"bias\"](%110),\n",
       " %112 : Tensor = prim::GetAttr[name=\"weight\"](%110),\n",
       " %113 : Float(128:1, 128:128) = aten::t(%112), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.query # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0,\n",
       " %output.1 : Float(1:12800, 100:128, 128:1) = aten::matmul(%input.5, %113), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.query # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0,\n",
       " %x.1 : Float(1:12800, 100:128, 128:1) = aten::add_(%output.1, %111, %87), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.query # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1678:0,\n",
       " %116 : Tensor = prim::GetAttr[name=\"bias\"](%109),\n",
       " %117 : Tensor = prim::GetAttr[name=\"weight\"](%109),\n",
       " %118 : Float(128:1, 128:128) = aten::t(%117), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.key # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0,\n",
       " %output.2 : Float(1:12800, 100:128, 128:1) = aten::matmul(%input.5, %118), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.key # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0,\n",
       " %x.3 : Float(1:12800, 100:128, 128:1) = aten::add_(%output.2, %116, %87), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.key # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1678:0,\n",
       " %121 : Tensor = prim::GetAttr[name=\"bias\"](%108),\n",
       " %122 : Tensor = prim::GetAttr[name=\"weight\"](%108),\n",
       " %123 : Float(128:1, 128:128) = aten::t(%122), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.value # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0,\n",
       " %output.3 : Float(1:12800, 100:128, 128:1) = aten::matmul(%input.5, %123), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.value # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0,\n",
       " %x.5 : Float(1:12800, 100:128, 128:1) = aten::add_(%output.3, %121, %87), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.value # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1678:0,\n",
       " %126 : int = aten::size(%x.1, %88), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:227:0,\n",
       " %127 : int = aten::size(%x.1, %87), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:227:0,\n",
       " %128 : int[] = prim::ListConstruct(%126, %127, %89, %90), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self,\n",
       " %x.2 : Float(1:12800, 100:128, 2:64, 64:1) = aten::view(%x.1, %128), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:228:0,\n",
       " %130 : int[] = prim::ListConstruct(%88, %89, %87, %91), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self,\n",
       " %query_layer.1 : Float(1:12800, 2:64, 100:128, 64:1) = aten::permute(%x.2, %130), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:229:0,\n",
       " %132 : int = aten::size(%x.3, %88), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:227:0,\n",
       " %133 : int = aten::size(%x.3, %87), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:227:0,\n",
       " %134 : int[] = prim::ListConstruct(%132, %133, %89, %90), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self,\n",
       " %x.4 : Float(1:12800, 100:128, 2:64, 64:1) = aten::view(%x.3, %134), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:228:0,\n",
       " %136 : int[] = prim::ListConstruct(%88, %89, %87, %91), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self,\n",
       " %key_layer.1 : Float(1:12800, 2:64, 100:128, 64:1) = aten::permute(%x.4, %136), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:229:0,\n",
       " %138 : int = aten::size(%x.5, %88), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:227:0,\n",
       " %139 : int = aten::size(%x.5, %87), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:227:0,\n",
       " %140 : int[] = prim::ListConstruct(%138, %139, %89, %90), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self,\n",
       " %x.6 : Float(1:12800, 100:128, 2:64, 64:1) = aten::view(%x.5, %140), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:228:0,\n",
       " %142 : int[] = prim::ListConstruct(%88, %89, %87, %91), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self,\n",
       " %value_layer.1 : Float(1:12800, 2:64, 100:128, 64:1) = aten::permute(%x.6, %142), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:229:0,\n",
       " %144 : Float(1:12800, 2:64, 64:1, 100:128) = aten::transpose(%key_layer.1, %92, %93), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:258:0,\n",
       " %attention_scores.1 : Float(1:20000, 2:10000, 100:100, 100:1) = aten::matmul(%query_layer.1, %144), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:258:0,\n",
       " %attention_scores.2 : Float(1:20000, 2:10000, 100:100, 100:1) = aten::div(%attention_scores.1, %94), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:259:0,\n",
       " %input.6 : Float(1:20000, 2:10000, 100:100, 100:1) = aten::add(%attention_scores.2, %attention_mask, %87), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:262:0,\n",
       " %input.7 : Float(1:20000, 2:10000, 100:100, 100:1) = aten::softmax(%input.6, %92, %95), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1498:0,\n",
       " %attention_probs.1 : Float(1:20000, 2:10000, 100:100, 100:1) = aten::dropout(%input.7, %97, %96), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.dropout # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:973:0,\n",
       " %context_layer.1 : Float(1:12800, 2:6400, 100:64, 64:1) = aten::matmul(%attention_probs.1, %value_layer.1), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:275:0,\n",
       " %151 : int[] = prim::ListConstruct(%88, %89, %87, %91), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self,\n",
       " %152 : Float(1:12800, 100:64, 2:6400, 64:1) = aten::permute(%context_layer.1, %151), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:277:0,\n",
       " %context_layer.2 : Float(1:12800, 100:128, 2:64, 64:1) = aten::contiguous(%152, %88), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:277:0,\n",
       " %154 : int = aten::size(%context_layer.2, %88), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:278:0,\n",
       " %155 : int = aten::size(%context_layer.2, %87), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:278:0,\n",
       " %156 : int[] = prim::ListConstruct(%154, %155, %98), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self,\n",
       " %input.8 : Float(1:12800, 100:128, 128:1) = aten::view(%context_layer.2, %156), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:279:0,\n",
       " %158 : __torch__.torch.nn.modules.normalization.___torch_mangle_9.LayerNorm = prim::GetAttr[name=\"LayerNorm\"](%106),\n",
       " %159 : __torch__.torch.nn.modules.linear.___torch_mangle_8.Linear = prim::GetAttr[name=\"dense\"](%106),\n",
       " %160 : Tensor = prim::GetAttr[name=\"bias\"](%159),\n",
       " %161 : Tensor = prim::GetAttr[name=\"weight\"](%159),\n",
       " %162 : Float(128:1, 128:128) = aten::t(%161), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.output/__module.encoder.layer.0.attention.output.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0,\n",
       " %output.4 : Float(1:12800, 100:128, 128:1) = aten::matmul(%input.8, %162), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.output/__module.encoder.layer.0.attention.output.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0,\n",
       " %input.9 : Float(1:12800, 100:128, 128:1) = aten::add_(%output.4, %160, %87), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.output/__module.encoder.layer.0.attention.output.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1678:0,\n",
       " %hidden_states.1 : Float(1:12800, 100:128, 128:1) = aten::dropout(%input.9, %97, %96), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.output/__module.encoder.layer.0.attention.output.dropout # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:973:0,\n",
       " %input.10 : Float(1:12800, 100:128, 128:1) = aten::add(%hidden_states.1, %input.5, %87), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.output # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:295:0,\n",
       " %167 : Tensor = prim::GetAttr[name=\"bias\"](%158),\n",
       " %168 : Tensor = prim::GetAttr[name=\"weight\"](%158),\n",
       " %169 : int[] = prim::ListConstruct(%98), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.output/__module.encoder.layer.0.attention.output.LayerNorm,\n",
       " %input_tensor.1 : Float(1:12800, 100:128, 128:1) = aten::layer_norm(%input.10, %169, %168, %167, %86, %85), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.output/__module.encoder.layer.0.attention.output.LayerNorm # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:2048:0,\n",
       " %171 : __torch__.torch.nn.modules.linear.___torch_mangle_11.Linear = prim::GetAttr[name=\"dense\"](%104),\n",
       " %172 : Tensor = prim::GetAttr[name=\"bias\"](%171),\n",
       " %173 : Tensor = prim::GetAttr[name=\"weight\"](%171),\n",
       " %174 : Float(128:1, 512:128) = aten::t(%173), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.intermediate/__module.encoder.layer.0.intermediate.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0,\n",
       " %output.5 : Float(1:51200, 100:512, 512:1) = aten::matmul(%input_tensor.1, %174), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.intermediate/__module.encoder.layer.0.intermediate.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0,\n",
       " %input.11 : Float(1:51200, 100:512, 512:1) = aten::add_(%output.5, %172, %87), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.intermediate/__module.encoder.layer.0.intermediate.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1678:0,\n",
       " %input.12 : Float(1:51200, 100:512, 512:1) = aten::gelu(%input.11), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.intermediate # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1369:0,\n",
       " %178 : __torch__.torch.nn.modules.normalization.___torch_mangle_13.LayerNorm = prim::GetAttr[name=\"LayerNorm\"](%103),\n",
       " %179 : __torch__.torch.nn.modules.linear.___torch_mangle_12.Linear = prim::GetAttr[name=\"dense\"](%103),\n",
       " %180 : Tensor = prim::GetAttr[name=\"bias\"](%179),\n",
       " %181 : Tensor = prim::GetAttr[name=\"weight\"](%179),\n",
       " %182 : Float(512:1, 128:512) = aten::t(%181), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.output/__module.encoder.layer.0.output.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0,\n",
       " %output.6 : Float(1:12800, 100:128, 128:1) = aten::matmul(%input.12, %182), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.output/__module.encoder.layer.0.output.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0,\n",
       " %input.13 : Float(1:12800, 100:128, 128:1) = aten::add_(%output.6, %180, %87), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.output/__module.encoder.layer.0.output.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1678:0,\n",
       " %hidden_states.2 : Float(1:12800, 100:128, 128:1) = aten::dropout(%input.13, %97, %96), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.output/__module.encoder.layer.0.output.dropout # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:973:0,\n",
       " %input.14 : Float(1:12800, 100:128, 128:1) = aten::add(%hidden_states.2, %input_tensor.1, %87), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.output # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:371:0,\n",
       " %187 : Tensor = prim::GetAttr[name=\"bias\"](%178),\n",
       " %188 : Tensor = prim::GetAttr[name=\"weight\"](%178),\n",
       " %189 : int[] = prim::ListConstruct(%98), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.output/__module.encoder.layer.0.output.LayerNorm,\n",
       " %input.15 : Float(1:12800, 100:128, 128:1) = aten::layer_norm(%input.14, %189, %188, %187, %86, %85), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.output/__module.encoder.layer.0.output.LayerNorm # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:2048:0,\n",
       " %191 : __torch__.transformers.modeling_bert.___torch_mangle_30.BertOutput = prim::GetAttr[name=\"output\"](%100),\n",
       " %192 : __torch__.transformers.modeling_bert.___torch_mangle_26.BertIntermediate = prim::GetAttr[name=\"intermediate\"](%100),\n",
       " %193 : __torch__.transformers.modeling_bert.___torch_mangle_24.BertAttention = prim::GetAttr[name=\"attention\"](%100),\n",
       " %194 : __torch__.transformers.modeling_bert.___torch_mangle_23.BertSelfOutput = prim::GetAttr[name=\"output\"](%193),\n",
       " %195 : __torch__.transformers.modeling_bert.___torch_mangle_19.BertSelfAttention = prim::GetAttr[name=\"self\"](%193),\n",
       " %196 : __torch__.torch.nn.modules.linear.___torch_mangle_17.Linear = prim::GetAttr[name=\"value\"](%195),\n",
       " %197 : __torch__.torch.nn.modules.linear.___torch_mangle_16.Linear = prim::GetAttr[name=\"key\"](%195),\n",
       " %198 : __torch__.torch.nn.modules.linear.___torch_mangle_15.Linear = prim::GetAttr[name=\"query\"](%195),\n",
       " %199 : Tensor = prim::GetAttr[name=\"bias\"](%198),\n",
       " %200 : Tensor = prim::GetAttr[name=\"weight\"](%198),\n",
       " %201 : Float(128:1, 128:128) = aten::t(%200), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self/__module.encoder.layer.1.attention.self.query # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0,\n",
       " %output.7 : Float(1:12800, 100:128, 128:1) = aten::matmul(%input.15, %201), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self/__module.encoder.layer.1.attention.self.query # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0,\n",
       " %x.7 : Float(1:12800, 100:128, 128:1) = aten::add_(%output.7, %199, %87), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self/__module.encoder.layer.1.attention.self.query # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1678:0,\n",
       " %204 : Tensor = prim::GetAttr[name=\"bias\"](%197),\n",
       " %205 : Tensor = prim::GetAttr[name=\"weight\"](%197),\n",
       " %206 : Float(128:1, 128:128) = aten::t(%205), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self/__module.encoder.layer.1.attention.self.key # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0,\n",
       " %output.8 : Float(1:12800, 100:128, 128:1) = aten::matmul(%input.15, %206), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self/__module.encoder.layer.1.attention.self.key # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0,\n",
       " %x.9 : Float(1:12800, 100:128, 128:1) = aten::add_(%output.8, %204, %87), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self/__module.encoder.layer.1.attention.self.key # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1678:0,\n",
       " %209 : Tensor = prim::GetAttr[name=\"bias\"](%196),\n",
       " %210 : Tensor = prim::GetAttr[name=\"weight\"](%196),\n",
       " %211 : Float(128:1, 128:128) = aten::t(%210), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self/__module.encoder.layer.1.attention.self.value # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0,\n",
       " %output.9 : Float(1:12800, 100:128, 128:1) = aten::matmul(%input.15, %211), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self/__module.encoder.layer.1.attention.self.value # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0,\n",
       " %x.11 : Float(1:12800, 100:128, 128:1) = aten::add_(%output.9, %209, %87), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self/__module.encoder.layer.1.attention.self.value # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1678:0,\n",
       " %214 : int = aten::size(%x.7, %88), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:227:0,\n",
       " %215 : int = aten::size(%x.7, %87), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:227:0,\n",
       " %216 : int[] = prim::ListConstruct(%214, %215, %89, %90), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self,\n",
       " %x.8 : Float(1:12800, 100:128, 2:64, 64:1) = aten::view(%x.7, %216), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:228:0,\n",
       " %218 : int[] = prim::ListConstruct(%88, %89, %87, %91), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self,\n",
       " %query_layer : Float(1:12800, 2:64, 100:128, 64:1) = aten::permute(%x.8, %218), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:229:0,\n",
       " %220 : int = aten::size(%x.9, %88), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:227:0,\n",
       " %221 : int = aten::size(%x.9, %87), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:227:0,\n",
       " %222 : int[] = prim::ListConstruct(%220, %221, %89, %90), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self,\n",
       " %x.10 : Float(1:12800, 100:128, 2:64, 64:1) = aten::view(%x.9, %222), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:228:0,\n",
       " %224 : int[] = prim::ListConstruct(%88, %89, %87, %91), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self,\n",
       " %key_layer : Float(1:12800, 2:64, 100:128, 64:1) = aten::permute(%x.10, %224), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:229:0,\n",
       " %226 : int = aten::size(%x.11, %88), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:227:0,\n",
       " %227 : int = aten::size(%x.11, %87), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:227:0,\n",
       " %228 : int[] = prim::ListConstruct(%226, %227, %89, %90), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self,\n",
       " %x : Float(1:12800, 100:128, 2:64, 64:1) = aten::view(%x.11, %228), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:228:0,\n",
       " %230 : int[] = prim::ListConstruct(%88, %89, %87, %91), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self,\n",
       " %value_layer : Float(1:12800, 2:64, 100:128, 64:1) = aten::permute(%x, %230), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:229:0,\n",
       " %232 : Float(1:12800, 2:64, 64:1, 100:128) = aten::transpose(%key_layer, %92, %93), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:258:0,\n",
       " %attention_scores.3 : Float(1:20000, 2:10000, 100:100, 100:1) = aten::matmul(%query_layer, %232), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:258:0,\n",
       " %attention_scores : Float(1:20000, 2:10000, 100:100, 100:1) = aten::div(%attention_scores.3, %94), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:259:0,\n",
       " %input.16 : Float(1:20000, 2:10000, 100:100, 100:1) = aten::add(%attention_scores, %attention_mask, %87), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:262:0,\n",
       " %input.17 : Float(1:20000, 2:10000, 100:100, 100:1) = aten::softmax(%input.16, %92, %95), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1498:0,\n",
       " %attention_probs : Float(1:20000, 2:10000, 100:100, 100:1) = aten::dropout(%input.17, %97, %96), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self/__module.encoder.layer.1.attention.self.dropout # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:973:0,\n",
       " %context_layer.3 : Float(1:12800, 2:6400, 100:64, 64:1) = aten::matmul(%attention_probs, %value_layer), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:275:0,\n",
       " %239 : int[] = prim::ListConstruct(%88, %89, %87, %91), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self,\n",
       " %240 : Float(1:12800, 100:64, 2:6400, 64:1) = aten::permute(%context_layer.3, %239), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:277:0,\n",
       " %context_layer : Float(1:12800, 100:128, 2:64, 64:1) = aten::contiguous(%240, %88), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:277:0,\n",
       " %242 : int = aten::size(%context_layer, %88), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:278:0,\n",
       " %243 : int = aten::size(%context_layer, %87), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:278:0,\n",
       " %244 : int[] = prim::ListConstruct(%242, %243, %98), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self,\n",
       " %input.18 : Float(1:12800, 100:128, 128:1) = aten::view(%context_layer, %244), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:279:0,\n",
       " %246 : __torch__.torch.nn.modules.normalization.___torch_mangle_21.LayerNorm = prim::GetAttr[name=\"LayerNorm\"](%194),\n",
       " %247 : __torch__.torch.nn.modules.linear.___torch_mangle_20.Linear = prim::GetAttr[name=\"dense\"](%194),\n",
       " %248 : Tensor = prim::GetAttr[name=\"bias\"](%247),\n",
       " %249 : Tensor = prim::GetAttr[name=\"weight\"](%247),\n",
       " %250 : Float(128:1, 128:128) = aten::t(%249), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.output/__module.encoder.layer.1.attention.output.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0,\n",
       " %output.10 : Float(1:12800, 100:128, 128:1) = aten::matmul(%input.18, %250), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.output/__module.encoder.layer.1.attention.output.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0,\n",
       " %input.19 : Float(1:12800, 100:128, 128:1) = aten::add_(%output.10, %248, %87), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.output/__module.encoder.layer.1.attention.output.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1678:0,\n",
       " %hidden_states.3 : Float(1:12800, 100:128, 128:1) = aten::dropout(%input.19, %97, %96), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.output/__module.encoder.layer.1.attention.output.dropout # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:973:0,\n",
       " %input.20 : Float(1:12800, 100:128, 128:1) = aten::add(%hidden_states.3, %input.15, %87), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.output # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:295:0,\n",
       " %255 : Tensor = prim::GetAttr[name=\"bias\"](%246),\n",
       " %256 : Tensor = prim::GetAttr[name=\"weight\"](%246),\n",
       " %257 : int[] = prim::ListConstruct(%98), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.output/__module.encoder.layer.1.attention.output.LayerNorm,\n",
       " %input_tensor : Float(1:12800, 100:128, 128:1) = aten::layer_norm(%input.20, %257, %256, %255, %86, %85), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.output/__module.encoder.layer.1.attention.output.LayerNorm # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:2048:0,\n",
       " %259 : __torch__.torch.nn.modules.linear.___torch_mangle_25.Linear = prim::GetAttr[name=\"dense\"](%192),\n",
       " %260 : Tensor = prim::GetAttr[name=\"bias\"](%259),\n",
       " %261 : Tensor = prim::GetAttr[name=\"weight\"](%259),\n",
       " %262 : Float(128:1, 512:128) = aten::t(%261), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.intermediate/__module.encoder.layer.1.intermediate.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0,\n",
       " %output.11 : Float(1:51200, 100:512, 512:1) = aten::matmul(%input_tensor, %262), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.intermediate/__module.encoder.layer.1.intermediate.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0,\n",
       " %input.21 : Float(1:51200, 100:512, 512:1) = aten::add_(%output.11, %260, %87), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.intermediate/__module.encoder.layer.1.intermediate.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1678:0,\n",
       " %input.22 : Float(1:51200, 100:512, 512:1) = aten::gelu(%input.21), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.intermediate # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1369:0,\n",
       " %266 : __torch__.torch.nn.modules.normalization.___torch_mangle_28.LayerNorm = prim::GetAttr[name=\"LayerNorm\"](%191),\n",
       " %267 : __torch__.torch.nn.modules.linear.___torch_mangle_27.Linear = prim::GetAttr[name=\"dense\"](%191),\n",
       " %268 : Tensor = prim::GetAttr[name=\"bias\"](%267),\n",
       " %269 : Tensor = prim::GetAttr[name=\"weight\"](%267),\n",
       " %270 : Float(512:1, 128:512) = aten::t(%269), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.output/__module.encoder.layer.1.output.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0,\n",
       " %output : Float(1:12800, 100:128, 128:1) = aten::matmul(%input.22, %270), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.output/__module.encoder.layer.1.output.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1676:0,\n",
       " %input.23 : Float(1:12800, 100:128, 128:1) = aten::add_(%output, %268, %87), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.output/__module.encoder.layer.1.output.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1678:0,\n",
       " %hidden_states.4 : Float(1:12800, 100:128, 128:1) = aten::dropout(%input.23, %97, %96), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.output/__module.encoder.layer.1.output.dropout # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:973:0,\n",
       " %input.24 : Float(1:12800, 100:128, 128:1) = aten::add(%hidden_states.4, %input_tensor, %87), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.output # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:371:0,\n",
       " %275 : Tensor = prim::GetAttr[name=\"bias\"](%266),\n",
       " %276 : Tensor = prim::GetAttr[name=\"weight\"](%266),\n",
       " %277 : int[] = prim::ListConstruct(%98), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.output/__module.encoder.layer.1.output.LayerNorm,\n",
       " %hidden_states : Float(1:12800, 100:128, 128:1) = aten::layer_norm(%input.24, %277, %276, %275, %86, %85), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.output/__module.encoder.layer.1.output.LayerNorm # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:2048:0,\n",
       " %279 : int = prim::Constant[value=1](), scope: __module.pooler # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:517:0,\n",
       " %280 : int = prim::Constant[value=9223372036854775807](), scope: __module.pooler # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:517:0,\n",
       " %281 : int = prim::Constant[value=0](), scope: __module.pooler # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:517:0,\n",
       " %282 : __torch__.torch.nn.modules.linear.___torch_mangle_32.Linear = prim::GetAttr[name=\"dense\"](%2),\n",
       " %283 : Float(1:12800, 100:128, 128:1) = aten::slice(%hidden_states, %281, %281, %280, %279), scope: __module.pooler # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:517:0,\n",
       " %input.25 : Float(1:12800, 128:1) = aten::select(%283, %279, %281), scope: __module.pooler # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:517:0,\n",
       " %285 : Tensor = prim::GetAttr[name=\"bias\"](%282),\n",
       " %286 : Tensor = prim::GetAttr[name=\"weight\"](%282),\n",
       " %287 : Float(128:1, 128:128) = aten::t(%286), scope: __module.pooler/__module.pooler.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1674:0,\n",
       " %input : Float(1:128, 128:1) = aten::addmm(%285, %input.25, %287, %279, %279), scope: __module.pooler/__module.pooler.dense # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/functional.py:1674:0,\n",
       " %289 : Float(1:128, 128:1) = aten::tanh(%input), scope: __module.pooler/__module.pooler.activation # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/torch/nn/modules/activation.py:350:0,\n",
       " %54 : (Float(1:12800, 100:128, 128:1), Float(1:128, 128:1)) = prim::TupleConstruct(%hidden_states, %289)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ni=list(graph.nodes())\n",
    "ni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "%2 : __torch__.transformers.modeling_bert.BertPooler = prim::GetAttr[name=\"pooler\"](%self.1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ni[0].output().node()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2 defined in (%2 : __torch__.transformers.modeling_bert.BertPooler = prim::GetAttr[name=\"pooler\"](%self.1)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ni[0].output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78 defined in (%78 : Float(1:12800, 100:128, 128:1) = aten::add(%inputs_embeds, %position_embeddings, %63), scope: __module.embeddings # /Users/qqcao/.pyenv/versions/nlpnrg/lib/python3.8/site-packages/transformers/modeling_bert.py:201:0\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ni[72].output() # build all input leaf data nodes, then construct the opnode with input and output nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "%2 : __torch__.transformers.modeling_bert.BertPooler = prim::GetAttr[name=\"pooler\"](%self.1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ni[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2 defined in (%2 : __torch__.transformers.modeling_bert.BertPooler = prim::GetAttr[name=\"pooler\"](%self.1)\n",
       " )]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ni[0].outputs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[self.1 defined in (%self.1 : __torch__.transformers.modeling_bert.BertModel, %input_ids : Long(1:100, 100:1) = prim::Param()\n",
       " )]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ni[0].inputs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "%self.1 : __torch__.transformers.modeling_bert.BertModel, %input_ids : Long(1:100, 100:1) = prim::Param()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pn=ni[0].input().node()\n",
    "pn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[self.1 defined in (%self.1 : __torch__.transformers.modeling_bert.BertModel, %input_ids : Long(1:100, 100:1) = prim::Param()\n",
       " ),\n",
       " input_ids defined in (%self.1 : __torch__.transformers.modeling_bert.BertModel, %input_ids : Long(1:100, 100:1) = prim::Param()\n",
       " )]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gi=list(graph.inputs())\n",
    "gi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__torch__.transformers.modeling_bert.BertModel"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(gi[0].node().outputs())[0].type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 100]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(gi[1].node().outputs())[1].type().sizes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'encoder.layer.0.attention.output'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'encoder/encoder.layer.0/encoder.layer.0.attention/encoder.layer.0.attention.output'.split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%self.1 : __torch__.transformers.modeling_bert.BertModel, %input_ids : Long(1:100, 100:1) = prim::Param()\n",
      "\n",
      "%self.1 : __torch__.transformers.modeling_bert.BertModel, %input_ids : Long(1:100, 100:1) = prim::Param()\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(pn)\n",
    "print(gi[1].node())\n",
    "pn==gi[0].node()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[%2 : __torch__.transformers.modeling_bert.BertPooler = prim::GetAttr[name=\"pooler\"](%self.1),\n",
       " %3 : __torch__.transformers.modeling_bert.BertEncoder = prim::GetAttr[name=\"encoder\"](%self.1),\n",
       " %4 : __torch__.transformers.modeling_bert.BertEmbeddings = prim::GetAttr[name=\"embeddings\"](%self.1)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i.user for i in gi[0].uses()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[54 defined in (%54 : (Float(1:12800, 100:128, 128:1), Float(1:128, 128:1)) = prim::TupleConstruct(%hidden_states, %289)\n",
       " )]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "go=list(graph.outputs())\n",
    "go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.44.1 (20200629.0846)\n",
       " -->\n",
       "<!-- Title: G Pages: 1 -->\n",
       "<svg width=\"296pt\" height=\"438pt\"\n",
       " viewBox=\"0.00 0.00 296.00 438.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 434)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-434 292,-434 292,4 -4,4\"/>\n",
       "<g id=\"clust1\" class=\"cluster\">\n",
       "<title>cluster_0</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"lightgrey\" points=\"8,-56 8,-386 180,-386 180,-56 8,-56\"/>\n",
       "<text text-anchor=\"middle\" x=\"94\" y=\"-370.8\" font-family=\"Times,serif\" font-size=\"14.00\">process #1</text>\n",
       "</g>\n",
       "<g id=\"clust2\" class=\"cluster\">\n",
       "<title>cluster_0</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"lightblue\" points=\"98,-64 98,-355 172,-355 172,-64 98,-64\"/>\n",
       "<text text-anchor=\"middle\" x=\"135\" y=\"-339.8\" font-family=\"Times,serif\" font-size=\"14.00\">process #3</text>\n",
       "</g>\n",
       "<g id=\"clust3\" class=\"cluster\">\n",
       "<title>cluster_1</title>\n",
       "<polygon fill=\"none\" stroke=\"blue\" points=\"206,-64 206,-355 280,-355 280,-64 206,-64\"/>\n",
       "<text text-anchor=\"middle\" x=\"243\" y=\"-339.8\" font-family=\"Times,serif\" font-size=\"14.00\">process #2</text>\n",
       "</g>\n",
       "<!-- a0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>a0</title>\n",
       "<ellipse fill=\"white\" stroke=\"white\" cx=\"63\" cy=\"-306\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"63\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">a0</text>\n",
       "</g>\n",
       "<!-- a1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>a1</title>\n",
       "<ellipse fill=\"white\" stroke=\"white\" cx=\"63\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"63\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">a1</text>\n",
       "</g>\n",
       "<!-- a0&#45;&gt;a1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>a0&#45;&gt;a1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M63,-287.7C63,-279.98 63,-270.71 63,-262.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"66.5,-262.1 63,-252.1 59.5,-262.1 66.5,-262.1\"/>\n",
       "</g>\n",
       "<!-- a2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>a2</title>\n",
       "<ellipse fill=\"white\" stroke=\"white\" cx=\"63\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"63\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">a2</text>\n",
       "</g>\n",
       "<!-- a1&#45;&gt;a2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>a1&#45;&gt;a2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M63,-215.7C63,-207.98 63,-198.71 63,-190.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"66.5,-190.1 63,-180.1 59.5,-190.1 66.5,-190.1\"/>\n",
       "</g>\n",
       "<!-- b3 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>b3</title>\n",
       "<ellipse fill=\"lightgrey\" stroke=\"black\" cx=\"241\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"241\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">b3</text>\n",
       "</g>\n",
       "<!-- a1&#45;&gt;b3 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>a1&#45;&gt;b3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M82.88,-221.77C86.54,-219.79 90.37,-217.79 94,-216 129.71,-198.41 144.97,-204.93 176,-180 187.85,-170.48 210.03,-138.49 225.16,-115.59\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"228.21,-117.31 230.76,-107.02 222.36,-113.47 228.21,-117.31\"/>\n",
       "</g>\n",
       "<!-- a3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>a3</title>\n",
       "<ellipse fill=\"white\" stroke=\"white\" cx=\"63\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"63\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">a3</text>\n",
       "</g>\n",
       "<!-- a2&#45;&gt;a3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>a2&#45;&gt;a3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M63,-143.7C63,-135.98 63,-126.71 63,-118.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"66.5,-118.1 63,-108.1 59.5,-118.1 66.5,-118.1\"/>\n",
       "</g>\n",
       "<!-- a3&#45;&gt;a0 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>a3&#45;&gt;a0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M49.25,-105.93C41.04,-115.9 31.38,-129.75 27,-144 12.89,-189.88 12.89,-206.12 27,-252 30.29,-262.69 36.54,-273.15 42.93,-281.92\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"40.35,-284.31 49.25,-290.07 45.88,-280.02 40.35,-284.31\"/>\n",
       "</g>\n",
       "<!-- end -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>end</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"170,-36 134,-36 134,0 170,0 170,-36\"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"146,-36 134,-24 \"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"134,-12 146,0 \"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"158,0 170,-12 \"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"170,-24 158,-36 \"/>\n",
       "<text text-anchor=\"middle\" x=\"152\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">end</text>\n",
       "</g>\n",
       "<!-- a3&#45;&gt;end -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>a3&#45;&gt;end</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M75.85,-73.77C81.17,-67.89 87.59,-61.32 94,-56 103.57,-48.06 114.95,-40.46 125.09,-34.23\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"127.17,-37.07 133.96,-28.93 123.58,-31.06 127.17,-37.07\"/>\n",
       "</g>\n",
       "<!-- c0 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>c0</title>\n",
       "<ellipse fill=\"white\" stroke=\"white\" cx=\"135\" cy=\"-306\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"135\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">c0</text>\n",
       "</g>\n",
       "<!-- c1 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>c1</title>\n",
       "<ellipse fill=\"white\" stroke=\"white\" cx=\"135\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"135\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">c1</text>\n",
       "</g>\n",
       "<!-- c0&#45;&gt;c1 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>c0&#45;&gt;c1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M135,-287.7C135,-279.98 135,-270.71 135,-262.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"138.5,-262.1 135,-252.1 131.5,-262.1 138.5,-262.1\"/>\n",
       "</g>\n",
       "<!-- c2 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>c2</title>\n",
       "<ellipse fill=\"white\" stroke=\"white\" cx=\"135\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"135\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">c2</text>\n",
       "</g>\n",
       "<!-- c1&#45;&gt;c2 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>c1&#45;&gt;c2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M135,-215.7C135,-207.98 135,-198.71 135,-190.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"138.5,-190.1 135,-180.1 131.5,-190.1 138.5,-190.1\"/>\n",
       "</g>\n",
       "<!-- c3 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>c3</title>\n",
       "<ellipse fill=\"white\" stroke=\"white\" cx=\"135\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"135\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">c3</text>\n",
       "</g>\n",
       "<!-- c2&#45;&gt;c3 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>c2&#45;&gt;c3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M135,-143.7C135,-135.98 135,-126.71 135,-118.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"138.5,-118.1 135,-108.1 131.5,-118.1 138.5,-118.1\"/>\n",
       "</g>\n",
       "<!-- b0 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>b0</title>\n",
       "<ellipse fill=\"lightgrey\" stroke=\"black\" cx=\"241\" cy=\"-306\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"241\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">b0</text>\n",
       "</g>\n",
       "<!-- b1 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>b1</title>\n",
       "<ellipse fill=\"lightgrey\" stroke=\"black\" cx=\"243\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"243\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">b1</text>\n",
       "</g>\n",
       "<!-- b0&#45;&gt;b1 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>b0&#45;&gt;b1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M241.49,-287.7C241.71,-279.98 241.98,-270.71 242.23,-262.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"245.72,-262.2 242.51,-252.1 238.73,-262 245.72,-262.2\"/>\n",
       "</g>\n",
       "<!-- b2 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>b2</title>\n",
       "<ellipse fill=\"lightgrey\" stroke=\"black\" cx=\"245\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"245\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">b2</text>\n",
       "</g>\n",
       "<!-- b1&#45;&gt;b2 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>b1&#45;&gt;b2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M243.49,-215.7C243.71,-207.98 243.98,-198.71 244.23,-190.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"247.72,-190.2 244.51,-180.1 240.73,-190 247.72,-190.2\"/>\n",
       "</g>\n",
       "<!-- b2&#45;&gt;a3 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>b2&#45;&gt;a3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M220.73,-153.83C190.49,-144.6 137.52,-127.41 94,-108 93.31,-107.69 92.61,-107.37 91.9,-107.04\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"93.28,-103.82 82.77,-102.47 90.14,-110.07 93.28,-103.82\"/>\n",
       "</g>\n",
       "<!-- b2&#45;&gt;b3 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>b2&#45;&gt;b3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M244.01,-143.7C243.57,-135.98 243.04,-126.71 242.55,-118.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"246.04,-117.89 241.98,-108.1 239.05,-118.29 246.04,-117.89\"/>\n",
       "</g>\n",
       "<!-- b3&#45;&gt;end -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>b3&#45;&gt;end</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M224.26,-75.83C211.26,-65.61 193,-51.24 178.08,-39.51\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"180.22,-36.74 170.2,-33.31 175.89,-42.25 180.22,-36.74\"/>\n",
       "</g>\n",
       "<!-- start -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>start</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"152,-430 115.47,-412 152,-394 188.53,-412 152,-430\"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"126.23,-417.3 126.23,-406.7 \"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"141.24,-399.3 162.76,-399.3 \"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"177.77,-406.7 177.77,-417.3 \"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"162.76,-424.7 141.24,-424.7 \"/>\n",
       "<text text-anchor=\"middle\" x=\"152\" y=\"-408.3\" font-family=\"Times,serif\" font-size=\"14.00\">start</text>\n",
       "</g>\n",
       "<!-- start&#45;&gt;a0 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>start&#45;&gt;a0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M128.61,-405.52C116.91,-401.74 103.3,-395.61 94,-386 80.26,-371.79 72.4,-350.78 68.04,-334\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"71.44,-333.14 65.76,-324.19 64.62,-334.73 71.44,-333.14\"/>\n",
       "</g>\n",
       "<!-- start&#45;&gt;b0 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>start&#45;&gt;b0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M163.42,-399.47C167.47,-395.29 172,-390.5 176,-386 192.13,-367.86 209.57,-346.57 222.32,-330.66\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"225.38,-332.43 228.88,-322.43 219.91,-328.07 225.38,-332.43\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x1393f1700>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from graphviz import Digraph\n",
    "\n",
    "g = Digraph('G')\n",
    "\n",
    "c0 = Digraph('cluster_0')\n",
    "c0.body.append('style=filled')\n",
    "c0.body.append('color=lightgrey')\n",
    "c0.node_attr.update(style='filled', color='white')\n",
    "c0.edges([('a0', 'a1'), ('a1', 'a2'), ('a2', 'a3')])\n",
    "c0.body.append('label =\"process #1\"')\n",
    "\n",
    "c2 = Digraph('cluster_0')\n",
    "c2.body.append('style=filled')\n",
    "c2.body.append('color=lightgrey')\n",
    "c2.node_attr.update(style='filled', color='white')\n",
    "c2.edges([('c0', 'c1'), ('c1', 'c2'), ('c2', 'c3')])\n",
    "c2.body.append('label =\"process #3\"')\n",
    "c2.body.append('color=lightblue')\n",
    "c0.subgraph(c2)\n",
    "\n",
    "c1 = Digraph('cluster_1')\n",
    "c1.node_attr.update(style='filled')\n",
    "c1.edges([('b0', 'b1'), ('b1', 'b2'), ('b2', 'b3')])\n",
    "c1.body.append('label =\"process #2\"')\n",
    "c1.body.append('color=blue')\n",
    "\n",
    "g.subgraph(c0)\n",
    "g.subgraph(c1)\n",
    "\n",
    "g.edge('start', 'a0')\n",
    "g.edge('start', 'b0')\n",
    "g.edge('a1', 'b3')\n",
    "g.edge('b2', 'a3')\n",
    "g.edge('a3', 'a0')\n",
    "g.edge('a3', 'end')\n",
    "g.edge('b3', 'end')\n",
    "\n",
    "g.node('start', shape='Mdiamond')\n",
    "g.node('end', shape='Msquare')\n",
    "\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub_scopes='encoder.layer.0.attention.output.LayerNorm'.split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'false'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'true' if '' and len(''.split('.')) else 'false'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 encoder.layer.0.attention.output encoder.layer.0.attention.output.LayerNorm\n",
      "5 encoder.layer.0.attention encoder.layer.0.attention.output\n",
      "4 encoder.layer.0 encoder.layer.0.attention\n",
      "3 encoder.layer encoder.layer.0\n",
      "2 encoder encoder.layer\n",
      "1  encoder\n"
     ]
    }
   ],
   "source": [
    "sub_scopes='encoder.layer.0.attention.output.LayerNorm'.split('.')\n",
    "for si in range(len(sub_scopes), 0, -1):\n",
    "    p_scope = '.'.join(sub_scopes[0:si-1])\n",
    "    child_scope = '.'.join(sub_scopes[0:si])\n",
    "    print(si, p_scope, child_scope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
